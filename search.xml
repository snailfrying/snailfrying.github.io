<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hive SQL 编译过程]]></title>
    <url>%2F2019%2F10%2F15%2FHive-SQL-%E7%BC%96%E8%AF%91%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[--- # **Hive SQL 编译过程** Hive是基于Hadoop的一个数据仓库系统，在各大公司都有广泛的应用。美团数据仓库也是基于Hive搭建，每天执行近万次的Hive ETL计算流程，负责每天数百GB的数据存储和分析。Hive的稳定性和性能对我们的数据分析非常关键。 在几次升级Hive的过程中，我们遇到了一些大大小小的问题。通过向社区的咨询和自己的努力，在解决这些问题的同时我们对Hive将SQL编译为MapReduce的过程有了比较深入的理解。对这一过程的理解不仅帮助我们解决了一些Hive的bug，也有利于我们优化Hive SQL，提升我们对Hive的掌控力，同时有能力去定制一些需要的功能。 MapReduce实现基本SQL操作的原理详细讲解SQL编译为MapReduce之前，我们先来看看MapReduce框架实现SQL基本操作的原理 Join的实现原理1select u.name, o.orderid from order o join user u on o.uid = u.uid; 在map的输出value中为不同表的数据打上tag标记，在reduce阶段根据tag判断数据来源。MapReduce的过程如下（这里只是说明最基本的Join的实现，还有其他的实现方式） MapReduce CommonJoin的实现 Group By的实现原理1select rank, isonline, count(*) from city group by rank, isonline; 将GroupBy的字段组合为map的输出key值，利用MapReduce的排序，在reduce阶段保存LastKey区分不同的key。MapReduce的过程如下（当然这里只是说明Reduce端的非Hash聚合过程） MapReduce Group By的实现 Distinct的实现原理1select dealid, count(distinct uid) num from order group by dealid; 当只有一个distinct字段时，如果不考虑Map阶段的Hash GroupBy，只需要将GroupBy字段和Distinct字段组合为map输出key，利用mapreduce的排序，同时将GroupBy字段作为reduce的key，在reduce阶段保存LastKey即可完成去重 MapReduce Distinct的实现 如果有多个distinct字段呢，如下面的SQL 1select dealid, count(distinct uid), count(distinct date) from order group by dealid; 实现方式有两种： （1）如果仍然按照上面一个distinct字段的方法，即下图这种实现方式，无法跟据uid和date分别排序，也就无法通过LastKey去重，仍然需要在reduce阶段在内存中通过Hash去重 MapReduce Multi Distinct的实现 （2）第二种实现方式，可以对所有的distinct字段编号，每行数据生成n行数据，那么相同字段就会分别排序，这时只需要在reduce阶段记录LastKey即可去重。 这种实现方式很好的利用了MapReduce的排序，节省了reduce阶段去重的内存消耗，但是缺点是增加了shuffle的数据量。 需要注意的是，在生成reduce value时，除第一个distinct字段所在行需要保留value值，其余distinct数据行value字段均可为空。 MapReduce Multi Distinct的实现 SQL转化为MapReduce的过程了解了MapReduce实现SQL基本操作之后，我们来看看Hive是如何将SQL转化为MapReduce任务的，整个编译过程分为六个阶段： Antlr定义SQL的语法规则，完成SQL词法，语法解析，将SQL转化为抽象语法树AST Tree 遍历AST Tree，抽象出查询的基本组成单元QueryBlock 遍历QueryBlock，翻译为执行操作树OperatorTree 逻辑层优化器进行OperatorTree变换，合并不必要的ReduceSinkOperator，减少shuffle数据量 遍历OperatorTree，翻译为MapReduce任务 物理层优化器进行MapReduce任务的变换，生成最终的执行计划 下面分别对这六个阶段进行介绍 Phase1 SQL词法，语法解析AntlrHive使用Antlr实现SQL的词法和语法解析。Antlr是一种语言识别的工具，可以用来构造领域语言。 这里不详细介绍Antlr，只需要了解使用Antlr构造特定的语言只需要编写一个语法文件，定义词法和语法替换规则即可，Antlr完成了词法分析、语法分析、语义分析、中间代码生成的过程。 Hive中语法规则的定义文件在0.10版本以前是Hive.g一个文件，随着语法规则越来越复杂，由语法规则生成的Java解析类可能超过Java类文件的最大上限，0.11版本将Hive.g拆成了5个文件，词法规则HiveLexer.g和语法规则的4个文件SelectClauseParser.g，FromClauseParser.g，IdentifiersParser.g，HiveParser.g。 抽象语法树AST Tree经过词法和语法解析后，如果需要对表达式做进一步的处理，使用 Antlr 的抽象语法树语法Abstract Syntax Tree，在语法分析的同时将输入语句转换成抽象语法树，后续在遍历语法树时完成进一步的处理。 下面的一段语法是Hive SQL中SelectStatement的语法规则，从中可以看出，SelectStatement包含select, from, where, groupby, having, orderby等子句。 （在下面的语法规则中，箭头表示对于原语句的改写，改写后会加入一些特殊词标示特定语法，比如TOK_QUERY标示一个查询块） 123456789101112131415selectStatement : selectClause fromClause whereClause? groupByClause? havingClause? orderByClause? clusterByClause? distributeByClause? sortByClause? limitClause? -&gt; ^(TOK_QUERY fromClause ^(TOK_INSERT ^(TOK_DESTINATION ^(TOK_DIR TOK_TMP_FILE)) selectClause whereClause? groupByClause? havingClause? orderByClause? clusterByClause? distributeByClause? sortByClause? limitClause?)) ; 样例SQL为了详细说明SQL翻译为MapReduce的过程，这里以一条简单的SQL为例，SQL中包含一个子查询，最终将数据写入到一张表中 123456789101112131415161718FROM( SELECT p.datekey datekey, p.userid userid, c.clienttype FROM detail.usersequence_client c JOIN fact.orderpayment p ON p.orderid = c.orderid JOIN default.user du ON du.userid = p.userid WHERE p.datekey = 20131118 ) baseINSERT OVERWRITE TABLE `test`.`customer_kpi`SELECT base.datekey, base.clienttype, count(distinct base.userid) buyer_countGROUP BY base.datekey, base.clienttype SQL生成AST TreeAntlr对Hive SQL解析的代码如下，HiveLexerX，HiveParser分别是Antlr对语法文件Hive.g编译后自动生成的词法解析和语法解析类，在这两个类中进行复杂的解析。 1234567891011121314HiveLexerX lexer = new HiveLexerX(new ANTLRNoCaseStringStream(command)); //词法解析，忽略关键词的大小写TokenRewriteStream tokens = new TokenRewriteStream(lexer);if (ctx != null) &#123; ctx.setTokenRewriteStream(tokens);&#125;HiveParser parser = new HiveParser(tokens); //语法解析parser.setTreeAdaptor(adaptor);HiveParser.statement_return r = null;try &#123; r = parser.statement(); //转化为AST Tree&#125; catch (RecognitionException e) &#123; e.printStackTrace(); throw new ParseException(parser.errors);&#125; 最终生成的AST Tree如下图右侧（使用Antlr Works生成，Antlr Works是Antlr提供的编写语法文件的编辑器），图中只是展开了骨架的几个节点，没有完全展开。 子查询1/2，分别对应右侧第1/2两个部分。 SQL生成AST Tree 这里注意一下内层子查询也会生成一个TOK_DESTINATION节点。请看上面SelectStatement的语法规则，这个节点是在语法改写中特意增加了的一个节点。原因是Hive中所有查询的数据均会保存在HDFS临时的文件中，无论是中间的子查询还是查询最终的结果，Insert语句最终会将数据写入表所在的HDFS目录下。 详细来看，将内存子查询的from子句展开后，得到如下AST Tree，每个表生成一个TOK_TABREF节点，Join条件生成一个“=”节点。其他SQL部分类似，不一一详述。 AST Tree Phase2 SQL基本组成单元QueryBlockAST Tree仍然非常复杂，不够结构化，不方便直接翻译为MapReduce程序，AST Tree转化为QueryBlock就是将SQL进一部抽象和结构化。 QueryBlockQueryBlock是一条SQL最基本的组成单元，包括三个部分：输入源，计算过程，输出。简单来讲一个QueryBlock就是一个子查询。 下图为Hive中QueryBlock相关对象的类图，解释图中几个重要的属性 QB#aliasToSubq（表示QB类的aliasToSubq属性）保存子查询的QB对象，aliasToSubq key值是子查询的别名 QB#qbp即QBParseInfo保存一个基本SQL单元中的给个操作部分的AST Tree结构，QBParseInfo#nameToDest这个HashMap保存查询单元的输出，key的形式是inclause-i（由于Hive支持Multi Insert语句，所以可能有多个输出），value是对应的ASTNode节点，即TOK_DESTINATION节点。类QBParseInfo其余HashMap属性分别保存输出和各个操作的ASTNode节点的对应关系。 QBParseInfo#JoinExpr保存TOK_JOIN节点。QB#QBJoinTree是对Join语法树的结构化。 QB#qbm保存每个输入表的元信息，比如表在HDFS上的路径，保存表数据的文件格式等。 QBExpr这个对象是为了表示Union操作。 QueryBlock AST Tree生成QueryBlockAST Tree生成QueryBlock的过程是一个递归的过程，先序遍历AST Tree，遇到不同的Token节点，保存到相应的属性中，主要包含以下几个过程 TOK_QUERY =&gt; 创建QB对象，循环递归子节点 TOK_FROM =&gt; 将表名语法部分保存到QB对象的aliasToTabs等属性中 TOK_INSERT =&gt; 循环递归子节点 TOK_DESTINATION =&gt; 将输出目标的语法部分保存在QBParseInfo对象的nameToDest属性中 TOK_SELECT =&gt; 分别将查询表达式的语法部分保存在destToSelExpr、destToAggregationExprs、destToDistinctFuncExprs三个属性中 TOK_WHERE =&gt; 将Where部分的语法保存在QBParseInfo对象的destToWhereExpr属性中 最终样例SQL生成两个QB对象，QB对象的关系如下，QB1是外层查询，QB2是子查询 12345QB1 \ QB2 Phase3 逻辑操作符OperatorOperatorHive最终生成的MapReduce任务，Map阶段和Reduce阶段均由OperatorTree组成。逻辑操作符，就是在Map阶段或者Reduce阶段完成单一特定的操作。 基本的操作符包括TableScanOperator，SelectOperator，FilterOperator，JoinOperator，GroupByOperator，ReduceSinkOperator 从名字就能猜出各个操作符完成的功能，TableScanOperator从MapReduce框架的Map接口原始输入表的数据，控制扫描表的数据行数，标记是从原表中取数据。JoinOperator完成Join操作。FilterOperator完成过滤操作 ReduceSinkOperator将Map端的字段组合序列化为Reduce Key/value, Partition Key，只可能出现在Map阶段，同时也标志着Hive生成的MapReduce程序中Map阶段的结束。 Operator在Map Reduce阶段之间的数据传递都是一个流式的过程。每一个Operator对一行数据完成操作后之后将数据传递给childOperator计算。 Operator类的主要属性和方法如下 RowSchema表示Operator的输出字段 InputObjInspector outputObjInspector解析输入和输出字段 processOp接收父Operator传递的数据，forward将处理好的数据传递给子Operator处理 Hive每一行数据经过一个Operator处理之后，会对字段重新编号，colExprMap记录每个表达式经过当前Operator处理前后的名称对应关系，在下一个阶段逻辑优化阶段用来回溯字段名 由于Hive的MapReduce程序是一个动态的程序，即不确定一个MapReduce Job会进行什么运算，可能是Join，也可能是GroupBy，所以Operator将所有运行时需要的参数保存在OperatorDesc中，OperatorDesc在提交任务前序列化到HDFS上，在MapReduce任务执行前从HDFS读取并反序列化。Map阶段OperatorTree在HDFS上的位置在Job.getConf(“hive.exec.plan”) + “/map.xml” QueryBlock QueryBlock生成Operator TreeQueryBlock生成Operator Tree就是遍历上一个过程中生成的QB和QBParseInfo对象的保存语法的属性，包含如下几个步骤： QB#aliasToSubq =&gt; 有子查询，递归调用 QB#aliasToTabs =&gt; TableScanOperator QBParseInfo#joinExpr =&gt; QBJoinTree =&gt; ReduceSinkOperator + JoinOperator QBParseInfo#destToWhereExpr =&gt; FilterOperator QBParseInfo#destToGroupby =&gt; ReduceSinkOperator + GroupByOperator QBParseInfo#destToOrderby =&gt; ReduceSinkOperator + ExtractOperator 由于Join/GroupBy/OrderBy均需要在Reduce阶段完成，所以在生成相应操作的Operator之前都会先生成一个ReduceSinkOperator，将字段组合并序列化为Reduce Key/value, Partition Key 接下来详细分析样例SQL生成OperatorTree的过程 先序遍历上一个阶段生成的QB对象 首先根据子QueryBlock QB2#aliasToTabs {du=dim.user, c=detail.usersequence_client, p=fact.orderpayment}生成TableScanOperator 12TableScanOperator(“dim.user”) TS[0]TableScanOperator(“detail.usersequence_client”) TS[1] TableScanOperator(“fact.orderpayment”) TS[2] 先序遍历QBParseInfo#joinExpr生成QBJoinTree，类QBJoinTree也是一个树状结构，QBJoinTree保存左右表的ASTNode和这个查询的别名，最终生成的查询树如下 12345 base / \ p du / \c p 前序遍历QBJoinTree，先生成detail.usersequence_client和fact.orderpayment的Join操作树 Join to Operator 图中 TS=TableScanOperator RS=ReduceSinkOperator JOIN=JoinOperator 生成中间表与dim.user的Join操作树 Join to Operator 根据QB2 QBParseInfo#destToWhereExpr 生成FilterOperator。此时QB2遍历完成。 下图中SelectOperator在某些场景下会根据一些条件判断是否需要解析字段。 Where to Operator 图中 FIL= FilterOperator SEL= SelectOperator 根据QB1的QBParseInfo#destToGroupby生成ReduceSinkOperator + GroupByOperator GroupBy to Operator 图中 GBY= GroupByOperator GBY[12]是HASH聚合，即在内存中通过Hash进行聚合运算 最终都解析完后，会生成一个FileSinkOperator，将数据写入HDFS FileSinkOperator 图中FS=FileSinkOperator Phase4 逻辑层优化器大部分逻辑层优化器通过变换OperatorTree，合并操作符，达到减少MapReduce Job，减少shuffle数据量的目的。 名称 作用 ② SimpleFetchOptimizer 优化没有GroupBy表达式的聚合查询 ② MapJoinProcessor MapJoin，需要SQL中提供hint，0.11版本已不用 ② BucketMapJoinOptimizer BucketMapJoin ② GroupByOptimizer Map端聚合 ① ReduceSinkDeDuplication 合并线性的OperatorTree中partition/sort key相同的reduce ① PredicatePushDown 谓词前置 ① CorrelationOptimizer 利用查询中的相关性，合并有相关性的Job，HIVE-2206 ColumnPruner 字段剪枝 表格中①的优化器均是一个Job干尽可能多的事情/合并。②的都是减少shuffle数据量，甚至不做Reduce。 CorrelationOptimizer优化器非常复杂，都能利用查询中的相关性，合并有相关性的Job，参考 Hive Correlation Optimizer 对于样例SQL，有两个优化器对其进行优化。下面分别介绍这两个优化器的作用，并补充一个优化器ReduceSinkDeDuplication的作用 PredicatePushDown优化器断言判断提前优化器将OperatorTree中的FilterOperator提前到TableScanOperator之后 PredicatePushDown NonBlockingOpDeDupProc优化器NonBlockingOpDeDupProc优化器合并SEL-SEL 或者 FIL-FIL 为一个Operator NonBlockingOpDeDupProc ReduceSinkDeDuplication优化器ReduceSinkDeDuplication可以合并线性相连的两个RS。实际上CorrelationOptimizer是ReduceSinkDeDuplication的超集，能合并线性和非线性的操作RS，但是Hive先实现的ReduceSinkDeDuplication 譬如下面这条SQL语句 1from (select key, value from src group by key, value) s select s.key group by s.key; 经过前面几个阶段之后，会生成如下的OperatorTree，两个Tree是相连的，这里没有画到一起 ReduceSinkDeDuplication 这时候遍历OperatorTree后能发现前前后两个RS输出的Key值和PartitionKey如下 Key PartitionKey childRS key key parentRS key,value key,value ReduceSinkDeDuplication优化器检测到：1. pRS Key完全包含cRS Key，且排序顺序一致；2. pRS PartitionKey完全包含cRS PartitionKey。符合优化条件，会对执行计划进行优化。 ReduceSinkDeDuplication将childRS和parentheRS与childRS之间的Operator删掉，保留的RS的Key为key,value字段，PartitionKey为key字段。合并后的OperatorTree如下： ReduceSinkDeDuplication Phase5 OperatorTree生成MapReduce Job的过程OperatorTree转化为MapReduce Job的过程分为下面几个阶段 对输出表生成MoveTask 从OperatorTree的其中一个根节点向下深度优先遍历 ReduceSinkOperator标示Map/Reduce的界限，多个Job间的界限 遍历其他根节点，遇过碰到JoinOperator合并MapReduceTask 生成StatTask更新元数据 剪断Map与Reduce间的Operator的关系 对输出表生成MoveTask由上一步OperatorTree只生成了一个FileSinkOperator，直接生成一个MoveTask，完成将最终生成的HDFS临时文件移动到目标表目录下 12MoveTask[Stage-0]Move Operator 开始遍历将OperatorTree中的所有根节点保存在一个toWalk的数组中，循环取出数组中的元素（省略QB1，未画出） 开始遍历 取出最后一个元素TS[p]放入栈 opStack{TS[p]}中 Rule #1 TS% 生成MapReduceTask对象，确定MapWork发现栈中的元素符合下面规则R1（这里用python代码简单表示） 1&quot;&quot;.join([t + &quot;%&quot; for t in opStack]) == &quot;TS%&quot; 生成一个MapReduceTask[Stage-1]对象，MapReduceTask[Stage-1]对象的MapWork属性保存Operator根节点的引用。由于OperatorTree之间之间的Parent Child关系，这个时候MapReduceTask[Stage-1]包含了以TS[p]为根的所有Operator Stage-1 生成Map阶段 Rule #2 TS%.*RS% 确定ReduceWork继续遍历TS[p]的子Operator，将子Operator存入栈opStack中 当第一个RS进栈后，即栈opStack = {TS[p], FIL[18], RS[4]}时，就会满足下面的规则R2 1&quot;&quot;.join([t + &quot;%&quot; for t in opStack]) == &quot;TS%.*RS%&quot; 这时候在MapReduceTask[Stage-1]对象的ReduceWork属性保存JOIN[5]的引用 Stage-1 生成Reduce阶段 Rule #3 RS%.*RS% 生成新MapReduceTask对象，切分MapReduceTask继续遍历JOIN[5]的子Operator，将子Operator存入栈opStack中 当第二个RS放入栈时，即当栈opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6]}时，就会满足下面的规则R3 1&quot;&quot;.join([t + &quot;%&quot; for t in opStack]) == “RS%.*RS%” //循环遍历opStack的每一个后缀数组 这时候创建一个新的MapReduceTask[Stage-2]对象，将OperatorTree从JOIN[5]和RS[6]之间剪开，并为JOIN[5]生成一个子Operator FS[19]，RS[6]生成一个TS[20]，MapReduceTask[Stage-2]对象的MapWork属性保存TS[20]的引用。 新生成的FS[19]将中间数据落地，存储在HDFS临时文件中。 Stage-2 继续遍历RS[6]的子Operator，将子Operator存入栈opStack中 当opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6], JOIN[8], SEL[10], GBY[12], RS[13]}时，又会满足R3规则 同理生成MapReduceTask[Stage-3]对象，并切开 Stage-2 和 Stage-3 的OperatorTree Stage-3 R4 FS% 连接MapReduceTask与MoveTask最终将所有子Operator存入栈中之后，opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6], JOIN[8], SEL[10], GBY[12], RS[13], GBY[14], SEL[15], FS[17]} 满足规则R4 1&quot;&quot;.join([t + &quot;%&quot; for t in opStack]) == “FS%” 这时候将MoveTask与MapReduceTask[Stage-3]连接起来，并生成一个StatsTask，修改表的元信息 MoveTask 合并Stage此时并没有结束，还有两个根节点没有遍历。 将opStack栈清空，将toWalk的第二个元素加入栈。会发现opStack = {TS[du]}继续满足R1 TS%，生成MapReduceTask[Stage-5] Stage-5 继续从TS[du]向下遍历，当opStack={TS[du], RS[7]}时，满足规则R2 TS%.*RS% 此时将JOIN[8]保存为MapReduceTask[Stage-5]的ReduceWork时，发现在一个Map对象保存的Operator与MapReduceWork对象关系的Map&lt;Operator, MapReduceWork&gt;对象中发现，JOIN[8]已经存在。此时将MapReduceTask[Stage-2]和MapReduceTask[Stage-5]合并为一个MapReduceTask 合并 Stage-2 和 Stage-5 同理从最后一个根节点TS[c]开始遍历，也会对MapReduceTask进行合并 合并 Stage-1 和 Stage-6 切分Map Reduce阶段最后一个阶段，将MapWork和ReduceWork中的OperatorTree以RS为界限剪开 切分Map Reduce阶段 OperatorTree生成MapReduceTask全貌最终共生成3个MapReduceTask，如下图 OperatorTree生成MapReduceTask全貌 Phase6 物理层优化器这里不详细介绍每个优化器的原理，单独介绍一下MapJoin的优化器 名称 作用 Vectorizer HIVE-4160，将在0.13中发布 SortMergeJoinResolver 与bucket配合，类似于归并排序 SamplingOptimizer 并行order by优化器，在0.12中发布 CommonJoinResolver + MapJoinResolver MapJoin优化器 MapJoin原理 mapjoin原理 MapJoin简单说就是在Map阶段将小表读入内存，顺序扫描大表完成Join。 上图是Hive MapJoin的原理图，出自Facebook工程师Liyin Tang的一篇介绍Join优化的slice，从图中可以看出MapJoin分为两个阶段： 通过MapReduce Local Task，将小表读入内存，生成HashTableFiles上传至Distributed Cache中，这里会对HashTableFiles进行压缩。 MapReduce Job在Map阶段，每个Mapper从Distributed Cache读取HashTableFiles到内存中，顺序扫描大表，在Map阶段直接进行Join，将数据传递给下一个MapReduce任务。 conditionaltask 如果Join的两张表一张表是临时表，就会生成一个ConditionalTask，在运行期间判断是否使用MapJoin CommonJoinResolver优化器CommonJoinResolver优化器就是将CommonJoin转化为MapJoin，转化过程如下 深度优先遍历Task Tree 找到JoinOperator，判断左右表数据量大小 对与小表 + 大表 =&gt; MapJoinTask，对于小/大表 + 中间表 =&gt; ConditionalTask 遍历上一个阶段生成的MapReduce任务，发现MapReduceTask[Stage-2] JOIN[8]中有一张表为临时表，先对Stage-2进行深度拷贝（由于需要保留原始执行计划为Backup Plan，所以这里将执行计划拷贝了一份），生成一个MapJoinOperator替代JoinOperator，然后生成一个MapReduceLocalWork读取小表生成HashTableFiles上传至DistributedCache中。 mapjoin变换 MapReduceTask经过变换后的执行计划如下图所示 mapjoin变换 MapJoinResolver优化器MapJoinResolver优化器遍历Task Tree，将所有有local work的MapReduceTask拆成两个Task MapJoinResolver 最终MapJoinResolver处理完之后，执行计划如下图所示 MapJoinResolver Hive SQL编译过程的设计从上述整个SQL编译的过程，可以看出编译过程的设计有几个优点值得学习和借鉴 使用Antlr开源软件定义语法规则，大大简化了词法和语法的编译解析过程，仅仅需要维护一份语法文件即可。 整体思路很清晰，分阶段的设计使整个编译过程代码容易维护，使得后续各种优化器方便的以可插拔的方式开关，譬如Hive 0.13最新的特性Vectorization和对Tez引擎的支持都是可插拔的。 每个Operator只完成单一的功能，简化了整个MapReduce程序。 社区发展方向Hive依然在迅速的发展中，为了提升Hive的性能，hortonworks公司主导的Stinger计划提出了一系列对Hive的改进，比较重要的改进有： Vectorization - 使Hive从单行单行处理数据改为批量处理方式，大大提升了指令流水线和缓存的利用率 Hive on Tez - 将Hive底层的MapReduce计算框架替换为Tez计算框架。Tez不仅可以支持多Reduce阶段的任务MRR，还可以一次性提交执行计划，因而能更好的分配资源。 Cost Based Optimizer - 使Hive能够自动选择最优的Join顺序，提高查询速度 Implement insert, update, and delete in Hive with full ACID support - 支持表按主键的增量更新 我们也将跟进社区的发展，结合自身的业务需要，提升Hive型ETL流程的性能 参考HiveSQL编译过程https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html Antlr: http://www.antlr.org/ Wiki Antlr介绍: http://en.wikipedia.org/wiki/ANTLR Hive Wiki: https://cwiki.apache.org/confluence/display/Hive/Home HiveSQL编译过程: http://www.slideshare.net/recruitcojp/internal-hive Join Optimization in Hive: Join Strategies in Hive from the 2011 Hadoop Summit (Liyin Tang, Namit Jain) Hive Design Docs: https://cwiki.apache.org/confluence/display/Hive/DesignDocs 版权声明： 除非注明，本博文章均为原创，转载请以链接形式标明本文地址。]]></content>
      <tags>
        <tag>hive</tag>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DB2 performance Optimization]]></title>
    <url>%2F2019%2F10%2F14%2FDB2-performance-Optimization%2F</url>
    <content type="text"><![CDATA[# 提高 DB2 查询性能的常用方法 提高DB2查询性能的常用方法将着重介绍如何使用 Visual Explain 和 db2expln 查看动态查询的存取计划。读者可以查阅 DB2 Info Center 获得有关查看静态查询存取计划的内容。 DB2 Visual ExplainDB2 提供了非常直观有效的方法来查看查询的存取计划。DB2 Visual Explain 能够获得可视化的查询计划，而 db2expln 命令则可以获得文本形式的查询计划。有了查询计划，我们就可以有针对的对查询进行优化。根据查询计划找出代价最高的扫描 ( 表扫描，索引扫描等 ) 和操作 (Join，Filter，Fetch 等 )，继而通过改写查询或者创建索引消除代价较高的扫描或操作来优化查询。 DB2 提供了多种方法来得到可视化查询计划。 通过 DB2 Control Center 获得可视化查询计划。如图 1： 图 1. 可视化查询计划 点击”Explain SQL”后输入要进行分析的查询语句以及查询标号和标签，点击 Ok 按钮便可得到可视化的查询计划。此时，查询计划会被存储在系统的 Explain 表中。用户可以通过图 1 中的”Show Explained Statements History”命令获得存储在 Explain 表中的所有查询计划。 通过 Command Editor( 在 DB2 8.2 版本之前叫做 Command Center) 获得可视化的查询计划。如图 2： 图 2. 获得可视化的查询计划 在主窗口输入查询并连接数据库后，点击图中所示的按钮即可得到可视化的查询计划，如图 3： 图 3. 查询计划结果 在图 3 所示的查询计划中，还可以点击图示中的每个节点来察看详细的统计信息。譬如双击节点”FETCH(13) 21,959.75” 后将会弹出如图 4 所示的对话框： 图 4. 详细的统计信息 图 4 中的统计信息主要包括此 FETCH 操作的总代价，CPU，I/O 以及获得结果集中的第一行的代价。在这里，timerons 是结合了 CPU 和 I/O 代价的成本单位。此外，图 4 中还收集了其他相关信息。譬如此操作读取了哪个表的哪些列，每个谓词的选择度 (selectivity)，使用了多少 buffer 等等。 db2exfmt db2exfmt 命令能够将 Explain 表中存储的存取计划信息以文本的形式进行格式化输出。db2exfmt 命令将各项信息更为直观的显示，使用起来更加方便。命令如清单 1 所示： 清单 1. db2exfmt 命令 1234567db2exfmt -d &lt;``db_name``&gt; -e &lt;``schema``&gt; -g T -o &lt;``output``&gt; -u &lt;``user``&gt; &lt;``password``&gt; -w &lt;``timestamp``&gt;Example: db2exfmt -d test_db -e user -g T -o D:\temp\sql_1_result_db2exfmt.txt ``-u user password -w lQuery: ``sql_1.txt（附件中） ``Results: ``sql_1_result_db2exfmt.txt（附件中） db2expln db2expln 是命令行下的解释工具，和前面介绍的 Visual Explain 功能相似。通过该命令可以获得文本形式的查询计划。命令如清单 2 所示 : 清单 2. db2expln 命令 1db2expln -d &lt;``db_name``&gt; -user &lt;``user``&gt; &lt;``password``&gt; -stmtfile &lt;``sql.file``&gt;`` ``-z @ -output &lt;``output``&gt; -g``Example: db2expln -d test_db -user user password -stmtfile D:\temp\sql_1.txt`` ``-z @ -output D:\temp\sql_1_result_db2expln.txt –g``Query:`` ``sql_1.txt（附件中）`` ``Results:`` ``sql_1_result_db2expln.txt（附件中） db2expln 将存取计划以文本形式输出，它只提供存取计划中主要的信息，并不包含每一个操作占用多少 CPU、I/O、占用 Buffer 的大小以及使用的数据库对象等信息，方便阅读。但是 db2expln 也会将各项有关存取计划的信息存入 Explain 表中，用户可以使用 db2exfmt 察看详细的格式化文本信息。 db2advis db2advis 是 DB2 提供的另外一种非常有用的命令。通过该命令 DB2 可以根据优化器的配置以及机器性能给出提高查询性能的建议。这种建议主要集中于如何创建索引，这些索引可以降低多少查询代价，需要创建哪些表或者 Materialized Query Table(MQT) 等。命令如清单 3 所示： 清单 3. db2advis 命令 1db2advis -d &lt;``db_name``&gt; -a &lt;``user``&gt;/&lt;``password``&gt; -i &lt;``sql.file``&gt; -o &lt;``output``&gt;``Example: db2advis -d test_db -a user/password`` ``-i D:\temp\sql_2.txt &gt; D:\temp\sql_2_result_db2advis.txt``Query:`` ``sql_2.txt（附件中）`` ``Results:`` ``sql_2_result_db2advis.txt（附件中） 通过 -i 指定的 SQL 文件可以包含多个查询，但是查询必须以分号分隔。这与 db2expln 命令不同，db2expln 可以通过 -z 参数指定多个查询之间的分隔符。用户可以把某一个 workload 中所使用的所有查询写入 SQL 文件中，并在每个查询之前使用”–#SET FREQUENCY ”为其指定在这个 workload 中的执行频率。db2advis 会根据每个查询在这个 workload 的频率指数进行权衡来给出索引的创建建议，从而达到整个 workload 的性能最优。 db2batch 前面介绍的工具和命令只提供了查询的估算代价，但有些时候估算代价和实际的执行时间并不是完全呈线形关系，有必要实际执行这些查询。db2batch 就是这样一个 Benchmark 工具，它能够提供从准备到查询完成中各个阶段所花费地具体时间，CPU 时间，以及返回的记录。命令如清单 4 所示： 清单 4. db2batch 命令 1db2batch -d &lt;``db_name``&gt; -a &lt;``user``&gt;/&lt;``password``&gt;`` ``-i &lt;``time_condition``&gt; -f &lt;``sql.file``&gt; -r &lt;``output``&gt;``Example: db2batch -d test_db -a user/password`` ``-i complete -f D:\temp\sql_3.txt -r d:\temp\sql_3_result_db2batch.txt``Query:`` ``sql_3.txt（附件中）`` ``Results:`` ``sql_3_result_db2batch.txt（附件中） 对于执行 db2batch 时一些详细的设置可以通过 -o 参数指定，也可以在 SQL 文件中指定，譬如本例中在 SQL 文件中使用了下面的配置参数 : –#SET ROWS_FETCH -1 ROWS_OUT 5 PERF_DETAIL 1 DELIMITER @ TIMESTAMP 其中 ROWS_FETCH 和 ROWS_OUT 定义了从查询的结果集中读取记录数和打印到输出文件中的记录数，PERF_DETAIL 设置了收集性能信息的级别，DELIMITER 则指定了多个查询间的间隔符。 提高查询性能的常用方法 下面我们将从三个方面介绍一些提高查询性能的方法。 创建索引 根据查询所使用的列建立多列索引 建立索引是用来提高查询性能最常用的方法。对于一个特定的查询，可以为某一个表所有出现在查询中的列建立一个联合索引，包括出现在 select 子句和条件语句中的列。但简单的建立一个覆盖所有列的索引并不一定能有效提高查询，因为在多列索引中列的顺序是非常重要的。这个特性是由于索引的 B+ 树结构决定的。一般情况下，要根据谓词的选择度来排列索引中各列的位置，选择度大的谓词所使用的列放在索引的前面，把那些只存在与 select 子句中的列放在索引的最后。譬如清单 5 中的查询： 清单 5. 索引中的谓词位置 1select add_date``from temp.customer``where city = &apos;WASHINGTON&apos;``and cntry_code = &apos;USA&apos;; 对于这样的查询可以在 temp.customer 上建立 (city，cntry_code，add_date) 索引。由于该索引包含了 temp.customer 所有用到的列，此查询将不会访问 temp.customer 的数据页面，而直接使用了索引页面。对于包含多列的联合索引，索引树中的根节点和中间节点存储了多列的值的联合。这就决定了存在两种索引扫描。回到清单 5 中的查询，由于此查询在新建索引的第一列上存在谓词条件，DB2 能够根据这个谓词条件从索引树的根节点开始遍历，经过中间节点最后定位到某一个叶子节点，然后从此叶子节点开始往后进行在叶子节点上的索引扫描，直到找到所有满足条件的记录。这种索引扫描称之为 Matching Index Scan。但是如果将 add_date 放在索引的第一个位置，而查询并不存在 add_date 上的谓词条件，那么这个索引扫描将会从第一个索引叶子节点开始，它无法从根节点开始并经过中间节点直接定位到某一个叶子节点，这种扫描的范围扩大到了整个索引，我们称之为 Non-matching Index Scan。图 5 显示了 DB2 根据不同索引生成的存取计划。 图 5. 根据不同索引生成的存取计划 根据条件语句中的谓词的选择度创建索引 因为建立索引需要占用数据库的存储空间，所以需要在空间和时间性能之间进行权衡。很多时候，只考虑那些在条件子句中有条件判断的列上建立索引会也会同样有效，同时节约了空间。譬如清单 5 中的查询，可以只建立 (city，cntry_code) 索引。我们还可以进一步地检查条件语句中的这两个谓词的选择度，执行清单 6 中的语句检查谓词选择度： 清单 6. 检查谓词选择度 1Queries:``1. select count(*) from temp.customer``where city = &apos;WASHINGTON&apos;``and cntry_code = &apos;USA&apos;;``2. select count(*) from temp.customer``where city = &apos;WASHINGTON&apos;;``3. select count(*) from temp.customer``where cntry_code = &apos;USA&apos;;``Results:``1. 1404``2. 1407``3. 128700 选择度越大，过滤掉的记录越多，返回的结果集也就越小。从清单 6 的结果可以看到，第二个查询的选择度几乎有和整个条件语句相同。因此可以直接建立单列索引 (city)，其性能与索引 (city，cntry_code，add_date) 具有相差不多的性能。表 1 中对两个索引的性能和大小进行了对比。 表 1. 两个索引的性能和大小对比 索引 查询计划总代价 索引大小 cust_i1(city，cntry_code，add_date) 28.94 timerons 19.52M cust_i3(city) 63.29 timerons 5.48M 从表 1 中可以看到单列索引 (city) 具有更加有效的性能空间比，也就是说占有尽可能小的空间得到尽可能高的查询速度。 避免在建有索引的列上使用函数 这是一个很简单的原则，如果在建有索引的列上使用函数，由于函数的单调性不确定，函数的返回值和输入值可能不会一一对应，就可能存在索引中位置差异很大的多个列值可以满足带有函数的谓词条件，因此 DB2 优化器将无法进行 Matching Index Scan，更坏的情况下可能会导致直接进行表扫描。图 6 中对比了使用 function 前后的存取计划的变化。 图 6. 使用 function 前后的存取计划的变化 在那些需要被排序的列上创建索引 这里的排序不仅仅指 order by 子句，还包括 distinct 和 group by 子句，他们都会产生排序的操作。由于索引本身是有序的，在其创建过程中已经进行了排序处理，因此在应用这些语句的列上创建索引会降低排序操作的代价。这种情况一般针对于没有条件语句的查询。如果存在条件语句，DB2 优化器会首先选择出满足条件的纪录，然后才对中间结果集进行排序。对于没有条件语句的查询，排序操作在总的查询代价中会占有较大比重，因此能够较大限度的利用索引的排序结构进行查询优化。此时可以创建单列索引，如果需要创建联合索引则需要把被排序的列放在联合索引的第一列。图 7 对比了清单 7 中的查询在创建索引前后的存取计划。 清单 7. 查询在创建索引前后的存取计划 1select distinct add_date from temp.customer; 图 7. 在创建索引前后的存取计划 从图 7 中我们可以看到在没有索引的情况下 SORT 操作是 24751.69 timerons，但是有索引的情况下，不再需要对结果集进行排序，可以直接进行 UNIQUE 操作，表中显示了这一操作只花费了 2499.98 timerons. 图 8 对比了清单 8 中的查询在创建联合索引前后的存取计划，从中可以更好的理解索引对排序操作的优化。 清单 8. 查询示例 1select cust_name from temp.customer order by add_date; 图 8. 创建联合索引前后的存取计划 索引的 B+ 树结构决定了索引 temp.cust_i5 的所有叶子节点本身就是按照 add_date 排序的，所以对于清单 8 中的查询，只需要顺序扫描索引 temp.cust_i5 的所有叶子节点。但是对于 temp.cust_i6 索引，其所有叶子节点是按照 cust_name 排序，因此在经过对索引的叶子节点扫描获得所有数据之后，还需要对 add_date 进行排序操作。 合理使用 include 关键词创建索引 对于类似下面的查询 : 清单 9. 查询示例 1select cust_name from temp.customer``where cust_num between &apos;0007000000&apos; and &apos;0007200000&apos; 在第一点中我们提到可以在 cust_num 和 cust_name 上建立联合索引来提高查询性能。但是由于 cust_num 是主键，可以使用 include 关键字创建唯一性索引： create unique index temp.cust_i7 on temp.customer(cust_num) include (cust_name) 使用 include 后，cust_name 列的数据将只存在于索引树的叶子节点，并不存在于索引的关键字中。这种情况下，使用带有 include 列的唯一索引会带来优于联合索引的性能，因为唯一索引能够避免一些不必要的操作，如排序。对于清单 9 中的查询创建索引 temp.cust_i7 后存取计划的代价为 12338.7 timerons，创建联合索引 temp.cust_i8(cust_num，cust_name) 后的代价为 12363.17 timerons。一般情况下，当查询的 where 子句中存在主键的谓词我们就可以创建带有 include 列的唯一索引，形成纯索引访问来提高查询性能。注意 include 只能用在创建唯一性索引中。 指定索引的排序属性 对于下面用来显示最近一个员工入职的时间的查询： select max(add_date) from temp.employee 很显然这个查询会进行全表扫描。查询计划如图 9.a: 图 9. 查询计划 显然我们可以在 add_date 上创建索引。根据下面的命令创建索引后的查询计划如图 9.b。 create index temp.employee_i1 on temp.employee(add_date) 这里存在一个误区，大家可能认为既然查询里要取得的是 add_date 的最大值，而我们又在 add_date 上建立了一个索引，优化器应该知道从索引树中直接去寻找最大值。但是实际情况并非如此，因为创建索引的时候并没有指定排序属性，默认为 ASC 升序排列，DB2 将会扫描整个索引树的叶子节点取得所有值后，然后取其最大。我们可以通过设置索引的排序属性来提高查询性能，根据下面的命令创建索引后的查询计划如图 9.c。 create index temp.employee_i1 on temp.employee(add_date desc) 对于降序排列的索引，DB2 不需要扫描整个索引数的叶子节点，因为第一个节点便是最大的。我们同样可以使用 ALLOW REVERSE SCANS 来指定索引为双向扫描，具有和 DESC 近似的查询性能。ALLOW REVERSE SCANS 可以被认为是 ASC 和 DESC 的组合，只是在以后数据更新的时候维护成本会相对高一些。 如果无法改变索引的排序属性，但是我们具有额外的信息，该公司每个月都会有新员工入职，那么这个查询就可以改写成： select max(add_date) from temp.employee where add_date &gt; current timestamp - 1 month 这样通过限定一个查询范围也会有效地提高查询性能。 索引和表的维护 重新组织索引 随着数据的不断删除，插入和更新，索引页会变得越来越零散，索引页的物理存储顺序不再匹配其逻辑顺序，索引结构的层次会变得过大，这些都会导致索引页的预读取变得效率低下。因此，根据数据更新的频繁程度需要适当的重新组织索引。可以使用 REORG INDEXES 命令来重新组织索引结构，也可以删除并重新创建索引达到相同的目的。同样的，对表进行重新组织也会带来性能的改善。 重新组织某一个表的所有索引的命令如下：REORG INDEXES ALL FOR TABLE table_name。 重新组织一个表的数据的命令如下，在下面的命令还可以为其指定一个特定的索引，REORG 命令将会根据这个索引的排序方式重新组织该表的数据。 REORG TABLE table_name INDEX index_name。 重新收集表和索引的统计信息 和在 2.1 中提到的原因类似，当一个表经过大量的索引修改、数据量变化或者重新组织后，可能需要重新收集表以及相关索引的统计信息。这些统计信息主要是关于表和索引存储的物理特性，包括记录数目，数据页的数目以及记录的平均长度等。优化器将根据这些信息决定使用什么样的存取计划来访问数据。因此，不能真实反映实际情况的统计信息可能会导致优化器选择错误的存取计划。收集表及其所有索引的统计信息的命令如下：RUNSTATS ON TABLE table_name FOR INDEXES ALL。 上述两个命令具有复杂的参数选择，用户可以参阅 DB2 Info Center 来根据实际情况使用这两个命令。 修改查询 合理使用 NOT IN 和 NOT EXISTS 一般情况下 NOT EXISTS 具有快于 NOT IN 的性能，但是这并不绝对。根据具体的数据情况、存在的索引以及查询的结构等因素，两者会有较大的性能差异，开发人员需要根据实际情况选择适当的方式。 譬如下面的查询： 清单 10. 查询示例 1表结构：temp.customer(cust_num) 主键：cust_num``表结构：temp.contact(cnt_id，cust_num) 主键：cnt_id``表结构：temp.contact_detail(cnt_id，address，phone) 主键：cnt_id``查询 :``select cust_num``from temp.customer cust``where not exists (select 1 from temp.contact cont``here cust.cust_num = cont.cust_num) 此查询用来列出所有不存在联系人的客户。对于这样的需求，开发人员会最自然的写出清单 10 中的查询，的确，对于大部分情况它具有最优的性能。该查询的查询代价为 178,430 timerons。让我们再来看看使用 NOT IN 后查询的总代价，请看清单 11。 清单 11. 查询示例 1查询：``select cust_num``from temp.customer cust``where cust.cust_num not in (select cont.cust_num from temp.contact cont)``代价：12,648,897,536 timerons 可以看到 NOT EXISTS 的性能要比 NOT IN 高出许多。NOT IN 是自内向外的操作，即先得到子查询的结果，然后执行最外层的查询，而 NOT EXISTS 恰好相反，是自外向内的操作。在上述例子中，temp.contact 表中有 65 万条记录，使得 10.2 查询中的 NOT IN 列表非常大，导致了使用 NOT IN 的查询具有非常高的查询代价。下面我们对 10.1 和 10.2 的查询进行修改，将 temp.contact 表中的记录限制到 100 条，请看下面的查询： 清单 12. 查询示例 1查询：``select cust_num``from temp.customer cust``where not exists (select 1 from temp.contact cont``here cust.cust_num = cont.cust_num``and cont.cnt_id &lt; 100)``代价：42,015 timerons 清单 13. 查询示例 1查询：``select cust_num``from temp.customer cust``where cust.cust_num not in (select cont.cust_num from temp.contact cont``where cont.cnt_id &lt; 100)``代价：917,804 timerons 从 12 和 13 中可以看出 NOT EXISTS 的查询代价随子查询返回的结果集的变化没有大幅度的下降，随着子查询的结果集从 65 万下降到 100 条，NOT EXISTS 的查询代价从 178,430 下降到 42,015，只下降 4 倍。但是 NOT IN 的查询代价却有着极大的变化，其查询代价从 12,648,897,536 下降到 917,804，下降了 13782 倍。可见子查询的结果集对 NOT IN 的性能影响很大，但是这个简单的查询不能说明 NOT EXISTS 永远好于 NOT IN，因为同样存在一些因素对 NOT EXISTS 的性能有很大的影响。我们再看下面的例子： 清单 14. 查询示例 1查询：``select cust_num``from temp.customer cust``where not exists (select 1 from temp.contact cont``where cust.cust_num = cont.cust_num``and cont.cnt_id in (select cnt_id from temp.contact_detail``where cnt_id&lt;100))``代价：5,263,096 timerons 清单 15. 查询示例 1查询：``select cust_num``from temp.customer cust``where cust_num not in (select cust_num from temp.contact cont``where cont.cnt_id in (select cnt_id from temp.contact_detail``where cnt_id&lt;100))``代价：4,289,095 timerons 在上面的例子中，我们只是对查询增加了一个小改动，使用一个嵌套查询限制了在 temp.contact 中扫描的范围。但是在这两个新的查询中，NOT IN 的性能却又好于 NOT EXISTS。NOT EXISTS 的代价增加了 125 倍，而 NOT IN 的代价却只增加了 4 倍。这是由于 NOT EXISTS 是自外向内，嵌套查询的复杂度对其存在较大的影响。因此在实际应用中，要考虑子查询的结果集以及子查询的复杂度来决定使用 NOT EXISTS 或者 NOT IN。对于 IN，EXISTS 和 JOIN 等操作，大多数情况下 DB2 优化器都能形成比较一致的最终查询计划。 合理使用子查询减少数据扫描和利用索引 某些情况下可以将查询中的某一部分逻辑提取出来作为子查询出现，能够减少扫描的数据量，以及利用索引进行数据检索。请看清单 16 中的查询： 清单 16. 1索引：temp.cust_i1 on temp.customer(add_date)``temp.order_i1 on temp.order(sold_to_cust_num)``temp.order_i2 on temp.order(add_date)``查询：``select cust.cust_num``from temp.customer cust``left join temp.order ord``on cust.cust_num = ord.sold_to_cust_num``where cust.add_date &gt; current timestamp - 2 months``or ord.add_date &gt; current timestamp - 2 months 上面的查询用来选择所有两个月内新增加的用户以及在两个月内定购了产品的用户。从图 10.a 的查询计划中可看出没有任何索引被使用。 图 10. 查询计划 使用子查询对该查询重新改写后，请看清单 17: 清单 17. 1查询：``with tmp as(``select sold_to_cust_num from temp.order ``where add_date &gt; current timestamp - 2 months)``select cust.cust_num from temp.customer cust``where cust.add_date &gt; current timestamp - 2 months``or cust.cust_num in (select sold_to_cust_num from tmp ) 在清单 17 的查询中，我们使用子查询预先限定了要扫描 temp.order 表中的记录数目，而不是像清单 16 中的查询那样对 temp.order 表进行全表扫描。同时，在预先限定数据范围的时候，能够利用 temp.order_i2 索引。请看其查询计划，如图 10.b。可以看到查询代价有大幅度下降。其实，即使没有 temp.order_i2 索引，修改后的查询也仍然由于前者，因为它预先限定了数据的扫描范围，也减少了后续连接处理的数据量，请看图 10.c。 重新排列各个表的连接顺序，尽量减小中间结果集的数据量 一般情况下，DB2 会根据各表的 JOIN 顺序自顶向下顺序处理，因此合理排列各表的连接顺序会提高查询性能。譬如清单 18 中的查询： 清单 18. 1查询：``select cust.cust_name, ord.order_num, cnt.cnt_first_name``from temp.customer cust``left join temp.order ord``on cust.cust_num = ord.sold_to_cust_num``join temp.contact cnt``on cust.cust_num = cnt.cust_num``where cnt.mod_date &gt; current timestamp - 1 months 清单 18 中的查询用来选择出所有最近一个月内修改过联系人信息的客户的订单信息。此查询会按照链接的顺序先将 temp.customer 表和 temp.order 表进行 LEFT JOIN，然后使用结果集去 JOIN temp.contact 表。由于该查询使用了 LEFT JOIN，因此在生成中间结果集的时候不会有任何记录会被过滤掉，中间结果集的记录数目大于等于 temp.customer 表。了解到了 DB2 是如何解释和执行这样的查询后，很自然的我们就会想到将 JOIN 提前。请看清单 19。 清单 19. 1查询：``select cust.cust_name, ord.order_num, cnt.cnt_first_name``from temp.customer cust``join temp.contact cnt``on cust.cust_num = cnt.cust_num``left join temp.order ord``on cust.cust_num = ord.sold_to_cust_num``where cnt.mod_date &gt; current timestamp - 1 months 图 11.a 和图 11.b 分别为清单 18 和 19 的查询的存取计划。在 19 的查询中，在形成中间结果集的时候也应用到了 WHERE 语句中的条件，而不是在所有 JOIN 都结束以后才被应用去除记录的。 图 11. 查询计划 另外，在修改查询尽量减少中间结果集的记录条数的时候还要考虑中间结果集的数据总量，譬如中间结果集需要保存的每条记录的长度。如果我们把 JOIN temp.contact 提前以后，由于中间结果集需要保存过多的 contact 表的列反而使得结果集的数据总量变大，可能不会带来性能上的改善。 使用 UDF 代替查询中复杂的部分 由于 UDF 是预先编译的，性能普遍优于一般的查询，UDF 使用的存取计划一经编译就会相对稳定。笔者在工作中曾多次发现，使用 UDF 代替查询或者视图中的复杂部分会提高几倍甚至几十倍的性能，主要原因是迫使 DB2 使用指定的存取计划来充分利用 index 或者调整其访问过程（如 Join 顺序， Filter 位置等）。使用 UDF 进行优化的基本思路是，将复杂查询分解为多个部分执行，针对每个部分优化处理，将各部分组合时能够避免存取计划的一些不必要变化，优化整体性能。譬如清单 20 中的查询： 清单 20. 1查询：select * from temp.customer where cust_num in (``select distinct sold_to_cust_num from temp.order``where add_date &gt; current timestamp - 2 months``union``select distinct cust_num from temp.contact``where add_date &gt; current timestamp - 2 months``) 这个查询会导致优化器生成比较复杂的查询计划，尤其是 temp.customer 是一个比较复杂的视图的时候。这种情况下我们可以通过创建 UDF，将其分步执行：先执行子查询获得 cust_num 值的列表，然后执行最外层的查询。下面的例子是通过 UDF 对清单 20 的查询的改写： 清单 21. 1CREATE FUNCTION temp.getCustNum(p_date timestamp)``RETURNS``TABLE (cust_num CHARACTER(10))``RETURN``select distinct sold_to_cust_num from temp.order``where add_date &gt; p_date``union``select distinct cust_num from temp.contact``where add_date &gt; p_date;``select * from customer where cust_num in (``select cust_num from table(temp.getCustNum(current timestamp - 2 months)) tbl``) 改写前后的查询代价分别是 445,159.31 和 254,436.98。当面对比较复杂的查询时考虑使用 UDF 将其拆分为多步执行常常会带来意想不到的效果。在实际的项目中，如果数据处理和查询调用是包含在其他应用程序中如 Unix 脚本，Java 程序等，同样可以考虑采用分步数据处理的方式来调用数据库，以优化应用性能。 总结 本文主要介绍了如何使用 DB2 提供的各种查看存取计划的工具，并根据作者在 DB2 方面的开发经验总结了一些提高查询性能的方法和技巧。如果能够有效地利用 DB2 提供的各种工具，理解 DB2 中索引的结构，以及查询将如何被解释，数据库开发人员可以更好的提高查询性能来满足需求。 版权声明： 除非注明，本博文章均为原创，转载请以链接形式标明本文地址。]]></content>
      <tags>
        <tag>sql</tag>
        <tag>Optimization</tag>
        <tag>db2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mxLibraryLog]]></title>
    <url>%2F2019%2F10%2F07%2FmxLibraryLog%2F</url>
    <content type="text"></content>
      <tags>
        <tag>self-study</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有梦就有远方]]></title>
    <url>%2F2019%2F10%2F07%2Fsnaillife%2F</url>
    <content type="text"><![CDATA[有梦才有远方 雪夜茫茫，你知道一棵小草的梦吗？寒冷孤寂中，她怀抱一个信念取暖，等到村归大地时，她就会以两片绿叶问候春天，而那两片绿叶，就是曾经在雪地下轻轻地梦呓。 &gt; 候鸟南飞，征途迢迢，他的梦呢?在远方，在视野里，那是南方湛蓝的大海。她很累很累，但依然往前奋飞。因为梦又赐予她另一对翅膀。 &gt; 窗前托腮凝思的少女，你是想做一朵云的诗，还是做一只蝶的画？ &gt; 风中奔跑的翩翩的少年，你是想做一只鹰，与天比高，还是做一条壮阔的长河，为大地抒怀? &gt; 我喜欢做梦。梦让我看到窗外的阳光，梦让我看到天边的彩霞，梦给我不变的召唤于步伐，梦引领我去追逐一个又一个目标。&gt; 1952年，一个叫查克贝瑞的美国青年，做了这么一个梦：超越贝多芬!并把这个消息告诉柴可夫斯基。多年以后，他成功了，成为摇滚音乐的奠基人之一。梦赋予他豪迈的宣言，梦也引领他走向光明的大道。梦启发了他的初心，他则用成功证明了梦的真实与壮美-——因为有了梦，才有了梦想；有了梦想，才有了理想；有了理想，才有了理想而奋斗的人生历程。 &gt; 没有泪水的人，他的眼睛是干涸的； &gt; 没有梦的人，他的夜晚是黑暗的。 &gt; 太阳总是在有梦的地方升起，月亮总是在有梦的地方朦胧。梦是永恒的微笑，使你的心灵永远充满激情，使你的双眼永远澄澈明亮。 &gt; 世界的万花筒散着诱人的清香，未来的天空下也传来迷人的歌唱。我们整装待发 ,用美梦打扮，从实干出发，等到我们抵达秋天的果园，轻轻地擦去夏天留在我们脸上的汗水与灰尘时，我们就可以听得见曾经对春天说过的那句话 ：美梦成真！]]></content>
      <categories>
        <category>dream</category>
      </categories>
      <tags>
        <tag>梦想</tag>
        <tag>破晓</tag>
        <tag>古月山风</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F10%2F07%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
</search>
