<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[chapter3-dynamic-algorithm]]></title>
    <url>%2F2020%2F02%2F19%2Fchapter3-dynamic-algorithm%2F</url>
    <content type="text"><![CDATA[chapter3-dynamic-algorithm参考链接 [TOC] 斐波那契数列 爬楼梯123456789101112131415161718192021222324252627282930313233import sysimport mathimport functoolsdef climbStairs(n): # 递归的方法就是遍历每一次方法， # 直接最后两步或者一部的时候计数计科。 # 就像一颗树，每次减去1和2构成两个分支，依次类推，直到所有的叶子节点为1和2为止 # 这就是递归，自定向上的逻辑方法 def dg_c(n): if n == 1: return 1 if n == 2: return 2 else: return dg_c(n-1) + dg_c(n-2) print(dg_c(n)) # 动态规划，对于每一次上台阶的次数，都是上两次方法之和 # 比如'3'的次数是'2'和'1'的次数和就是3次。 # 因此只需要构建前两次flag 进行记录 依次往前推，就可以计算出，最终结果 # 这就是动态规划，自底向上的逻辑方法 def dy_c(n): pre1,pre2 = 2,1 if n &lt;= 2: return n for i in range(2,n,1): cur = pre1 + pre2 pre2 = pre1 pre1 = cur print(pre1,pre2) print(pre1) dy_c(n)climbStairs(4) 强盗抢劫123456789101112131415161718192021222324252627def rob(nums): # 抢劫一排住户，但是不能抢邻近的住户，求最大抢劫量。 # 不能够抢劫相邻的住户，意思对于i来说，如果要这个物品，我们就不能够要i-1的物品 # 因此,代码如下，代码实现逻辑难点，在于如何记录不相邻数据之和 def rob1(nums): n = len(nums) if n &lt;= 2: if n == 0: return 0 return max(nums) db = [i for i in nums] db[1] = max(nums[0],nums[1]) for i in range(2,n): db[i] = max(db[i-1], db[i-2] + nums[i]) print(db[-1]) #优化空间，只需要累计后前后两个数即可，由上分析可得出 def rob2(nums): pre1, pre2 = 0, 0 for i in range(len(nums)): cur = max(pre2+nums[i],pre1) pre2 = pre1 pre1 = cur print(pre1) rob2(nums) rob1(nums)rob([8,7,9,23,1]) 强盗在环形街区抢劫12345678910111213141516171819def rob_II(nums) -&gt; int: # 相比较上一题，这一题，房子的排列组成了一环，以为这第一房子和最后一个房子是相邻的。 # 也意味着每一个位置都能够成为起点 n = len(nums) if n &lt;= 2: if n == 0: return 0 return max(nums) def rob(nums, first, last): pre1, pre2 = 0, 0 for i in range(first,last): cur = max(pre2+nums[i],pre1) pre2 = pre1 pre1 = cur return pre1 res = max(rob(nums,0, n-1),rob(nums,1,n)) print(res) return res rob_II([8,7,9,23,1]) 母牛生产12345678910#假设农场中成熟的母牛每年都会生 1 头小母牛，并且永远不会死。第一年有 1 只小母牛，从第二年开始，# 母牛开始生小母牛。每只小母牛 3 年之后成熟又可以生小母牛。给定整数 N，求 N 年后牛的数量。#今年的母牛=去年母牛的数量和三年前母牛的数量def cownum(N): def dg_c(N): if N &lt;= 1: return 1 return dg_c(N-1)+dg_c(N-3) print(dg_c(N))cownum(7) 矩阵路径 矩阵的最小路径和123456789101112131415161718192021222324252627282930313233343536373839404142434445# 求从矩阵的左上角到右下角的最小路径和，每次只能向右和向下移动。def minPathSum(grid) -&gt; int: # 由题意可知，从矩阵的左上角到右下角的最小路径和，因此每次路径的数，与之相关的只有这个数的向上一个和左边一个， # 即如果这个数为grid[i][j],关联的数为grid[i-1][j] ,grid[i][j-1] 但是对于矩阵来说是有边界的， # 所以要解决如何遍历边界的值，也就是i和j等于0的时候 # 由于矩阵每次关联的只有上一行的数据，所以临时存储只需要一行的列表即可 def mps1(grid): db = [i for i in grid[0]] a = 0 for i,v in enumerate(db): a += v db[i] = a for i in range(1,len(grid)): for j in range(len(grid[0])): try: db[j] = min(db[j-1],db[j]) + grid[i][j] except: db[j] = min(999999, db[ j ]) + grid[i][j] print(db[-1]) def mps2(grid): m, n = len(grid), len(grid[0]) if m == 0 or n == 0: return 0 dp = [0 for i in grid[0]] for i in range(m): for j in range(n): if j == 0: dp[j] = dp[j] elif i == 0: dp[j] = dp[j-1] else: dp[j] = min(dp[j-1],dp[j]) dp[j] += grid[i][j] print(dp[-1]) mps1(grid) mps2(grid)grid = [ [1,3,1], [1,5,1], [4,2,1] ]minPathSum(grid) 矩阵的总路径数12345678910111213141516171819202122232425262728293031323334# 统计从矩阵左上角到右下角的路径总数，每次只能向右或者向下移动def uniquePaths(): # 又题意可知，每次只能向右或者向下移动。因此 # 对于一个矩阵来说，到位置grid[i][j],是grid[i-1][j]和grid[i][j-1]次数之和 # 当然也要考虑边界问题，所处矩阵边界位置，也就是i和j等于0的位置，次数都被置为1 # 由于矩阵每次关联的只有上一行的数据，所以临时存储只需要一行的列表即可 def up1(): m, n = 7, 3 dp = [ 1 for i in range(n) ] for i in range(m): for j in range(n): if i == 0 or j == 0: dp[ j ] = 1 else: dp[ j ] = dp[ j ] + dp[ j - 1 ] print(dp[ -1 ]) def up2(): # 组合问题 # 机器人总共移动的次数S = m + n - 2， # 向下移动的次数D = m - 1， # 那么问题可以看成从S中取出D个位置的组合数量，这个问题的解为C(S, D)。 m, n = 7, 3 S = m + n - 2 #总共的移动次数 D = m - 1 #向下的移动次数 ret = 1 for i in range(1,D+1) : ret = ret * (S - D + i) // i print(ret) up1() up2()uniquePaths() 数组区间 数组区间和123456789101112131415def sumRange(m,n): # 对指定区间及进行求和 # 对矩阵进行求累加值，然后用前后索引相减，就可以得到最终值，细节在于第一个点，和如果起点是第一个位置，如何处理 nums = [-2, 0, 3, -5, 2, -1] def sr(nums): dp = [0] for i in range(1,len(nums)+1): dp.append(nums[i-1] + dp[i-1]) return dp dp = sr(nums) if n &gt; 0: return dp[m+1] - dp[n] else: return dp[ m ]sumRange(5,0) 数组中等差递增子区间的个数1234567891011121314151617181920212223242526def numberOfArithmeticSlices(): ''' 一次遍历等差子数列，在增加数过程中，我们可以发现规律如下： dp[2] = 1 [0, 1, 2] dp[3] = dp[2] + 1 = 2 [0, 1, 2, 3], // [0, 1, 2] 之后加一个 3 [1, 2, 3] // 新的递增子区间 dp[4] = dp[3] + 1 = 3 [0, 1, 2, 3, 4], // [0, 1, 2, 3] 之后加一个 4 [1, 2, 3, 4], // [1, 2, 3] 之后加一个 4 [2, 3, 4] // 新的递增子区间 :return: sum(dp) ''' A = [ 0, 1, 2, 3, 4 ] n, dp =len(A), [0 for i in A] if n == 0: return 0 #从2开始 防止+1是 越界 for i in range(2,n): if A[i] - A[i-1] == A[i-1] - A[i-2]: dp[i] = dp[i-1] + 1 print(sum(dp)) return sum(dp)numberOfArithmeticSlices() 分割整数 分割整数的最大乘积123456789101112131415161718192021222324252627282930313233343536373839404142434445464748def integerBreak(): n = 11 # 如果n=10,从1-&gt;10依次进行计算，并且记录每次最大数。最终会找出规律。 # 数字4拆成2 + 2，乘积最大，为4。 # 数字5拆成3 + 2，乘积最大，为6。 # 数字6拆成3 + 3，乘积最大，为9。 # 数字7拆为3 + 4，乘积最大，为12。 # 数字8拆为3 + 3 + 2，乘积最大，为18。 # 数字9拆为3 + 3 + 3，乘积最大，为27。 # 数字10拆为3 + 3 + 4，乘积最大，为36 # 其中难点在于，像10分为3*3*4,而3*3在6中，而10包含6所以在每一次推论中，要跟新最大值。 # 因此，代码如下： def ib1(): dp = [ 1 if i == 1 else 0 for i in range(n + 1) ] for i in range(2, n + 1): for j in range(1, i): dp[ i ] = max(dp[ i ], max(j * dp[ i - j ], j * (i - j))) print(dp) #数学公式 def ib2(): if n &gt; 3: m, k = divmod(n, 3) if k == 2: return 3 ** m * 2 if k == 1: return 3 ** (m - 1) * 4 if k == 0: return 3 ** m if n == 3: return 2 if n == 2: return 1 def ib3(n): if n == 2 or n == 3: return n - 1 res = 1 while(n &gt; 4): res *= 3 n -= 3 return n*res ib1() print(ib2()) print(ib3(n))integerBreak() 按平方数来分割整数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576def numSquares(): # 通过观察每一个数的最大平方组合数列可以看出 #遍历数 最佳平方组成方式 组成平方数个数 遍历数**0.5+1 # 1 * 1(1的平方省略) # 2 1+1 2 2 # 3 1+1+1 3 2 # 4 2**2 1 2 # 5 2**2+1 2 3 # 6 2**2+1+1 3 3 # 7 2**2+1+1+1 4 3 # 8 2**2+2**2 2 3 # 9 3**3 1 4 # 1 4 9...算是临界点， # 对于平方数来说，最大可遍历到(遍历数**0.5+1) 也就是临界点数 # 因此有代码 numSquare2() n = 38 def genertateSquareList(n): squareList = [] diff, square = 3, 1 while( square &lt;= n): squareList.append(square) square += diff diff += 2 return squareList squareList = genertateSquareList(n) print(squareList) dp = [0 for i in range(n+1)] for i in range(1,n+1): mv = sys.maxsize for square in squareList: if square &gt; i: break mv = min(mv,dp[i - square] + 1) dp[i] = mv print(dp) print(dp[-1]) return dp[-1]numSquares()#动态规划def numSquare2(): n = 38 def numSquares( n: int ) -&gt; int: dp = [ i for i in range(n + 1) ] for i in range(2, n + 1): print(1,int(i ** (0.5)) + 1) for j in range(1, int(i ** (0.5)) + 1): dp[ i ] = min(dp[ i ], dp[ i - j * j ] + 1) print(dp[-1]) return dp[ -1 ] numSquares(n) #数学方式def numSquares1(n: int ) -&gt; int: # 直接通过规律算出来 因为次方数只在[1,2,3,4] #判断是不是平方 def isSquare( n: int ) -&gt; bool: sq = int(math.sqrt(n)) return sq * sq == n if isSquare(n): return 1 while (n &amp; 3) == 0: n &gt;&gt;= 2 if (n &amp; 7) == 7: return 4 sq = int(math.sqrt(n)) + 1 for i in range(1, sq): if isSquare(n - i * i): return 2 return 3 3. 分割整数构成字母字符串123456789101112131415161718192021222324252627282930def numDecodings(): # 91. 解码方法 # Given encoded message "12", it could be decoded as "AB" (1 2) or "L" (12). # 从题中可以看出 当首个数字为'0' 还有'606'是无法解码的，因为没有'0.','60','06'所组成的编码 # 对于解码来说，顺序以及数的大小是固定(最多两位进行变换)的，由此可取去推断数字只能为1为何2为当中去组成。 # 通过对数进行递推，可以得出： # 当某一位是'0'时候，只能跟前面的数字[1,2]并且这一位的组合方式和前两位一样(因为前一位的数组，必须和'0'组成在一起，就不能组成前一位的方式了) # 当某一位属于字母范畴是'&#123;1,2&#125;[1,6]',这意味的组合方式是前两位的和。 # 当这一位数字属于[7,...]，那么这意味只能单独出现，所以也和前一位相同。 # 因此可的代码如下： s = '227' n, cur, pre = len(s), 1, 1 if not n or s[0] == '0': return 0 for i in range(1,n): if s[i] == '0': if s[i-1] == '1' or s[i-1] == '2': #因为pre要和前两位的方式相同，所以直接把pre等于cur就行 就如倒退一步 pre = cur else: return 0 else: if s[i-1] == '1' or (s[i-1] == '2' and s[i] &lt;= '6'): pre, cur = cur + pre, pre else: #往前走一步，pre不变（因为前一步和本次组合相同），cur等于当前的pre（需要跟进） cur = pre print(pre)numDecodings() 长递增子序列 最长递增子序列1234567891011121314151617181920212223242526def lengthOfLIS(): #300. 最长上升子序列 nums = [ 10, 9, 2, 5, 3, 7, 101, 18 ] if not nums: return 0 l, tails = 0, [0 for i in nums] def binarySearch(tail, l, num): left, right = 0, l while(left &lt; right): mid = left + (right - left) // 2 if tail[mid] == num: return mid elif tail[mid] &gt; num: right = mid else: left = mid + 1 return left for v in nums: index = binarySearch(tails, l, v) tails[index] = v print(tails) if index == l: l += 1 print(l)lengthOfLIS() 一组整数对能够构成的最长链123456789101112131415161718192021222324252627282930313233def findLongestChain(): # 对于 (a, b) 和 (c, d) ，如果 b &lt; c(很重要)，则它们可以构成一条链。 # 如列子：[1,2], [2,3], [3,4]] # 只需要遍历每一个元素后，然后保存当前最小的c1，进行分别比较，然后满足b&lt;c1即可加1，不满足，更新c1 # 坑点： # 1.leetcode列子误导，全为大于1？(其实有小于1的数) # 2.栗子总体趋势单调？(其实顺序不一) # 如果组成了长链，那么整体顺序一单挑的！！！ # 因此，我们需要进行对元素的首元素进行排序，这样就保证，后面不会出现首元素比其前面更小，而需要更新首元素的情况。 # 对首元素排序a，而b是不变的，整体的顺序是不会产生影响的（这一步没做，会很坑），并且保证记录了当前最小的首元素 # 所以，这需要满足要求加1即可，代码如下： pairs = [ [ -10, -8 ], [ 8, 9 ], [ -5, 0 ], [ 6, 10 ], [ -6, -4 ], [ 1, 7 ], [ 9, 10 ], [ -4, 7 ] ] if not pairs: return 0 import functools # 可不要cmp def cmp( a, b ): if (a[ 0 ] - b[ 0 ]) &lt; 0: return -1 if (a[ 0 ] - b[ 0 ]) == 0: return 0 else: return 1 pairs = sorted(pairs, key = functools.cmp_to_key(cmp)) dp = [ 1 for i in range(len(pairs)) ] for i in range(1, len(pairs)): for j in range(i): if pairs[ j ][ 1 ] &lt; pairs[ i ][ 0 ]: dp[ i ] = max(dp[ i ], dp[ j ] + 1) print(dp) return max(dp)findLongestChain() 最长摆动子序列1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#376. 摆动序列def wiggleMaxLength(): nums = [1,17,5,10,13,15,10,5,16,8] # 如果连续数字之间的差严格地在正数和负数之间交替，则数字序列称为摆动序列。 # 坑：1.知道序列的意思-可以不连续 2 如何去转化正负关系 3. 测试样例中 是有相同数的，如何过滤（同正正 fufu一样） # 直观如上列列子，如果为正为1，为服即为0 [1, 0, 1, 1, 1, 0, 0, 1, 0]， # 直接可以看出，我们直接遍历用只想前后两指针，记录当前不连续的值和往前移动的值，就可以求出最长摆动子序列 if not nums:return 0 if len(set(nums)) == 1: return 1 if len(set(nums)) == 2: return 2 dp= [] for i in range(1, len(nums)): temp = nums[i] - nums[i-1] if temp &lt; 0: dp.append(0) elif temp &gt; 0: dp.append(1) print(dp) if len(set(dp)) == 1: return 2 maxv, cur,cv = -sys.maxsize, 1, dp[0] for i in range(1,len(dp)): if dp[i] != cv: cur += 1 cv = dp[i] else: cur = cur print(cur+1) return cur + 1def wiggleMaxLength1( ) -&gt; int: # 如何优化 # 从利用两指针去记录前后书过程中，判断正负，其实不需要1和0去表示。 # 从而优化空间速度 nums = [ 3, 3, 3, 2, 5 ] if not nums: return 0 up, down = 1, 1 for i in range(1, len(nums)): if nums[ i ] &gt; nums[ i - 1 ]: up = down + 1 if nums[ i ] &lt; nums[ i - 1 ]: down = up + 1 print(max(up,down)) return max(up,down)wiggleMaxLength()wiggleMaxLength1() 最长公共子序列 最长公共子序列1234567891011121314151617181920212223242526272829303132333435363738394041424344# 1143. 最长公共子序列def longestCommonSubsequence(): text1 = "abcde"; text2 = "ace" #如果为空 直接返回、 if text1 == text2 or text1 == "" or text2 == "": return text2 #方法1 # 给定两个字符串 text1 和 text2，返回这两个字符串的最长公共子序列。 # 最直观的想法就是，两成循环，一次遍历，如果出现相同的字符，且不是同一位置的加1(难点就在于把握不同点位置的认识)， # 但是为了要继承字符的连续性，就要填补不是相同的字符。这很简单直接补上上一位的数值即可(因为遍历是顺序的) # 然后依次逻辑，代码如下： def lcs1(): dp = [ [ 0 for i in range(len(text2) + 1) ] for j in range(len(text1) + 1) ] print(dp) for i in range(1, len(text1) + 1): for j in range(1, len(text2) + 1): if text1[ i - 1 ] == text2[ j - 1 ]: dp[ i ][ j ] = dp[ i - 1 ][ j - 1 ] + 1 #必须为这点，要找以前匹配过且不是本身的值 else: dp[ i ][ j ] = max(dp[ i - 1 ][ j ], dp[ i ][ j - 1 ]) print(dp[ -1 ][ -1 ]) return dp[ -1 ][ -1 ] # 逻辑同上， 优化空间复杂度。动态规划题做多了，一般空间都是可以优化为O(n)的 # 因为对于其中遍历到一个字符中，关联的数组就为上一个和左一个，即数为dp[ i ][ j ]那么关联的dp[ i - 1 ][ j ]和dp[ i ][ j - 1 ] # 这道题有一个难点就在于，如何去找到他的p[ i - 1 ][ j - 1 ]，这个值就为算上一个值时的原始值。 # 因此优化代码逻辑如下: def lcs2(): m = len(text1);n = len(text2) dp = [0 for i in range(n+1)] for i in range(1,m+1): temp = 0 for j in range(1,n+1): now = dp[j] if text1[i-1] == text2[j-1]: dp[j] = temp + 1 else: dp[j] = max(dp[j-1], dp[j]) temp = now print(dp[-1]) return dp[-1] lcs1() lcs2()longestCommonSubsequence() 0-1 背包1. 0-1 背包12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152def knapsack(): # 有一个容量为 N 的背包，要用这个背包装下物品的价值最大，这些物品有两个属性：体积 w 和价值 v。 # 确定值-背包重量一定即w 通过w去确定背包所能装载的最大值v # 给定物品重量与价值列表如下wb-&gt;vb # 通过去遍历wb，意为每次增加一个物品 # 二层遍历背包容量W，判断背包是否能够装载当前物品。（并且要参考以前获得的值） # 如果装载不下当前物品，就填充上一次的价值 # 即代码逻辑如下： wb = [2, 4] vb = [3, 11] N, W = 2, 8 def ks1(): wv = [ [ 0 for j in range(W + 1) ] for i in range(N + 1) ] for i in range(1, N + 1): w, v = wb[ i - 1 ], vb[ i - 1 ] for j in range(1, W + 1): if j &gt;= w: wv[ i ][ j ] = max(wv[ i - 1 ][ j ], wv[ i ][ j - w ] + v) else: wv[ i ][ j ] = wv[ i - 1 ][ j ] print(wv[ -1 ][ -1 ]) return wv[ -1 ][ -1 ] def ks2(): # 从上述分析可知： # 对于临时表wv而言，只用到了前一层的值，所以只需要O(N)的空间复杂度即可： # 代码如下： dp = [0 for i in range(W+1)] for i in range(1, N+1): w = wb[i-1]; v = vb[i-1];old = dp[1] for j in range(1, W+1): if j &gt;= w: temp = dp[j-w] + v dp[j] = max(old, temp) else: dp[j] = old if j &lt; W: old = dp[j+1] print(dp[-1]) #有上述思路，如果倒叙遍历... 会咋样呢？ for i in range(2, N + 1): w = wb[ i - 1 ] v = vb[ i - 1 ] for j in range(W,0,-1): if j &gt;= w: dp[ j ] = max(dp[j], dp[ j - w ] + v) print(dp) print(dp[ -1 ]) ks1() ks2()knapsack() 划分数组为和相等的两部分123456789101112131415161718192021222324252627282930313233343536373839404142#416. 分割等和子集#题目描述给定一个只包含正整数的非空数组。是否可以将这个数组分割成两个子集，使得两个子集的元素和相等。def canPartition(): nums = [1,1,1,3,5,3] # 由题意数组分割成两个子集，使得两个子集的元素和相等 # 因为只包含正整数的非空数组，所以如果全部和为奇数是不可能分割的，长度小于1也不行。这就意味着我们只需要找到他均值就行 # 因此，我们只需要遍历所给元素，因为不可重复使用，直接遍历就行 # 如果找到其中元素为遍历均值数组v相等，即这个数可以求和找到 # 当遍历大于v是,只需依次去判断以前的值是否可以找到即可 # 难点在于如何判断以前的值。倒序遍历就不用考虑原始值是否被覆盖了，就比如值为10前去5等于5，就会重复使用原始值 def cp1(): mid = sum(nums)//2 if sum(nums) % 2 != 0 or len(nums) &lt;= 1: return False dp = [0 for i in range(mid+1)] for i, v in enumerate(nums): for j in range(mid,v-1,-1): if dp[j-v] == 1 or v == j : dp[j] = 1 print(v,j) print(dp) return dp[-1] def cp2(): div, remain = divmod(sum(nums), 2) if remain != 0: return False N = len(nums) nums.sort(reverse = True) def _dfs( target, pos ): if target == 0: return True if pos &lt; N and target &lt; nums[ pos ]: return False for i in range(pos, N): if _dfs(target - nums[ i ], i + 1): return True return False return _dfs(div, 0)canPartition() 改变一组数的正负号使得它们的和为一给定数12345678910111213141516171819202122232425262728293031323334353637# 494. 目标和def findTargetSumWays(): nums ,S = [ 1, 1, 1, 1, 1 ], 3 # 改变一组数的正负号使得它们的和为一给定数 # 又题意可知，是有正负组成两类符号组成 # 可以将这组数看成两部分，P和N，其中P使用正号，N使用负号，有以下推导： # 既可以推论： # sum(P) - sum(N) = target # sum(P) + sum(N) + sum(P) - sum(N) = target + sum(P) + sum(N) # 2 * sum(P) = target + sum(nums) # 因此只要找到一个子集，令它们都取正号，并且和等于(target + sum(nums)) / 2，就证明存在解。 def dy(num, S): div, remain = divmod(sum(nums), 2) if remain == 0: return 0 dp = [1 if i == 1 else 0 for i in range(div + 1)] for i in nums: for j in range(div,i-1,-1): if dp[j - i] == 1: dp[j] += dp[j - i] return dp[-1] # 深度搜索，即遍历每一种选择 # 就如同比遍历每一个数，然后每一个有两种选择，如同一颗树，每次长两次枝丫，知道分为列子长度数为支点。 # 知道遍历为止 代码逻辑如下 def dfs(nums, pos, res = 0, c=0): if pos &gt; len(nums) - 1: if res == S: return 1 return 0 return dfs(nums, pos + 1, res-nums[pos], c) + dfs(nums, pos + 1, res+nums[pos], c) print(dfs(nums, 0, 0,0)) print(dy(nums, S))indTargetSumWays() 01 字符构成最多的字符串12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970def findMaxForm(): import functools strs = ["111","1000","1000","1000"];m = 9; n = 3 # 1. 如果用长度去排序，然后用贪婪算法，贪婪算法错误 # 2. 如果用每一个元素统计1和0的个数，然后排序就正确比动态规划时间复杂度更低O(n*lg(n)) # 所以要找好指标，就像如果背包用比列系数也挺不错 哈哈哈 def tl(): def tl1(): def cmp( a, b ): if (len(a) - len(b)) &lt; 0: return -1 if (len(a) - len(b)) == 0: return 0 else: return 1 pairs = sorted(strs, key = functools.cmp_to_key(cmp)) print(pairs) c0,c1 = 0, 0 m0, n0 = 0, 0 for str in pairs: for s in str: if s == '0': m0 += 1 else: n0 += 1 if m &gt;= m0 and n &gt;= n0: c0 += 1 print(c0) return c0 def tl2(): def getMax( counts, m: int, n: int ) -&gt; int: ans = 0 for k in counts: if m &gt;= k[ 0 ] and n &gt;= k[ 1 ]: ans += 1 m -= k[ 0 ] n -= k[ 1 ] return ans counts = [ ] from collections import Counter for s in strs: d = Counter(s) counts.append([ d[ '0' ], d[ '1' ] ]) c1 = sorted(counts, key = lambda x:min(x[ 0 ], x[ 1 ])) c2 = sorted(counts, key = lambda x:min(m - x[ 0 ], n - x[ 1 ]), reverse = True) return max(getMax(c1, m, n), getMax(c2, m, n)) def dy(): # 类比于0-1背包问题，知识把建表中，求上一次元素的思路，化为当前01的个数，这就是由于不是而 # 求上一值的过程 就是验证此值是否能够填入 dp = [ [0 for j in range(n+1)] for i in range(m+1)] for str in strs: ones, zeros = 0, 0 for s in str: if s == '0': zeros += 1 else: ones += 1 for i in range(m, zeros-1, -1): for j in range(n, ones-1, -1): dp[i][j] = max(dp[i][j], dp[i-zeros][j-ones] + 1) print(dp[-1][-1]) return dp[-1][-1] tl() dy() findMaxForm() 找零钱的最少硬币数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152def coinChange(): coins = [186,419,83,408]; amount = 6249 # 同背包问题即可，对价格进行依次遍历，保证不重复使用 # 然后对目标价格遍历，保证累加性（每种结果能够遍历），判断使得每次取出最佳分数 # 代码如下： if amount == 0: return 0 def dy(): dp = [ sys.maxsize for i in range(amount + 1) ] for c in coins: for i in range(c, amount + 1): if c == i: dp[ i ] = 1 dp[ i ] = min(dp[ i ], dp[ i - c ] + 1) print(dp[ -1 ]) if dp[ -1 ] == sys.maxsize: return -1 return dp[ -1 ] dy() # 深度搜索与剪枝优化 # 难点在于 不是一个数能够除尽的，比如amount=19，coins=[2,3],其中19对每一个数都不能被除尽，而19=15+4 # 是能够找到零钱的。 # 当使用深度搜索是，逻辑不能够被此干扰，而直接取余，造成没有结果。 # 逻辑其实和动态回归一样，只是里面的一层循环进行优化和剪枝。 minv = sys.maxsize coins = sorted(coins,reverse = True) lc, minv = len(coins), amount + 1 dp = [] def dfs(target, index, count): nonlocal minv,dp if count + target//coins[index] &gt;= minv: return if target % coins[index] == 0: minv = count + target//coins[index] dp.append(coins[ index ]) print(dp) if index == lc - 1: return print(index, target,coins[index],target//coins[index]) for i in range(target//coins[index],-1,-1): dp.append(coins[index]) dfs(target - coins[index]*i, index+1, count + i) dp = [] dfs(amount, 0, 0) print(minv) return -1 if minv &gt; amount else minvcoinChange() 找零钱的硬币数组合123456789101112131415161718192021222324252627def change(): # 找零钱的最少硬币数思路一样，也是一个类似背包问题，只是进行求和 amount = 5;coins = [ 1, 2, 5 ] # if amount == 0 : # return 1 # dp = [0 for i in range(amount + 1)] # for c in coins: # if c &gt; amount: # continue # for i in range(c,amount+1): # if i == c: # dp[i] += 1 # dp[i] += dp[i-c] # return dp[-1] if amount == 0: return 1 dp = [ 1 if i == 0 else 0 for i in range(amount + 1) ] for c in coins: if c &gt; amount: continue for i in range(-c + amount + 1): if dp[ i ]: dp[ i + c ] += dp[ i ] print(dp) print(dp[ -1 ]) return dp[ -1 ]change() 字符串按单词列表分割123456789101112131415161718def wordBreak(): s = "leetcode"; wordDict = [ "leet", "code" ] # 由题意得，分词后顺序是变的，也就是wordDict能组成的词语只能从左到右 # 更具所给s的长度建立矩阵 # 矩阵然后遍历所给词典，这就保证所组成的词语是按照上诉顺序的 # 然后难点就在于，只要出现了所给词语，就标记即可。 dp = [0 for i in range(len(s)+1)] print(s[0:len(s)]) tc, dp[0] = 0, 1 for i in range(1,len(s) + 1): for w in wordDict: l = len(w) if l &lt;= i and (w == s[i-l:i]): dp[i] = (dp[i] | dp[i-l]) print(dp[-1]) return dp[-1]wordBreak() 组合总和12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849def combinationSum4(): nums = [ 1, 2, 3 ] target = 4 # 又题意可知，可以重复使用nums并且顺序不同，亦是一种结果 # 因此代码逻辑如下： if not nums or target == 0: return 0 def dy(): dp = [0 for i in range(target+1)] # 保留nums的顺序 # for n in nums: # for i in range(target-n+1): # if dp[i]: # dp[i+n] += dp[i] #不保证nums的顺序 for i in range(1,target+1): for n in nums: if n &gt; i: continue if n == i: dp[i] += 1 dp[i] = dp[i] + dp[i-n] print(dp[-1]) return dp[-1] def dfs(): size = len(nums) memmory = &#123;&#125; def helper( target ): if target == 0: return 1 res = 0 for i in range(size): if nums[ i ] &gt; target: continue next_target = target - nums[ i ] if next_target in memmory: res += memmory[ next_target ] else: memmory[ next_target ] = helper(next_target) res += memmory[ next_target ] return res return helper(target) dy() dfs()combinationSum4() 股票交易 需要冷却期的股票交易123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import numpy as npdef maxProfit(): print(6&amp;1) print(float('-inf')) #infinity # 根据题意，每一个数都有0：买入，1：卖出，2：冷冻期。三个状态之间进行转化 # 即如果当前i=1时，就是第一只股票，前面没有买即可初始化i=0状态为[0,0,0] # 这样根据状态转移方程： # 1.当前买入(利润) = max(上一次买入,上一次卖出 + 当前价格)-&gt;max(买入状态，卖出状态转为买入状态)-&gt;其中卖出后一直不买，期间属于冷冻期 # 2.当前卖出(利润) = max(上一次卖出，冷冻期 - 当前价格)-&gt;max(卖出状态，买入状态转为卖出状态)-&gt;其中如果买入一次后如果一直不卖，期间属于冷冻期 # 3.冷冻期 = 当前买入(利润) # 为了保证每一次循环，能够保证利益最大，所以需要取得买入和卖出当前的最大值 # 因此代码逻辑如下： prices = [1,2,3,0,2] #如果一上述状态转换方程，根据prices退出结果为 ''' [[ 0. -1. 0.]#初始值解释 0：刚开始没有卖出，利润为0,1：买入一只股票利润-prices[0],3:冷冻期是上一次没有股票，所以利润0 [ 1. -1. 0.] [ 2. -1. 1.] [ 2. 1. 2.] [ 3. 1. 2.]] ''' if len(prices) &lt; 2: return 0 def mp1(): n = len(prices) dp = np.zeros((n,3)) dp[0][1] = -prices[0] for i in range(1, n): dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i]) dp[i][1] = max(dp[i-1][1], dp[i-1][2] - prices[i]) dp[i][2] = dp[i-1][0] print(max(dp[n-1][0],dp[n-1][2])) print(dp) return max(dp[n-1][0],dp[n-1][2]) # 又上诉逻辑以及代码实现上，观察可知： # 保留状态0、1、2上股票之间的联系，只是当前股票和上一只股票之间进行联系 # 因此只需要两个变量进行存储历史变量，进行转换即可 # 代码如下： def mp2(): hold, sell, freeze = -sys.maxsize, 0, 0 for v in prices: hold = max(hold, sell - v) sell = freeze freeze = max(freeze, hold + v) print(max(sell, freeze)) return max(sell, freeze) mp1() mp2()maxProfit() 需要交易费用的股票交易1234567891011121314151617181920#714. 买卖股票的最佳时机含手续费def maxProfit1(): prices = [1, 3, 2, 8, 4, 9];fee = 2 if len(prices) &lt; 2: return 0 # 股票交易有三给状态，卖出(sell):卖出是这种状态,持有(hold):买入这种状态,停歇(rest):1.卖出股票但不买入股票期间;2.买入股票但不卖出期间 # 股票交易就在这三种状态之间进行转换即:hold-&gt;(rest)-&gt;sell-&gt;(rest)-hold(括号表示可有可无) # 根据这三种状态，我们就可以根据题意算出结果 # 其中我们需要保存当前最大值，来求解最大利润。 # 每一个状态用当前利润进行表示 sell, hold, rest = 0, -sys.maxsize, 0 for p in prices: hold = max(hold, sell - p) rest = hold #可以不要，只是有这种状态 sell = max(sell,rest + p -fee ) print(sell,rest) return max(sell, rest)maxProfit1() 只能进行两次的股票交易1234567891011121314151617181920212223242526272829# 123. 买卖股票的最佳时机 IIIdef maxProfit2(): prices = [3,2,6,5,0,3] if len(prices) &lt; 2: return 0 firstHold, firstSell = float('-inf'), 0 secondHold, secondSell = float('-inf'), 0 # for p in prices: # if(firstHold &lt; -p): # firstHold = -p # # if firstSell &lt; firstHold + p: # firstSell = firstHold + p # # if secondHold &lt; firstSell - p: # secondHold = firstSell - p # # if secondSell &lt; secondHold + p: # secondSell = secondHold + p for p in prices: firstHold = max(firstHold, -p) firstSell = max(firstSell, firstHold + p) secondHold = max(secondHold, firstSell - p) secondSell = max(secondSell, secondHold + p) print(secondSell) return secondSellmaxProfit2() 只能进行 k 次的股票交易123456789101112131415161718192021222324252627def maxProfit4(): prices = [3,2,6,5,0,3]; k = 2 #当交易次数，能够遍历完全部的股票的时候，只需要把利润为正的交易加和即可 maxv = 0 if len(prices) // 2 &lt;= k: for i in range(1, len(prices)): if prices[i] &gt; prices[i-1]: maxv += (prices[i] - prices[i-1]) return maxv elif len(prices) &lt; 2 or k == 0: return 0 # 当交易次数k，不能够遍历所以股票时 # 说明有些股票将会被省去，但是股票的相对顺序是不可变的 # 因此可你存储矩阵dp[i][j]如下，其中i表示k次交易，j-&gt;(0:买入(hold)，1:卖出(sell)) dp = [[float('-inf'),float('-inf')] for i in range(k)] for p in prices: dp[0][0] = max(dp[0][0], -p) dp[0][1] = max(dp[0][1], dp[0][0] + p) for i in range(1,k): dp[i][0] = max(dp[i][0], dp[i - 1][1] - p) dp[i][1] = max(dp[i][1], dp[i][0] + p) print(dp[-1][1]) return dp[-1][1]maxProfit4() 字符串编辑 删除两个字符串的字符使它们相等12345678910111213141516def minDistance(): word1, word2 = "ab", "a" l1, l2 = len(word1), len(word2) # 又题意可知，最少删除字符，使他们相等，也就是保留他们最常相等的字符串 # 因此求出他们公有最长公共子序列就行 # 代码如下： dp = [[0 for i in range(l2+1)] for j in range(l1+1)] for i in range(1,l1+1): for j in range(1,l2+1): if word1[i-1] == word2[j-1]: dp[i][j] = dp[i-1][j-1] + 1 else: dp[i][j] = max(dp[i][j - 1], dp[i - 1][j]) print(dp[-1][-1]) return l1+l2-2*dp[-1][-1]minDistance() 编辑距离12345678910111213141516171819202122232425def minDistance1(): word1, word2 = "horse", "ros" # 如过把word2看作子序列，意思先在word1中找到最长的公共子序列(意味着相同的不加1)，而其他的就需要通过增加，替换操作进行配对 # 就如同做字符串编辑的思路 # 只是多考虑了相等的地方如何去处理 # 只是多考虑了相等的地方如何去处理 l1, l2 = len(word1), len(word2) if not l1 and not l2: return 0 if not l1 or not l2: return 1 dp = [ [i if j == 0 else 0 for i in range(l2 + 1) ] for j in range(l1 + 1) ] for i in range(l1 + 1): dp[i][0] = i print(dp) for i in range(1, l1 + 1): for j in range(1, l2 + 1): if word1[ i - 1 ] == word2[ j - 1 ]: dp[ i ][ j ] = dp[ i - 1 ][ j - 1 ] else: dp[ i ][ j ] = min(dp[ i-1 ][ j - 1 ], min(dp[ i ][ j - 1 ], dp[ i - 1 ][ j ]))+1 print(dp[ -1 ][ -1 ]) return dp[ -1 ][ -1 ]minDistance1() 复制粘贴字符1234567891011121314151617181920212223242526272829303132333435363738394041#650. 只有两个键的键盘def minSteps(): n = 3 def dg(n): if n == 1: return 0 for i in range(2, int(math.sqrt(n) + 1)): if n % i == 0: return i + dg(n/i) return n print(dg(n)) def dy(n): dp = [0 for i in range(n+1)] h = int(math.sqrt(n)) for i in range(2,n+1): dp[i] = i for j in range(2, h+1): if i % j == 0: dp[i] = dp[j] + dp[i//j] break print(dp[-1]) return (dp[-1]) dy(n) def fj(n) -&gt; int: # 质数分解,比如输入为70时,70 = 2×5×7 # 操作次数为:2+5+7 res = [] while n &gt; 1: tmp = 2 while n % tmp: tmp += 1 n//=tmp res.append(tmp) return sum(res) fj(n) minSteps()]]></content>
  </entry>
  <entry>
    <title><![CDATA[snail first travel essays 3day]]></title>
    <url>%2F2020%2F02%2F06%2Fsnail-first-travel-essays-3day%2F</url>
    <content type="text"><![CDATA[snail first travel essays 3day20200123 雨 目的地-西溪湿地公园 一个人，一个口罩，一把伞，一个背包，一碗混沌，五个煎饺，一个目的地。 由于新型肺炎的不断扩散，我家人的关注，我更加选择人少的地方了。综合了一下，很想去湿地公园，毕竟电视上看多了，想去看花和鸟，哈哈哈，虽然我们大璧山也有。。。 第一次做杭州的公交，走路去车站，看见一个树，外面老皮坏了，重新又长了新枝干，我是棵树就好了，哈哈。 到了湿地公园，门票居然80，学生半价，然后拿了一张地图，就开始干。进景点，现在都要测体温了… ​ “宝剑锋从磨砺出，梅花香自苦寒来” 连野鸭，都要秀我恩爱！！！ 我以为这次旅行，就这样平淡的结束了，走路，遇见只小松鼠。哇！第一次看见松鼠，激动得一动不动，怕打扰他，逃跑了，他好可爱啊，爬树和在枝丫上跳跃的技术，非常棒。 这是他的家吗？ 这次，你应该能找到吧~ 实力抢拍，真的太帅了~ 坐在亭子中，听着雨滴的击打生，鸟儿在空中划过，偶尔听得野鸭的叫声。逐渐的城市化，以及人民财富的提升。在农村，坐在门槛上休息，听瓦房屋檐下雨滴声，婆婆的叫骂声，以及成为一种不可再有的奢侈。不管瓦房建的和以前多像，不管是不是那个地，他都已经不再了。是否想过，曾经小时候的画面，令人烦劳的画面，却是你一辈子只能在梦中，怀恋的地。 可能人，一辈子在学会一件事。那就是如何去珍惜。当他逃离的瓦房，进入了砖房，他却想着区里的楼房。当他有了区里的楼房，却又想着市里面的楼房… 依次逻辑，我想每一个人都和一样，有这样“贪”过。却是我们成长的必修课。我们无法讨论这人性，对与错。但我肯定知道，它让我笑得更少了一点。 我还是相信冰河世纪里负鼠和剑齿虎的对话 剑齿虎：“你们为什么每天这么的开心？” 负鼠：“因为我们傻啊！” 我很喜欢竹！！！ 野鸭，真的很可爱！！！ 水下观鱼，设计感还行，只是没看见多少鱼，哈哈 又要走一天了，真担心自己的脚 这里是康熙建筑，门票10元，打折，因为五点过了吧。本来50rmb，如果高峰期要150.就这样观看一下150，真是“好奇心，害死猫啊！！！” 终于要回上海了！！！ 好累啊！！！像个乞丐！！！ 总结 总体三天来说，开销就500吧！（没细算）。 总体感受还是非常不错的，就是有点冷和放不开，毕竟雨天和新型肺炎的原因 一个人旅行，一定要提前准备。考虑到天气，以及行程规划等。因为时间还是挺紧张的，我真是一只不停的在走，每天四万步左右吧（肯定少了，有时候开启了超级省电模式的） 对于湿地公园推荐指数三颗星吧！ 夏天会更棒。 旅行就是有目的地，却有意外和选择到达方向的乐趣。永远不知道下一秒会发生什么，会相遇什么。在路上的感觉。真好！！！ 20200206 17:08完成三天的blog，特此记录我第一次一个人旅行的观山览水，以及察言观色。截止今日，我都没有出过门，除了那拿外卖，害得我太湖游玩一圈的计划泡汤。这都要从一只蝙蝠，开始说起！！！]]></content>
      <categories>
        <category>-[随笔]</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[snail first travel essays 2day]]></title>
    <url>%2F2020%2F02%2F06%2Fsnail-first-travel-essays-2day%2F</url>
    <content type="text"><![CDATA[snail first travel essays 2day20200122 雨 8:24 起床 洗涑 5煎饺 1豆腐脑 8元。 带上口罩，打开哈罗APP，骑上单车，一只手拿着伞，一只手操作，耳朵听着歌与高德小姐姐的美妙声音，淋着雨一直走（技术不好，莫学我！！！），驶向浙江大学之江校区。 根据自身情况，旅行不太喜欢坐公交，走路和骑单车对我来说更能够了解风土文化。 城市的建筑，特别的中国的建筑，没有让我感到一丝的惊喜，可能雾太大了吧！ 大约40几分钟的形成，途中遇见交警，表面镇定自若，实着慌得一匹，差点行驶到外环去了，还好行驶3米后，发现没有非机动车道。我选择的是钱塘江岸过去的。 虽然没有看见钱塘江，不过在对岸，还是能够赶脚钱塘江很宽很长，毕竟那桥，就赶脚很牛逼。 目的地到达，停车，果不其然，我越界了。还好我是第一次，我堂堂季包单车用户，不收我调度费，哈哈哈，突然高兴了不少。 门卫，叫我拿出身份证登记一下。门卫直接在硬件上识别一下就可以了。看来现在景点效率十足啊。门卫给我说：“为什么不回家过年啊？”，我呵呵一下，“一言难尽啊！！！” 之江校区，网友全力推荐的校区。踏进校园，历史感，肃穆感十足。路边高大久远的香樟树，浅黄色石砖显得格外的有历史感。它完全采用西式的建筑风格，包括古典复兴主义、中世纪哥特风格、很好的融合具有独特美国殖民地风格。相比较于城市的现代感，我更喜欢这里的，历史感和宁静感。 常春树树叶飘动，雨滴拍打着树叶，屋檐落下雨滴，枯树挂着雨水，迎着光，格外的发亮。高大挺拔的树，瓦蓝瓦蓝的山水，格外的令人喜欢。喜欢宁静的人，不知道有多羡慕这里的学生和教师了。（我好羡慕的…） 看客们，注意了，图片会很多哟！！！ 文艺的小草： 池水的源头： 校外的后花园，附带龙井茶源一带（去了九溪烟树，才知道是龙井茶，涨知识了，土豪啊！！！） 继续另辟蹊径： 真是喜欢这里的水啊！！！ 途中，在校园小道中，发现几处呕吐物，我想是离别，考研结束后最后的狂欢吧。对于现大四的我，没有选择考研，或许是一种遗憾、或许是这辈子做的最正确的事情吧！ 游玩了两小时，从空无一人的篮球场，到令人羡慕的健身房，到野外别墅的教师房，以及后花园。不得不感叹，我高中的时候还给我哥说：“我想考浙大，那种异想天开”。我哥只给我两个字，“加油”。 然后我打开了高德地图，开始了我的梦幻之旅—–九溪烟树： 由于雨天，高德显示要翻山，近路。反正旅游那就跟吧。我就z走一百米，记录我的生活，23333！ 路越来越窄，探险的精神一触即发！！！ 开始有了悬崖，一个人注意安全！（这里由于我是一位钢铁直男，并且对于爬山是有经验的，所以还没有让我担心。对于大家来爬山的话，最好的晴天，并且有人陪伴，请勿模仿！！！） 开始有了路障，说明这条路可能很久没有维护了，毕竟冬天了 这段悬崖真刺激！！！ 发现有人去过，给了自己一点信心，能够走通。（万一是野兽呢！！！） 在路上，一把伞，一个人，一条路，一个方向。我 不怕死，舔了一下，还行。 由于在山区，高德地图定位不标准，而且有两条路，我判断是应该要下山了。所以尝试了几次下面的几条路。都怀疑是否走错了。返回回去，只有这一条路啊。多次探查上面分支，发现这是来回几个弯向上。弄得我判断没有路了，以为要原路返回呢！！！ 起码九个弯！！！ 又有路了，表示很开心！！！ 开始下山了！！！ 发现有人来过，更加确定高德应该没错！！！ 下山，由于雨天，路滑，树障，显得格外的危险了。还有我比较有经验！！！ 不管路有多长，有多难，总要停一停享受生活的美好。在路上，才是旅游的意义，而不是终点！！！ 不过我还是慌了，到了这，我只有一个念头，我能活着走出去就好了，因为雾大，辨别方向比较难，而且不熟悉。上次和我哥爬仙女山，下山的时候，没有原路返回，起了雾霾，结果早到另一个村了，通过问姓名真不靠谱。农村好多同姓。家长开了半小时车，才找到我们，555233333！！！ 死亡凝视！！！ 在这以为要到了，高兴过头，重心放高了，一走，才在泥土上了，就滑了一跤，还好羽绒服够厚。。。 突然看见浙大后花园一样的茶园。顿时欣喜又担心。欣喜是终于肯定有人来过，能够走出去了，担心是这和浙大的后花园挺像啊，不会走回去了吧！！！ 然后发现，其实不是，没有山间小路，没有山间别墅！！！ 这茶花真美美美！！！（我终于走出来了！！！） 哇！！！车！！！ 走出来的马路，有嘀嘀吗？ 看到这个，我脑海里，只有这个。卧槽，这是龙井茶！ 卧槽，那些山间的都是龙井茶!卧槽，真巴适! 我是不是从第二个塔那边走出来的！！！ 枯树，挂着雨水，开出别样的花，能活着，看着什么都没！！！ 是真的美！！！ 这树，也是够坚强的！！！ 这小溪，高树，夏天在这嬉戏和荡秋千肯定很爽！！！ 经过长途跋涉，我终于到了九溪烟树！！！ 在这里遇到一个老太太，是景点管理自愿者。给我们旅游的讲解地方文化。她叫我从池塘边饶过去，看一下瀑布，山半腰有一个亭子，不要上去，路太滑。然后就去杨梅岭村，那里可以去农民加买菜叶，70元一两。在老婆婆的热心招待下，我决定上亭，买几两茶叶给家里送去。 九溪烟树，向上爬50米左右，有一个亭子，山间的水流下，成为一个瀑布，供给下面的池塘。水质很高，还有人在这打水，回家用呢！！！ 这路两岸的树，真棒啊，一天走在这，除了冷和饿，心也是凉的，静透了… 这里是本地人来爬山，散步的。真羡慕，由于太冷，我就打个卡，不进去了，好几公里呢！！！！ 一进村，就有个老太太，问我是否要买茶叶，我说：“是的，我就是来买茶叶的”。然后她我带进她家，给我泡了种一高一低的茶叶，放了好多茶叶。看着心疼，哈哈哈。然后，我也品不出什么名堂。就问了一下相关情况。茶叶是自己种，也是自己烘干的，不需要加什么添加剂，客厅有个炒茶机，用手炒的。贵的70，便宜的50.我买了四两（我网上查了一下，确实要便宜得多，而且这里是中国第一龙井茶种植地那老太太说的，哈哈）。然后我说，还没有吃饭呢，问了这里有什么吃的。这里确实没有什么吃的，必进这个点了。 然后问如何出去，那老太太就带我去了，途中遇到小卖部，就买了一点饼干和椰子奶。开瓶盖的时候，应该划到手了，吃了半天，才发现我手流血了… 看着外面街道，问老太太，您们这过年有什么特色吗？他说：“没什么特色，和平常一样”，是啊，听说城头人的有钱人，过年都不在家的。不过他们可真幸福，环境好，家家别墅，种植龙井茶，清明节可卖140一两。实乃羡慕。 然后就在这座公交，去了西湖。戴口罩的，开始变多了。 然后，鞋子打湿了，裤子也不挺脏，在公交站，给两位老夫妻，指路，去拱野区环城北路。我想这个点，应该是去吃饭吧！！！然后思考了一下，去了杭州美术馆，赶脚还行吧，主要记录农业文化。通过文字，画和艺术品去展现出来。 最后，听到新型肺炎越来越严重了，回家我也没做公交，走路回去的。看了一下美食评分高的，赶脚也没什么吃的。买了点零食，吃了碗牛肉面。就洗澡开黑了。。。上图就是我的住处。 总结 夏天去浙江大学之江校区和九溪烟树，很不错，环境好，能够锻炼身体。听本地人说清明节不错，很多人来的。 对于爬山注意点： 鞋子一定要防滑的，皮鞋就算了，不是徒步。 注意下脚的位置，踩摩擦力大的位置（树叶） 注意放低自己的重心（弯腰走） 注意一定要用手去找支撑点，一步一步来。 注意思考下下步的位置，是否有一定的支撑点。不然上不去，下不来的。 一定不要雨天一个人去爬山，特别是女汉子，我想没有想我这样无聊的人了（高德敢导，我就敢走…） 杭州确实水好，吃得到没看见什么，毕竟景区。来着度假的，是不错的选择，就是有点贵，哈哈。 一个人背包，容易打湿，所以去杭州注意如何打伞和放置背包内的物品。 这次最惊喜的，就是爬山了吧，刺激。还有就是一个人在路上，听着雨打在伞上的声音，小溪的流水声，那种感觉好久没有了，宁静。 未完待续…]]></content>
      <categories>
        <category>-[随笔]</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[snail_first_travel_essays_1day]]></title>
    <url>%2F2020%2F02%2F04%2Fsnail-first-travel-essays-1day%2F</url>
    <content type="text"><![CDATA[snail_first_travel_essays_1day 第一次旅行规划总览​ 总体游玩路途，从下图可完全看出。由于那时刚爆发新型肺炎，防范意识还不够高，口罩都带错了，第一天还是去的人多的西湖，不过是一个人，不喜欢人多的地方，也比较好奇，所以游玩，都是走的比较人少去的地方，观览。 第一天(20200121)： 游玩西湖一圈 第一天(20200122)： 游玩浙江大学之江校区-九溪烟树 第一天(20200123)： 游玩西溪湿地公园 大体规划如上，现在此blog，记录我第一天的观山览水，以及察言观色。 ​ 2020-01-21 晴 上海 4:36 骑着自行车去赶火车。 ​ 第一次在凌晨4点起航，献给了旅行，而不是篮球（manba out but just i love you greatly）。上海的风，因离海近的原因，所以湿冷而且风大。骑自行车车手会被冻得没有知觉，不过我有长毛衣(假装安慰)，不过上海公交挺早的5:00就有了。我还是为了赶火车，所以临时骑自行车，提前也规划好公交路线，不过公交时间交接太长。 ​ 经过我似运动员的体制，大约40分钟，提前40分就到了上海南站。三层进候车栈，瞄见有大叔在泡方便面，有小姐姐在化妆，有小哥在涑口，还在有个哥们，躺在位置上，盖着被子玩手机。第一次身在他乡，第一次感受春运，第一次认为“回家”是有重量的。看着隔壁会重庆的列车，真想悄悄地溜上去呢！ ​ 绿皮火车，在文艺青年中，承载着”诗和远方“；在中年壮年中，承载着”家和儿女“；在白发老人中，承载着”福和富“。在我的眼中，承载着“脚臭，红烧牛肉的味道”。由于新型肺炎处于初始期，很多人都没有戴口罩，像我口罩都带错了（55552333），不过大部分年轻人都是带了口罩的。 在列车行驶中，雾逐渐的升高，阳光洒进车窗，空气也变得清新许多。人们有的到达了终点，却是另一个人的起航。人生就是这么奇怪。我也不觉得坐绿皮火车没有什么不好。慢，价廉，不正是一个人旅游的目的吗？慢慢地享受不同地域带来的文化冲击，慢慢地观察过客文字表达，慢慢地欣赏枯树上超大的鸟窝（南方人表示，北方的鸟窝，真的大，为什么没有去捅呢！查了一下，河南捅鸟窝事件，瑟瑟发抖）。 在无聊却又好奇的矛盾中，突然隔壁一个小孩吸引了我。母亲响亮的一把掌，父亲更响亮的三把掌。让我陷入深深地思考。母亲，应是可以无限被撒娇的可爱女人；父亲，应是可以无限避难和模仿的偶像；我不是很清楚一位母亲在这么多人面前，因为小孩一丁点的无理取闹，和她认为“小孩是玩真的”，而果断打他；我不明白一位父亲在这么多人面前，因为小孩不断承认错误，却在不断大声哭泣，被用武力而制作。最终小孩一个在一边趴着窗而小声哭泣，我想他怕了。他可能忘得很快，但绝对刻骨铭心。全程我没有看见母亲关心和用温暖的话教育他（而且我不认为小孩有错）。最令人痛心的事！！！小孩被父亲狠狠地扇三耳光的过程中，清爽的声音吸引了我，去偷看了一眼。看见那母亲在“笑”。我无法读懂一个人内心的想法，他们每一个人都有自己专属行为权力。生而为人，我很抱歉。是因为小孩一直在说“妈妈他打我”而”笑“、还是因为小孩被”打“，而反映不是她的错而”雀喜“，亦是”落井下石“的一种”嘲笑“。吾日三省吾身，我想可能太悲观；可能自己太小人而没有全面的思考，而判断他们是坏人；可能我不会生小孩！！！（就像我不明白我父母一样） 地球仍然在旋转，列车还在不断的前进，人们依然在开怀大笑。世界上，没有什么感动深受，只有自己的一厢情愿罢了。不过这些都丝毫不能我这”钢铁直男“打望“小仙女”的心情。杭州的美女，确实不错，想。。。！！！ 可能杭州和我有缘，可能我运气永远都不差。我到达站是杭州站。下站走路直达鼓楼，途中借着杭州老婆婆的胆，横穿马路(真带劲)。鬼使神差的进来一个小胡同，买了个韭菜饼，因为老板娘把混沌的手速吸引了我，吃了碗片川儿（和老板交流，那中面辣，最终没有，选了个没吃过的，他说你要吃辣可以加）。最终那面，辣到时不辣，烫倒是很烫。我想他应该是先抄聊，然后煮汤，下面的吧！真实绝了！。 舔包玩肚子，走进巷子深处。原来这是杭州当地人的集市。有卖蔬菜的，卖香料的，鲜鱼的… 看着尽头的一座上，我想应该能够爬上去吧！杭州的山，香樟树，樟树打底，梧桐树描冻，稀稀点点的鲜花点缀。感叹“还不奈”，和上海就差这座山和我大璧山就差岁月。沿着向上的街道走，有许多本地人在这散步，新型肺炎突来，也不能打断，锻炼身体的节奏。 ​ 继续往上走，突然要收我门票，原来这是城隍阁。 ​ 阁来，行道走遍，古代名人诗句显然。顿时文化气息弥漫。阁前，宏伟悠久。阁中，科技超前。阁上，西湖尽收眼底。整体感受，不用花15的学生价，不过第一次来还算讲究。整体建筑的风格、地基的建设和阁经营机制都和各地庙或者阁差不多。唯一好的就是能够看到西湖。惊奇就是，阁中有电梯，有高档酒店，有喝茶的地方。文化和商业结合，挺不错的，门票都要30，古人看了都说好，必须一次游。信手拈来风景有: 找到雷锋塔了吗？这可是东坡先生赞美的西湖哟！ ​ 《饮湖上初晴后雨》 ​ 水光潋滟晴方好 ​ 山色空蒙雨亦奇 ​ 欲把西湖比西子 ​ 淡妆浓抹总相宜 ​ woc，还行。 下阁，到十二生肖，没什么看的，一堆小孩在爬兽雕像（杜绝吃野味！！！） 翻山（真是翻山，不要走小路，有鲁迅说的小道，嘻嘻），大观台还行，下台，遇帘。 154年的长春藤还阔以。还拾得坚硬的种子一枚（用脚使劲磨，皮都不坏，所以白嫖一枚）。就在这不走直道上山，另辟蹊径斜到，忽喜- 真乃“天欲雪，云满湖，楼台明灭山有无。水清出石鱼可数，林深无人鸟相呼……” —–《腊日游孤山赠惠勤惠思二僧》 挺惊喜，发现初中学诗句中的清塘。顿时心情更加愉悦了，哈哈哈。 山半腰，如果吃饱饭，来散步，挺不错的。生活在这里的人，实在让人羡慕，哈哈哈。（写到这，20200205 18:15 昨天应该也是这点，昨天忘记保存了，忙着和伙伴吃鸡，直接关电脑保存了，哎，铭记于心） 走到这，是浙江烈士墓纪念碑，挺宏伟的，挺让人感触的。就像我现在能够吃饱喝饱在家等外卖打字。是因为解放军的保护伞，天使们的无私奉献，还有快递小哥的爱心守护，哈哈哈。不过我也很棒，在家做贡献呢！我可没有外出，嘿！！！。 纪念碑以及纪念馆，长廊我就没有拍了，尊重，肃穆。还有人来给烈士上香的。下山遇见，应该是00后吧，小学生带着红领巾给我“参观烈士革命文化调查表”，我还真不认识表中的革命家，哈哈哈（丢面）。不过他们没有带口罩，带队的小哥哥也没有带！！！（看来那是的宣传力度不够大） 下山，邂逅西湖。 西湖边。突然下起了下午，在亭下占休，望着湖边。还挺舒服的，还好穿得厚，不是还真有小冷。只是不知道能不能遇见白蛇娘子。雷峰塔越来越近了。。。 塔下，戴口罩的依然挺少，不过这有电梯，还挺新奇。塔中，亦有电梯，我选择楼梯上塔，电梯下塔。 塔中： 塔中就这个还行，不过类似的，想大家都怕见过，只是文化输出一样，底楼就是雷峰塔旧时的地基。没什么可看的，纪录片还行。 塔上： 知道为什么要来近拍这个吗？ 只是在一片长春树下，只有这两棵树凋谢。人，生来平等？ 这里人挺多的。门票费40,。康康西湖还讲究吧。大部分人只是花40元来做一个电梯。但是文化人就是不一样了，但这儿女，统计画壁上文化记载和百度修补，给儿女文化输出。比火车上夫妻好多了，哈哈。不过小孩表现到不一样，有的好奇问爸妈，爸妈无奈只有百度讲，有的被迫不无奈听爸妈讲。哈哈哈，还挺有趣。 塔外： 赶脚刚修完不久，周边也没什么可看的。只能说夏天乘凉还不赖吧！ 然后就去了苏堤。看了一下苏东坡纪念馆： 这字还阔以吧，我看到顿时就笑了（这不是和我写得差不多呢！都是人，为何他这么优秀）。 周边还是好的，人少，野鸭挺可爱的，头带着脚移动的永动机。 “柳“通”留“！！！枯叶的柳，很意境。。。 这字写得真好看！！！ 花港观鱼，tm没有与，里面风挺大，树很高，夏天散步不错！ 然后一路从苏堤-宝石流霞，走了好久。。。打着闪，手冷到爆，不过风景挺让人心静的，就是太冷。 宝石山，我到的时候要五点过了吧，西湖博物馆都关门了。景点博物馆赶脚4:30就关门了。和网友所说，这里还是很不错的。晚上可以一去，爬山注意安全，女生一个人还是免了，像我这种钢铁直男，爬山长大的，还是很有吸引力的，夜景也挺不错的哦！ 不过宝石山塔，在修所以不能进，宝石流霞，是一个小山坡一个小山破累上去的。虽然写着不要攀爬，我还是一个一个爬了，跟攀岩似的，还挺带劲，哈哈哈。一山比一山高，爬了一个上去，woc，还有一个。woc，这里有路。哈哈哈。晚上，大家如果要去，注意安全。请勿攀爬！！！ 下面这些图，其实都是晚上拍的，天气挺黑的了，华为mate30做了渲染的。 然后就下山，脚好累，看了一下支付宝，走了将近四万不，打开运动集福，还真走完了西湖，哈哈哈。 下山后，我一直祈祷有一个哈罗单车，哈哈哈。走了几步，还真看见了，真实幸福。沿着西湖岸边骑行，手机看了有什么好吃的，然后定了一个青旅，好巧不巧。刚好在鼓楼傍边。我的起点。先定了一晚上，看好不好。最后赶脚不错，才定的第二晚。房间还不错，高低床，挺高的。还需要学生证入住，挺安全的，哈哈哈。45每晚。就是是公共厕所，热水需要挺久。评分5.0。 对于吃饭，小吃周边很多的大商场也挺多。修得挺气派的。有兴趣购物的，可以去康康。我就康了一下苹果专卖店。因为修得比上海南京路的更加气派。样式差不多，哈哈。像美食街，什么杭州特产，看了评论等，最好不去，基本每个村都有，哈哈。不过本地人排队的，到还行。青旅对面有家早餐店，挺不错的，煎饺，豆腐脑，价廉好吃。 不过吃饭的时候，看见一对夫妻，女的和我一样点的黄瓜粥，只不过没有杭州包子，男的，吃的面样，挺简单的。他们途中男的没说话，玩手机。最后女生生气了。说他闷气，又不沟通，一天就知道玩手机。骂了一会，男的也不敢说什么，最后女的付完钱走了，男的坐了一会，带着东西走了。我想生活不易啊，可我还是单身狗。钢铁直男万岁。还有就是我对面一桌阿姨点了一碗面。然后，在吃的时候叫服务员过来，说我的钱包丢了，付不起钱，还把全部口袋拿出来看，服务员也没说什么，必进过年吧。 回旅馆，和朋友开了几把黑，美美的睡上一觉，真实舒服啊。只有累了，才知道睡觉也是一种享受。就像现在的天使，就该惩罚他们睡觉。 总结： 打卡景点，第一次就行了，图个没去过，人多的话，还是最好不去（花钱可以不去，性价比较低）。 2. 西湖散步还是很不错的，有女朋友更好，我可吃了不少狗粮呢！ 3. 吴川景区，爬一下山，也挺不错的。 4. 宝山塔，那边的景区也挺不错的。 5. 玩这些景点，我走得比较慢，我还是走了整整一天。必进我去了很多小路。如果高峰期去还是计划好，根据实际情况，针对性玩。（注意正确地带口罩！！！） 未完待续…]]></content>
      <categories>
        <category>-[随笔]</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[spark与pandas 如何构建分类模型]]></title>
    <url>%2F2020%2F01%2F20%2Fspark%E4%B8%8Epandas-%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[spark与pandas 如何构建分类模型本章通过sklearn，鸢尾花数据，通过pandas的DataFrame与spark的DataFrame之间转化，构建spark多分类模型，并且图调参以及得到最佳参数和评价分数。具体代码流程如下： 导入相关工具包12345678910111213141516171819import numpy as npimport pandas as pdimport sklearn.datasets as sdfrom pyspark.context import SparkContextfrom pyspark.sql.context import SparkSessionfrom pyspark.sql import Rowfrom pyspark.ml.linalg import Vectorsfrom pyspark.mllib.regression import LabeledPointfrom pyspark.ml.tuning import ParamGridBuilder,CrossValidatorfrom pyspark.ml.classification import LogisticRegressionfrom pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModelfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator,BinaryClassificationEvaluator 导入数据以及转换数据结果12345678910111213141516171819202122232425262728293031sc = SparkContext('local','iris_logistic')spark = SparkSession(sc)#获取鸢尾花数据data = sd.load_iris()#data_x = data.data[:100,:]#data_y = data.target[:100]data_x = data.datadata_y = data.target#转为DataFrame类型-pandasdata_x = pd.DataFrame(data_x)data_x.columns = ['sw','sh','dw','dh']print(data_x.dtypes)data_x['label'] = data_y#转为DataFrame类型-sparkdata_x = spark.createDataFrame(data_x)print(data_x)#labeledPoint 只能实现二分类#parsedData = data_x.rdd.map(lambda row:LabeledPoint(row[-1], Vectors.dense(row[:-1])))#print(parsedData .collect())#training = sc.parallelize(training)train_x, test_x = data_x.randomSplit([.75,.25],38)#通过Row 建立X和Y 多分类数据结构row = Row( 'label','features')train_x = train_x.rdd.map(lambda v: (row(v[-1],Vectors.dense(v[:-1])))).toDF()test_x = test_x.rdd.map(lambda v: (row(v[-1],Vectors.dense(v[:-1])))).toDF()print(train_x.show(2)) 构建模型以及输出最佳参数-评价分数123456789101112131415161718192021222324252627282930313233343536#建立模型lr = LogisticRegression()#构建参数图，进行网筛选最佳参数grid = ParamGridBuilder()\ .addGrid(lr.maxIter, [8, 18])\ .addGrid(lr.regParam, [0.1, 0.01]) \ .addGrid(lr.fitIntercept, [False, True])\ .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\ .build()#建立多分类 结果估计器evaluator = MulticlassClassificationEvaluator()cv = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator, parallelism=2,numFolds=2)#训练以及预测cvModel = cv.fit(train_x)pre=cvModel.transform(test_x)print(evaluator.evaluate(pre))#输出结果selected = pre.select("features", "label", "probability","prediction")for s in selected.collect(): print(s)def getBestParam(cvModel): params = cvModel.getEstimatorParamMaps() avgMetrics = cvModel.avgMetrics all_params = list(zip(params, avgMetrics)) print(all_params) best_param = sorted(all_params, key=lambda x: x[1], reverse=True)[0][0] return best_param#输出最佳参数best_param = getBestParam(cvModel)for p, v in best_param.items(): print("&#123;&#125; : &#123;&#125;".format(p.name, v))]]></content>
      <categories>
        <category>spark</category>
      </categories>
      <tags>
        <tag>algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chapter2 最小二乘法完整实践理论]]></title>
    <url>%2F2019%2F11%2F20%2Fchapter2-%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E5%AE%8C%E6%95%B4%E5%AE%9E%E8%B7%B5%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[chapter2- 最小二乘法完整实践理论1.概要​ 此章，通过最小二乘法，在统计学习，机器学习，深度学习的轨道上进行讨论，它们叁之间的共性与异性。 2.什么是最小二乘法​ 最小二乘法（least squares method），又称最小平方法，是一种数学优化方法。它通过最小化误差的平方和寻找数据的最佳函数匹配。 ​ 利用最小二乘法可以简便地求得未知的数据，并使得求得的数据与实际数据之间误差的平方和为最小。 ​ 高斯于1823年在误差$e_1,…,e_n$独立同分布的假定下,证明了最小二乘方法的一个最优性质: 在所有无偏的线性估计类中,最小二乘方法是其中方差最小的。 对于数据$(x_i,y_i)(i = 1,2,3,…,m)$,能够拟合出下列公式（1），即是一个多项式函数$$h_\theta(x_1,x_2,…x_n)=\theta_0+\theta_1x_1+…+\theta_{n−1}x_{n−1}$$ ​ 利用数据$(x_i,y_i)$代入公式1,利用数学知识是能够解出最佳拟合参数$W_i$。即能够得到$H(x)$使得与真实值相差最小—残差$e_i$。因此，得到一个代价函数(Cost Function)，亦为损失函数(公式2)。 $$min\sum_{i=1}^{m}e_i = \min\sum_{i=1}^n(y_i-h_θ(x^{(i)})^2$$ 3.统计学中如何去解最小二乘法​ 我们以一次线性函数模型来进行用数学公式求解，让大家初始一下统计学如何去拟合数据的。对于高阶函数，统计学知识求解，感兴趣的同学，可以去Google一下。 3.1 代数法求解最小二乘法​ 最简单的线性式$h_\theta= \theta_1x + \theta_0$有代价函数为：$$J(\theta_1,\theta_0) =\sum_{i=1}^n(y_i-h_θ(x^{(i)})^2=\sum_{i=1}^n(y_i-\theta_1x - \theta_0)^2$$​ 有了公式(3)代价函数，我们如何去使它最小了，最常用的解法就是对$\theta_1$和$\theta_0$分别求编导，令编导为 零，就可以解出$\theta_1$和$\theta_0$的值，即过程为： ​ $J(\theta_1,\theta_0)$对$\theta_0 $求导，得到如下方程：$$\sum_{i=1}^m(y^{i}-\theta_0-\theta_1x^{(i)}) = 0$$​ $J(\theta_1,\theta_0)$对$\theta_1 $求导，得到如下方程：$$\sum_{i=1}^m(y^{i}-\theta_0-\theta_1x^{(i)})x^{(i)} = 0$$​ 公式(4)、(5)组成一个二元方程组，容易解出$\theta_1$和$\theta_0$的值 ​$$\theta_0=\frac{\sum_{i=1}^m(x^{(i)})^2\sum_{i=1}^my^{x^{(i)}}-\sum_{i=1}^mx^{(i)}\sum_{i=1}^mx^{(i)}y^{(i)}}{m\sum_{i=1}^m(x^{(i)})^2 - (\sum_{i=1}^mx^{(i)})^2}$$ $$\theta_1=\frac{m\sum_{i=1}^mx^{(i)}y^{(i)} - \sum_{i=1}^mx^{(i)}\sum_{i=1}^my^{(i)}}{m\sum_{i=1}^m(x^{(i)})^2 - (\sum_{i=1}^mx^{(i)})^2}$$ ​ 利用求导的方式,很容推广到多个样本特征的多项式拟合当中。即在拟合函数公式(1)当中，求解参数 $\theta_i(i=0,1,2,3,\cdots,m)$,可以简化拟合函数为：$$h_θ(x_1,x_2,…x_n)=\sum_{i=0}^{n}\theta_ix_i$$​ 损失函数就可以表示为：$$J(\theta_0,\theta_1,\cdots,\theta_j) =\sum_{i=1}^m(h_θ(x_0^{(i)},x_1^{(i)},\cdots,x_j^{(i)}) - y^{(j)})^2=\sum_{i=1}^n(\sum_{j=1}^m\theta_jx_j^{(i)}-y^{(i)})^2$$​ 利用损失函数分别对$\theta_i(i=0,1,2,3,\cdots,m)$求导，并令导数为0可得：$$\sum_{i=1}^n(\sum_{j=1}^m\theta_jx_j^{(i)}-y^{(i)})x_j^=0 \ (j=0,\cdots,m)$$​ 就可以得到一个M+1个一元方程组，求解这个方程组，就可以得到所有的$\theta_i(i=0,1,2,3,\cdots,m)$。代 入参数到$h_\theta$就可以得到拟合函数了 3.2 矩阵法求解最小二乘法​ 对于上述$h_\theta$,矩阵表达式形式为： $$h_\theta(X) = \theta X$$​ 即$h_{\theta}=y= \theta_1 x + \theta_0$,写成代价矩阵式为: 12345678910111213141516171819202122232425$$\min\limits_&#123;x_0,x_1&#125;\begin&#123;Vmatrix&#125; \begin&#123;pmatrix&#125; \theta_0\\ \theta_1 \end&#123;pmatrix&#125; \begin&#123;pmatrix&#125; 1&amp;x_1 \\ .&amp;. \\ .&amp;. \\ .&amp;. \\ 1&amp;x_m \\ \end&#123;pmatrix&#125; - \begin&#123;pmatrix&#125; y_1\\ .\\ .\\ .\\ y_m \\ \end&#123;pmatrix&#125;\end&#123;Vmatrix&#125;_2 =\ \min\limits_&#123;x&#125;||\theta X-Y||_2$$ ​ 化简为矩阵损失函数 $J(θ)=\frac{1}{2}(θX−Y)^T(θX−Y)$，其中， 假设函数$h_{\theta}(X)$为mx1的向量,$\theta$为nx1的 向量，里面有n个代数法的模型参数。$X$为$m\times n$维的矩阵。m代表样本的个数，n代表样本的特征数. ​ 对于损失函数求导，并且令为0，可能 ​$$\frac{\partial}{\partial \theta}J{(\theta)} = X^T(X\theta-Y) = 0$$​ 这里用到了矩阵求导链式法则，和两个矩阵求导的公式： ​ 公式1: $\frac{\partial}{\partial x}(X^TX) = 2X \ x为向量$ ​ 公式2: $ \Delta_X f(AX+B)=A^T\Delta_Y f,Y=AX+B,\ f(Y)为标量$ ​ 对上述求导等式整理后可得：$$X^TX\theta = X^TY$$​ 两边同时左乘$(X^TX)$可得：$$\theta = (X^TX)^{-1}X^TY$$​ 这样就可以求出$\theta$向量表达式的公式，免去了代数法一个个去求导的麻烦.只要给了数据，就可以用公式(15)算出$\theta$,得到数据拟合函数$h_{\theta}(X)$了。 4.机器学习实现最小二乘法现在我们使用机器学习方法去实现最小二乘法。这里选择Python3.7进行实现。 逻辑步骤如下： a.导入相关的工具包以及定义相关函数123456789101112131415161718192021import numpy as npimport scipy as spfrom scipy.optimize import leastsqimport matplotlib.pyplot as plt%matplotlib inline# 目标函数def real_func(x): return np.sin(2*np.pi*x)# 多项式def fit_func(p, x): f = np.poly1d(p) return f(x)# 残差def residuals_func(p, x, y): ret = fit_func(p, x) - y return ret b.生成线性函数数据123456789# 十个点nums = 10#等差x = np.linspace(0, 1, nums)# print(x)x_points = np.linspace(0, 1, 1000)# 加上正态分布噪音的目标函数的值y_ = real_func(x)y = [np.random.normal(0, 0.1) + y1 for y1 in y_] c.创建拟合函数并且可视化数据12345678910111213141516def fitting(M=0): """ M 为多项式的次数 """ # 随机初始化多项式参数 p_init = np.random.rand(M + 1) # 最小二乘法 求导得到参数theta p_lsq = leastsq(residuals_func, p_init, args=(x, y)) print('Fitting Parameters:', p_lsq[0]) # 可视化 plt.plot(x_points, real_func(x_points), label='real') plt.plot(x_points, fit_func(p_lsq[0], x_points), label='fitted curve') plt.plot(x, y, 'bo', label='noise') plt.legend() return p_lsq d.训练数据12# M=0p_lsq_0 = fitting(M=0) 12# M=1p_lsq_1 = fitting(M=1) 12# M=3p_lsq_3 = fitting(M=3) 12# M=9p_lsq_9 = fitting(M=9) ​ 随着M阶数的增加，函数对点的拟合程度也随之提高，当M=3时，函数拟合程度的泛化能力算是最好的。当M=9的时候，函数把每一个点都进行了拟合，并且都在线上，也就是说在训练集当中，准确率为100%，但是如果设置测试集，M=9拟合的函数一定没有M=3的函数的泛化能力强。下面，介绍正则化。当我们追求准确率时，又要保证函数的泛化能力，正则化是一个很好的技巧，可以有效的防止过拟合问题。当然不同的正则化，适应着不同的数据分布，随着我们篇章的书写，会继续讨论相关问题。 123456regularization = 0.0001def residuals_func_regularization(p, x, y): ret = fit_func(p, x) - y ret = np.append(ret,np.sqrt(0.5 * regularization * np.square(p))) # L2范数作为正则化项 return ret 123# 最小二乘法,加正则化项p_init = np.random.rand(9 + 1)p_lsq_regularization = leastsq(residuals_func_regularization, p_init, args=(x, y)) 123456789#可视化正则化后与不适用正则化之间的效果的效果plt.plot(x_points, real_func(x_points), label='real')plt.plot(x_points, fit_func(p_lsq_9[0], x_points), label='fitted curve')plt.plot( x_points, fit_func(p_lsq_regularization[0], x_points), label='regularization')plt.plot(x, y, 'bo', label='noise')plt.legend() 从上图，可以看出，正则化对于模型的泛化能力还是很有效果的，当然增加拟合数据x，y的数量，拟合程度降维更好，有兴趣的同学可以试一试。 5. 深度学习实现最小二乘法现在我们使用深度学习方法去实现最小二乘法。这里选择TensorFlow 2.0进行实现。可以使用在线编译器google-colab-notebook. 逻辑步骤如下： a.导入工具包12%tensorflow_version 2.ximport tensorflow as tf 123456789101112131415161718#目标函数def real_func(x): y = tf.sin(2*np.pi*x) return yclass Model(object): def __init__(self): self.W_1 = tf.Variable(tf.random.uniform([1])) # 随机初始化参数 self.W_2 = tf.Variable(tf.random.uniform([1])) self.W_3 = tf.Variable(tf.random.uniform([1])) self.b = tf.Variable(tf.random.uniform([1])) def __call__(self,x): y_pred = self.W_1*x + self.W_2*x**2 + self.W_3*x**3 + self.b return y_preddef loss(predicted_y, desired_y): return tf.reduce_mean(tf.square(predicted_y - desired_y)) 12345678910#拟合数据nums = 100000 #产生数据的点数t_x = tf.linspace(-1.0,1.0,nums)#加入正太分布噪声noise = tf.random.truncated_normal([nums,], mean = .0, stddev = .1, dtype=tf.float32, seed = 38)t_y = real_func(t_x) + noise# print(t_y)#原图像t_x_points = tf.linspace(-1.0,1.0,10000)t_y_points = real_func(t_x_points) 123456789101112#这里建立3阶拟合函数，可以自行增加拟合函数的阶数，注意需要更新的参数W.def train_step(model, inputs, outputs, learning_rate): with tf.GradientTape() as tape: current_loss = loss(model(inputs), outputs) dW_1, dW_2, dW_3, db = tape.gradient(current_loss, [model.W_1, model.W_2, model.W_3, model.b]) #加入优化器 能够提升 0.550 -- 0.506 optimizer.apply_gradients(zip((dW_1, dW_2, dW_3, db), [model.W_1, model.W_2, model.W_3, model.b])) model.W_1.assign_sub(learning_rate * dW_1) model.W_2.assign_sub(learning_rate * dW_2) model.W_3.assign_sub(learning_rate * dW_3) model.b.assign_sub(learning_rate * db) 1234567891011121314151617181920#加载模型变量model = Model()#加载优化算法 optimizer = tf.keras.optimizers.Adam()# 收集 W 和 b 的历史数值，用于显示current_loss = 0Ws1, Ws2, Ws3, bs = [], [], [], []epochs = range(100)for epoch in epochs: Ws1.append(model.W_1.numpy()) Ws2.append(model.W_2.numpy()) Ws3.append(model.W_3.numpy()) bs.append(model.b.numpy()) current_loss = loss(model(t_x), t_y) train_step(model, t_x, t_y, learning_rate=0.01) print('Epoch %2d: W1=%1.2f W2=%1.2f W3=%1.2f b=%1.2f, loss=%2.5f' % (epoch, Ws1[-1], Ws2[-1], Ws3[-1], bs[-1], current_loss))print("current_loss %.3f" % current_loss) 123456789#通过获得参数，实现拟合函数def pre_f(x): f = Ws1[-1]*x + Ws2[-1]*x**2 + Ws3[-1]*x**3 + bs[-1] return f#可视化拟合函数plt.plot(t_x_points.numpy(), t_y_points.numpy(),label = 'real')plt.plot(t_x.numpy(), t_y.numpy(),label = 'noise')plt.plot(t_x.numpy(), pre_f(t_x).numpy(), label = 'pre')plt.legend() ​ 可见，在小量的数据当中，深度学习的效果，不尽人意，和ML实现的效果相比，相差还是较大的。你可以把数据量以及迭代次数增加，可以增加拟合效果，特别是数据量的增加，可以有效的提升模型的效果。如果感兴趣，可以试一试。当然深度学习的正则化亦有效果的。 6. 总结三者之间的联系以及区别。​ 通过统计学，机器学习，深度学习上理论和实践的讲述。我们很容易从中总结如下几点它们之间的联系与区别。 a.联系​ 1.每一种学习都离不开坚实数学知识基础。 ​ 2.机器学习和深度学习代码实践上都由统计学学习理论支撑，即三者在实现最小二乘法上的逻辑一致。 b.区别​ 1.可以发现统计学学习在参数，数据量较大和函数阶数较大后，实现最小二乘法基本是不可能的事情，进行对数值较大的计算，并且在生活中，数据量是较大的，人工完成，工具量极大，并且准确率不能够保证，所以产生机器学习。 ​ 2.机器学习没有把统计学理论上的结果，完完全全的实现，只是拟合出来的函数，能够逼近正确结果，也就是近似值。所以在机器学习当中，模型的鲁棒性(robust)显得格外重要。当然传统的机器学习在数据量上的运行亦是有限制的。所以在一些方面产生了深度学习去训练。比如nlp，cv… 3.由于数据量已经超级巨大(部署与分布式)，并且在某些方面深度学习有较大的优势，因为它在数据量极大的时候，效果更好，更快并且自动化提取特征。 ​ 总之，我们从统计学学习-&gt;机器学习-&gt;深度学习,依次完成了最小二乘法。希望大家能够在流程与实践当中，能够体会到数学基础的重要性，以及三者之间的实质联系与区别。 参考文献@(*.*)@ @(^.^)@ @(*.*)@ @(^.^)@ @(*.*)@ @(^.^)@ @(*.*)@ @(^.^)@ @(*.*)@ @(^.^)@ 统计学习方法概论 最小二乘法原理 TensorFlow 2.0基础]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chapter3-感知机]]></title>
    <url>%2F2019%2F11%2F20%2Fchapter3-%E6%84%9F%E7%9F%A5%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[chapter3-感知机1.概要通过上一章最小二乘法的理论与实践，我们知道统计学学习-机器学习-深度学习，它们之间的联系与区别。本章我们将讨论感知机算法，再次讨论他们叁之间的关系。并且很有必要熟悉感知机，虽然它现在在分类模型当中已经不适用，因为泛化能力有限，能力更强的为支撑向量机(svm)。但是它在机器学习和深度学习其他深奥算法上有较大的联系，甚至为其算法逻辑实现基础。掌握它的思想，为进一步的提升，打下坚实的基础。 2.感知机模型原理首先感知机算法是一种二分类线性算法。当然也可以提升至多维分类模型上，但是都是线性模型，对于非线性的，神经网络了解一下。感知机学习算法：用一个函数输入$x$(一个实值的向量)映射到输出值$f(x)$(一个二元值):$$f(x)=\begin{cases} 1 \qquad if \quad w.x + b &gt; 0 \ \ -1 \qquad other wise\end{cases}$$ 对于多维来说，如果我们有m个样本，每个样本对应于n维特征和一个二元类别输出，如下：$$(x_1^{(0)},x_2^{(0)},\cdots ,x_n^{(0)},y_0),\(x_1^{(1)},x_2^{(1)},\cdots ,x_n^{(1)},y_1),\(x_1^{(2)},x_2^{(2)},\cdots ,x_n^{(2)},y_2),\\cdots,\(x_1^{(m)},x_2^{(m)},\cdots ,x_n^{(m)},y_m)$$目标是找到一个如下平面去分割数据，即为：$$\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_3+\cdots+\theta_nx_n =0$$比较函数$f(x)$我们亦可以找出一个平面作为二分类平面,即为：$$f(x)=\begin{cases} \theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_3+\cdots+\theta_nx_n&gt;0 \ \theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_3+\cdots+\theta_nx_n&lt;0\end{cases}$$当然，我们是可以进行简化公式3的，拟定一个$x_0=1$，这样就有一个超平面$\sum_{i=0}^n \theta \bullet x$ 其中，$\theta$和$x$都是$(n+1)\times1$的向量,之间内积就组成一个平面。 感知机模型定义为，$y=sign(\theta \bullet x)$,其中$$sign(x)=\begin{cases}-1 \quad x&lt;0 \ 1 \quad x\geq 0 \end{cases}$$ 3.感知机模型损失函数从公式(5)可以看出令我们把的结果分为1和-1而不是0，这样我们可以很好的去判断分类结果是否正确，比如$y\theta \bullet x=1$(预测结果与真实样本同号，即为正确)，反之，$y\theta \bullet x=-1$则为分类错误。 对于感知机模型函数，我们目标就是使分类错误的点到超平面$y$的距离和最小，由于$y\theta \bullet x&lt;0$,所以对于每一个被错误分类的样本$i\in M$(其中M个分类错误点)到超平面的距离为：$$\frac{-y^{(i)}\theta \bullet x^{(i)}}{\begin{Vmatrix} \theta \end{Vmatrix}_2}$$其中${\begin{Vmatrix} \theta \end{Vmatrix}_2}$为L2范数 即可得到初步的损失函数:$$J\theta = -\sum_{i=0,i \in M}^{n}\frac{y^{(i)}\theta \bullet x^{(i)} }{\begin{Vmatrix} \theta \end{Vmatrix}_2}$$观察公式(7)，容易看出，分子分母都带有$\theta$，利用简单的数学知识可以看出，不管$\theta$如何增加还是减小，对于 $J(\theta)$来说都是同倍数增加减的。所以，我们可以把分子分母中的$\theta$简化一个，即，我们保留分子中的$\theta$。因此，简化后的损失函数为:$$J(\theta) = - \sum_{i=0,i \in M}^{n}{y^{(i)}\theta \bullet x^{(i)} }$$如果您了解支撑向量机(svm)的话，他的损失函数，是保留的分母，也就是:$$min\frac{1}{\begin{Vmatrix}\theta\end{Vmatrix}} \Leftrightarrow min\frac{1}{2}\begin{Vmatrix}\theta\end{Vmatrix}_2$$ 3.感知机模型的优化算法根据上述的推论。我们已知感知机模型算法的损失函数，因此，我们可以去迭代损失函数去找到最优参数$\theta$,依据原理可知，损失函数是通过对分类错误的样本进行更新，使之模型能够分类，正确。通常感知机模型的优化算法常用梯度下降算法(Gradient Descent)、拟牛顿算法，进行去优化。对于梯度下降算法分为批量梯度下降算法(BGD),随机梯度下降算法(SGD)和小批量随机梯度算法(MBGD)。由于感知机算法是对错误样本进行更新，所以不能够使用BGD,我们将用常用的SGD进行举例说明. 因此，我们对损失函数$J(\theta)$,对$\theta$进行求导可得:$$\frac{\partial }{\partial \theta_i}J(\theta_0,\theta_1,\cdots,\theta_j) =-\sum_{x_i\in M}y^{(i)}x^{(i)}$$即更新损失函数$J(\theta)$梯度下降公式:$$\theta=\theta+\alpha\sum_{x_i\in M}y^{(i)}x^{(i)}$$由于我们采用SGD，所以每次仅仅只需对一个误分类样本进行更新梯度。即假设采用第$i$个样本来更新，则可以假话公式为:$$\theta=\theta+\alpha y^{(i)}x^{(i)}$$其中$\alpha$为步长，$y^{(i)}$为样本输出结果(1 | -1),$x^{(i)}$为$(n+1)\times1$的向量。 4.感知机模型算法我们已经通过上述讨论，知道感知机模型算法的细枝末节，现在我们来总结，如何去实现此算法。 首先我们确定样本特征。对于特征如下:$$(x_1^{(0)},x_2^{(0)},\cdots ,x_n^{(0)},y_0),\(x_1^{(1)},x_2^{(1)},\cdots ,x_n^{(1)},y_1),\(x_1^{(2)},x_2^{(2)},\cdots ,x_n^{(2)},y_2),\\cdots,\(x_1^{(m)},x_2^{(m)},\cdots ,x_n^{(m)},y_m)$$对于样本输出结果$y^{(i)} \in(1,-1)$的二分类。 初始化所有$x_0 = 1$，对于参数$\theta$ 初始化为1,$\alpha$步长初始化0.8。 判断是否有样本满足$y\theta \bullet x=-1$，即为误分类样本，并且从中选择一个样本$x_i$, 对选择样本$x_i$进行更新参数$\theta_i$,更新后进入步骤3。 $$\theta=\theta+\alpha\sum_{x_i\in M}y^{(i)}x^{(i)}$$ 如果没有误分类样本就结束训练.此时的$\theta$即为最佳参数。 5.感知机算法的对偶形式感知机算法的对偶形式是对梯度下降过程进行优化，对于函数 $$f(x)=\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_3+\cdots+\theta_nx_n$$求导得到梯度可得:$$f(x)=\begin{cases} \theta_i^{(j)} = \sum_{i=1}^{n}\alpha y_i^{(j)}x_i^{(j)} \quad j \in m\ \theta_0 = \sum_{i=1}^{n} \alpha y_i\end{cases}$$对于梯度函数只对错误样本进行更新梯度，如果错误样本$j \in m$,那么对于错误样本$j$，函数分错一般就在拟合函数之间。如果你知道支持向量机(svm)的话，那么这些点就可能就是支撑向量点。而对于这些点迭代次数为$m_j$的话，由于$\alpha$亦为常数，我就可以令$\alpha m_j=\beta_j$,因此函数可以重写为:$$f(x)=\begin{cases} \theta_i^{(j)} = \sum_{i=1}^{n}\beta_j y_i^{(j)}x_i^{(j)} \quad j \in m\ \theta_0 = \sum_{i=1}^{n} \beta_j y_i\end{cases}$$对于对偶式，将公式(17)代入$y=sign(\theta \bullet x)$(假定了$x_0$=1),对于一次函数来说，有~$$f(x)=sign(\theta_1x+\theta_0)=sign(\sum_{j=1}^{m}\beta_j y_jx_j\bullet x_i+\sum_{j=1}^{m} \beta_j y_j) \quad j \in m$$即可判断是否为错误分类点公式为:$$y_i(\sum_{j=1}^{m}\beta_j y_jx_j\bullet x_i+\sum_{j=1}^{m} \beta_j y_j) &lt; 0\qquad(19)$$根据公式(18)，依据$y=\theta_1x+\theta_0$的形式代入公式(5)中，即得。观察公式(18)，我们可以看出有内积$G=x^{(i)}\bullet x^{(j)}$,两个常量矩阵内积令为$G$。我们可以事先算出$G$，进行查矩阵表形式给出值，就可以省下大量的计算。因此优化了梯度下降算法。本质就是对错误样本的删选算法形式进行优化。 因此，感知机对偶形式算法实现为！ ​ 1.初始化所有$x_0 = 1$，对于参数$\theta$ 初始化为1,$\alpha$步长初始化0.8，$\beta$为0。同上，不同初始值会带来不同的效果 ​ 2.计算样本内积Gram矩阵$G$ ​ 3. 在训练集里面选择一个误分类的点$(x^{(i)},y^{(i)})$,这个点应满足公式(19)，在检查是否满足时，就可以通过查询Gram矩阵的$G_{ij}$，的值，快速计算是否小于0 ​ 3.对$\beta$错误样本$i$分量进行更新$\beta_i =\beta_i+\alpha$ ​ 4.检查训练集里是否还有误分类的点，如果没有，算法结束，此时的$\theta$向量最终结果为下式。如果有,继续第2步 $$\begin{cases} \theta_i^{(j)} = \sum_{i=1}^{n}\beta_j y_i^{(j)}x_i^{(j)} \quad j \in m\ \theta_0 = \sum_{i=1}^{n} \beta_j y_i\end{cases}$$ 6.感知机算法代码实践6.1.感知机模型算法实现 导入相关工具包 12345import pandas as pdimport numpy as npfrom sklearn.datasets import load_irisimport matplotlib.pyplot as plt%matplotlib inline 加载数据 123456789# load datairis = load_iris()df = pd.DataFrame(iris.data, columns=iris.feature_names)df['label'] = iris.targetdf.columns = [ 'sepal length', 'sepal width', 'petal length', 'petal width', 'label']df.label.value_counts() 数据可视化 12345plt.scatter(df[:50]['sepal length'], df[:50]['sepal width'], label='0')plt.scatter(df[50:100]['sepal length'], df[50:100]['sepal width'], label='1')plt.xlabel('sepal length')plt.ylabel('sepal width')plt.legend() 划分数据集与样本 1234#iris数据集是三类样本没类样本数量为50 所以只取前两个样本data = np.array(df.iloc[:100, [0, 1, -1]])X, y = data[:,:-1], data[:,-1]y = np.array([1 if i == 1 else -1 for i in y]) 5.建立感知机模型 12345678910111213141516171819202122232425262728293031# 数据线性可分，二分类数据# 此处为一元一次线性方程class Model: def __init__(self): self.w = np.ones(len(data[0]) - 1, dtype=np.float32) self.b = 0 self.l_rate = 0.1 # self.data = data def sign(self, x, w, b): y = np.dot(x, w) + b return y # 随机梯度下降法 def fit(self, X_train, y_train): is_wrong = False while not is_wrong: wrong_count = 0 for d in range(len(X_train)): X = X_train[d] y = y_train[d] if y * self.sign(X, self.w, self.b) &lt;= 0: self.w = self.w + self.l_rate * np.dot(y, X) self.b = self.b + self.l_rate * y wrong_count += 1 if wrong_count == 0: is_wrong = True return 'Perceptron Model!' def score(self): pass 建立对偶形式感知机模型 12345678910111213141516171819202122232425262728293031323334353637383940414243G = np.dot(X,X.T)print(G,G.shape,y.shape)# 数据线性可分，二分类数据# 此处为一元一次线性方程class Model_Dual: def __init__(self): self.w = np.ones(X.shape[1], dtype=np.float32) self.beta = np.zeros(data.shape[0], dtype=np.float32) self.b = 0 self.l_rate = 0.1 # self.data = data def sign(self, x, w, b, y): y_ = np.sum(y*w*x + b) return y_ # 随机梯度下降法 def fit(self, X_train, y_train): is_wrong = False while not is_wrong: wrong_count = 0 for d in range(X_train.shape[0]): X = G[d] y = y_train[d] x = X_train[d] sum_v = 0 for d1 in range(X_train.shape[0]): #print(self.beta[d1] , y_train[d1] , X[d1]) w1 = self.beta[d1] * y_train[d1] * X[d1] b1 = self.beta[d1] * y_train[d1] sum_v += (w1 + b1) if y*sum_v &lt;= 0: self.beta[d] = self.beta[d] + self.l_rate wrong_count += 1 if wrong_count == 0: is_wrong = True return 'Perceptron Model!' def score(self): pass 训练模型 123456perceptron = Model()perceptron.fit(X, y)#@title Default title textperceptron = Model_Dual()perceptron.fit(X, y) 可视化结果() 12345678910#普通形式训练结果x_points = np.linspace(4, 7, 10)y_ = -(perceptron.w[0] * x_points + perceptron.b) / perceptron.w[1]plt.plot(x_points, y_)plt.plot(data[:50, 0], data[:50, 1], 'bo', color='blue', label='0')plt.plot(data[50:100, 0], data[50:100, 1], 'bo', color='orange', label='1')plt.xlabel('sepal length')plt.ylabel('sepal width')plt.legend() 1234567891011121314#对偶形式训练结果print(perceptron.beta.shape,y.shape,X.shape)perceptron.w = np.dot((np.multiply(list(perceptron.beta),y)),X)perceptron.b = np.dot(perceptron.beta,y)#需上诉算出参数x_points = np.linspace(4, 7, 10)y_ = -(perceptron.w[0] * x_points + perceptron.b) / perceptron.w[1]plt.plot(x_points, y_)plt.plot(data[:50, 0], data[:50, 1], 'bo', color='blue', label='0')plt.plot(data[50:100, 0], data[50:100, 1], 'bo', color='orange', label='1')plt.xlabel('sepal length')plt.ylabel('sepal width')plt.legend() ​ 6.2 感知机算法-sklearn实现 导包 1234import sklearnfrom sklearn.linear_model import Perceptronsklearn.__version__ 建模 12345678910clf = Perceptron(fit_intercept=True, max_iter=1000, shuffle=True)clf.fit(X, y)# Weights assigned to the features.print(clf.coef_)# 截距 Constants in decision function.print(clf.intercept_) 3.训练可视化 12345678910111213141516171819202122# 画布大小plt.figure(figsize=(10,10))# 中文标题plt.rcParams['font.sans-serif']=['SimHei']plt.rcParams['axes.unicode_minus'] = Falseplt.title('鸢尾花线性数据示例')plt.scatter(data[:50, 0], data[:50, 1], c='b', label='Iris-setosa',)plt.scatter(data[50:100, 0], data[50:100, 1], c='orange', label='Iris-versicolor')# 画感知机的线x_ponits = np.arange(4, 8)y_ = -(clf.coef_[0][0]*x_ponits + clf.intercept_)/clf.coef_[0][1]plt.plot(x_ponits, y_)# 其他部分plt.legend() # 显示图例plt.grid(False) # 不显示网格plt.xlabel('sepal length')plt.ylabel('sepal width')plt.legend() 4.纠正错误 在上图中，有一个位于左下角的蓝点没有被正确分类，这是因为 SKlearn 的 Perceptron 实例中有一个tol参数。 tol 参数规定了如果本次迭代的损失和上次迭代的损失之差小于一个特定值时，停止迭代。所以我们需要设置 tol=None 使之可以继续迭代： 12345678910111213141516171819202122232425262728clf = Perceptron(fit_intercept=True, max_iter=1000, tol=None, shuffle=True)clf.fit(X, y)# 画布大小plt.figure(figsize=(10,10))# 中文标题plt.rcParams['font.sans-serif']=['SimHei']plt.rcParams['axes.unicode_minus'] = Falseplt.title('鸢尾花线性数据示例')plt.scatter(data[:50, 0], data[:50, 1], c='b', label='Iris-setosa',)plt.scatter(data[50:100, 0], data[50:100, 1], c='orange', label='Iris-versicolor')# 画感知机的线x_ponits = np.arange(4, 8)y_ = -(clf.coef_[0][0]*x_ponits + clf.intercept_)/clf.coef_[0][1]plt.plot(x_ponits, y_)# 其他部分plt.legend() # 显示图例plt.grid(False) # 不显示网格plt.xlabel('sepal length')plt.ylabel('sepal width')plt.legend() 迭代次数随着tol减少或者不要而增加。模型对样本的数据拟合程度会更高（tol可以间接防止过度拟合样本） 参考文献@(*.*)@ @(^.^)@ @(*.*)@ @(^.^)@ @(*.*)@ @(^.^)@ @(*.*)@ @(^.^)@ @(*.*)@ @(^.^)@ 感知机原理 什么是范数 如何求点到面的距离 支撑向量机原理]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chapter6-神经网络]]></title>
    <url>%2F2019%2F11%2F20%2Fchapter6-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[chapter6-神经网络（neural networks）1. 神经网络原理这节大部分内容参考AndrewNG深度学习教学视频以及黄海广博士在github上开源的吴恩达深度学习笔记,本节知识根据自己使用经验进行基本总结，细致末梢还请看吴恩达老师讲义。对于neural networks统计学原理，我将从下面伍个部分进行仔细探讨，因为这些部分是神经网络不可或缺的部分。我将通过与logisticRegression原理进行对比介绍，如果不知道或者不清楚的可以看前面所介绍的logistic。最后实现代码，更深一步了解简单的TensorFlow实现。并且分析机器学习和深度学习建模的联系。 损失函数​ 损失函数（cost function）是优化的目的。如果没有损失函数，也就没有了目标。不管是任何事情，都需要去了解问题的根本。知道问题的缘由，才能进一步进行建模优化。比如是回归还是分类。是有监督，还是无监督。使用什么统计学原理。如何筛选评价函数。这些都需要通过损失函数，与具体背景结合去构建模型。这里不考虑业务背景。现，只通过逻辑回归损失函数去优化，实现对图像的分类。即有监督。所以损失函数为：$$L(\theta) = -Y^Tlogh_{\theta}(X) - (E-Y)^T log(E-h_{\theta}(X))$$ 非线性激活函数​ 为什么要有非线性激活函数？对于深度学习，非线性激活函数是必不可少的。如果没有非线性激活函数，那么深度学习只能解决极小数线性问题。 ​ 前面作为基础讨论的最小二乘法，只能够做线性拟合，做深度学习没有加非线性激活函数，进行拟合的结果简直惨不忍睹。对于现大数据时代，人行为规律分布，基本呈现高斯分布，也就是说，解决问题，要先解决重要度高的问题。而分类问题，是占有大壁江山的。当然时序问题也挺重要，将后讨论。 ​ 总之，废话连篇，深度学习，如果不加非线性激活函数，不管它的隐藏层有再深，模型再广。他拟合出来的结果依然会很差。因为世界上，出现规律及规范的线性数据，就像少之又少，并且训练的结果仍然是线性函数表示。 计算图（神经网络中的因为结果梯度下降）​ 对于现在api泛化的年代，TensorFlow2.0 pytorch keras 都有像sklearn一样模型接口，甚至更简单的工具包也有automl，autogluon。但是要想做得快，调得一手好参数，还是必须要从基础开始。计算图算是神经网络的灵魂所在。 什么神经网络 神经网络就是一个图，大致结构如上图所示。数学表达式如下： 其中$\sigma(z^{[i]})$表示非线性函数，。两行表示一个隐藏层。然后进行向量化，步骤如下： ​ 类比于前几章节，向量化的过程，神经网络也一样，公式更加的简单，相比较于非向量化的公式，只能在用for循环遍历计算，向量化的矩阵，计算更加的块。其中矩阵$Z,X $ 水平方向上，对应于不同的训练样本；竖直方向上，对应不同的输入特征. 神经网络的梯度下降算法 forward propagation ​ 正向传播就很简单，只需要从在$z^{[1]} \rightarrow a^{[1]} \rightarrow z^{[2]} \rightarrow a^{[2]} $ 依次计算即可 backward propagation 对于反向传播，我们需要链式求导，去更新参数$W,b$ 进而优化损失函数。 主要公式如下： 其中，𝑛[1]表示隐藏单元个数，𝑛[2]表示输出单元个数，每次优化预测值$Y:y^{(i) },(𝑖 = 1,2,…,𝑚) $,$L$为上述的logistic损失函数 正则化与标准化​ 需要细聊，数据处理，建模，优化模型，看此machine learning yearning！！！ 为什么要正则化 ​ 为什么要正则化？为什么要分析模型结果的方差和偏差？模型的泛化性如何？三个问号，目标同一，就是你到结果是否好？如下图所示，我们和直观的看出模型好坏与方差、偏差的关系。 对于神经网络，有不同于机器学习，正则化有： L1与L2 dropout（基本理解为随机去掉一些节点） early-stop（训练迭代评价回归线ROC的斜率最低时停止。） 为什么要标准化 神经网络的最大优势，就是在于能够驾驭超大数据量，并且有很好的结果。进而产生训练慢的负效应，因此需要标准化，它能使得模型训练速度更快。 对于神经网络来说，标准化也有许多优化。 根据数据样本角度，由于数据量超大的原因，深度学习常常用batch-size进行控制每次输入的数据，也就产生通过对每次batch-size的数据进行标准化，就产生了几种标准化。有兴趣可以查一下。 什么是梯度爆炸与消失 对于神经网络数学公式，正向传播来说，最终的结果如下： 我们可以从公式中看到，如果$W$过大或者过小，在连乘中，也就是模型迭代过程中，参数会逐渐变极小或变极大的情况。这种情况就被称为神经网络的梯度爆炸与消失。 因此，神经网络对参数初始化有较大的要求，需要根据使用不同数据和激活函数进行优化设置。具体细节参考上面的machine learning yearning！ 优化算法随着数据量的提升，神经网络的优化算法也逐渐提升。并且随着深度学习的流行，很多学者都会研究优化算法，产生许多有用的paper，并且能够适用于企业。 这里我就不仔细探讨优化算法的实现，以及对数据量的适应程度，有兴趣的可以查看论文，进行深刻研究 神经网络-Python实现1.加载数据12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152load_data.pyimport numpy as npimport matplotlib.pyplot as pltimport h5pydef load_dataset( ): train_dataset = h5py.File('./datasets/train_catvnoncat.h5', "r") train_set_x_orig = np.array(train_dataset[ "train_set_x" ][ : ]) # your train set features train_set_y_orig = np.array(train_dataset[ "train_set_y" ][ : ]) # your train set labels test_dataset = h5py.File('datasets/test_catvnoncat.h5', "r") test_set_x_orig = np.array(test_dataset[ "test_set_x" ][ : ]) # your test set features test_set_y_orig = np.array(test_dataset[ "test_set_y" ][ : ]) # your test set labels classes = np.array(test_dataset[ "list_classes" ][ : ]) # the list of classes train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[ 0 ])) test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[ 0 ])) return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classestrain_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()index = 10plt.imshow(train_set_x_orig[index])print ("y = " + str(train_set_y[:, index]) + ", it's a '" + classes[np.squeeze(train_set_y[:, index])].decode("utf-8") + "' picture.")m_train = train_set_x_orig.shape[0]m_test = test_set_x_orig.shape[0]num_px = train_set_x_orig.shape[1]print ("Number of training examples: m_train = " + str(m_train))print ("Number of testing examples: m_test = " + str(m_test))print ("Height/Width of each image: num_px = " + str(num_px))print ("Each image is of size: (" + str(num_px) + ", " + str(num_px) + ", 3)")print ("train_set_x shape: " + str(train_set_x_orig.shape))print ("train_set_y shape: " + str(train_set_y.shape))print ("test_set_x shape: " + str(test_set_x_orig.shape))print ("test_set_y shape: " + str(test_set_y.shape))train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).Ttest_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1).Tprint ("train_set_x_flatten shape: " + str(train_set_x_flatten.shape))print ("train_set_y shape: " + str(train_set_y.shape))print ("test_set_x_flatten shape: " + str(test_set_x_flatten.shape))print ("test_set_y shape: " + str(test_set_y.shape))print ("sanity check after reshaping: " + str(train_set_x_flatten[0:5,0]))train_set_x = train_set_x_flatten/255.test_set_x = test_set_x_flatten/255. 2.建立函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118#TensorFlow_build_function.pyimport randomimport numpy as npdef sigmiod(z): s = 1.0/ (1 + np.exp(-z)) return sdef initialize_w_and_b_info(dim): # w = np.random.randn() # 先初始值为零 简单看数据实现框架，初始为零是非常不好的因为 # 他使得神经网络训练时没有不对称性，这样导致你无论加多少个隐藏层都是一样的结果 w = np.zeros((dim,1)) b = 0 # b初始为零，没有问题 # W1 = np.random.randn(n_h, n_x) * 0.01 # b1 = np.zeros((n_h, 1)) # assert (b.shape == (dim, 1)) assert (w.shape == (dim,1)) assert (isinstance(b, float) or isinstance(b, int)) return w, b#神经网络的正向传播，def propagate(w, b, X, Y): """ Implement the cost function and its gradient for the propagation explained above Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of size (num_px * num_px * 3, number of examples) Y -- true "label" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples) Return: cost -- negative log-likelihood cost for logistic regression dw -- gradient of the loss with respect to w, thus same shape as w db -- gradient of the loss with respect to b, thus same shape as b Tips: - Write your code step by step for the propagation. np.log(), np.dot() """ m = X.shape[1] A = sigmiod(np.dot(w.T, X) + b) cost = -np.sum(Y*np.log(A) + (1- Y)* np.log(1- A))/m dw = np.dot(X,(A- Y).T)/m db = np.sum((A - Y),axis = 1,keepdims = True)/m assert (dw.shape == w.shape) assert (db.dtype == float ) cost = np.squeeze(cost) assert (cost.shape == ()) grads = &#123; 'dw' : dw, 'db' : db &#125; return grads ,cost#测试广播 正向，后向传播正确没有w, b, X, Y = np.array([[1],[2]]), 2, np.array([[1,2],[3,4]]), np.array([[1,0]])# grads, cost = propagate(w, b, X, Y)# print ("dw = " + str(grads["dw"]))# print ("db = " + str(grads["db"]))# print ("cost = " + str(cost))# 梯度下降，对 w,b进行更新 利用字典存储def optimize(w, b, X, Y,num_iterations, learning_rate, print_cost = False): costs = [] for i in range(num_iterations): grads, cost = propagate(w, b, X, Y) dw = grads['dw'] db = grads['db'] w = w - learning_rate*dw b = b - learning_rate*db if i % 100 == 0 : costs.append(cost) print_cost = True if print_cost and i % 100 == 0: print('cost after itertation %i : %f' %(i, cost)) params = &#123; 'w' : w, 'b' : b &#125; grads = &#123; 'dw' : dw, 'db' : db &#125; return params , grads , costs#测试激活函数是否正确# params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)# print ("w = " + str(params["w"]))# print ("b = " + str(params["b"]))# print ("dw = " + str(grads["dw"]))# print ("db = " + str(grads["db"]))def predict(w, b, X): m = X.shape[1] Y_prediction = np.zeros((1, m)) w = w.reshape((X.shape[0]), 1) A = sigmiod(np.dot(w.T,X) + b) for i in range(A.shape[0]): Y_prediction = np.around(A) assert (Y_prediction.shape == (1, m)) return Y_prediction 3.建立模型1234567891011121314151617181920212223242526272829#TensorFlow_model.pyfrom TensorFlow_learn_work_package.week1_work.tensorFlow_build_function import *from TensorFlow_learn_work_package.week1_work.load_data import *def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False): w, b = initialize_w_and_b_info(X_train.shape[0]) parameters, grads, costs = optimize(w, b , X_train, Y_train, num_iterations, learning_rate, print_cost= False) w = parameters['w'] b = parameters['b'] Y_prediction_test = predict(w, b, X_test) Y_prediction_train = predict(w, b, X_train) print("model_train_accuracy: &#123;&#125;%".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)* 100))) print(("model_text_accuracy: &#123;&#125;%".format((100 - np.mean(np.abs(Y_prediction_test - Y_test)* 100))))) d = &#123; "costs" : costs, "Y_prediction_train" : Y_prediction_train, "Y_prediction_test" : Y_prediction_test, "learning_rate" : learning_rate, 'w' : w , 'b' : b, 'num_iterations' : num_iterations &#125; return d#训练模型d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True) 数据以及源代码]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chapter4-梯度下降算法(Gradient Descent)]]></title>
    <url>%2F2019%2F11%2F20%2Fchapter4-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95-Gradient-Descent%2F</url>
    <content type="text"><![CDATA[chapter4-梯度下降算法(Gradient Descent)求解机器学习算法的模型参数时，即无约束优化问题时，梯度下降（Gradient Descent）是最常采用的方法之一，另一种常用的方法是最小二乘法。这里就对梯度下降法做一个完整的总结。 1.梯度在微积分里面，对多元函数的参数求∂偏导数，把求得的各个参数的偏导数以向量的形式写出来，就是梯度。比如函数$f(x,y)$,分别对$x,y$进行求导，求得梯度向量是$(\frac{\partial f}{\partial x},\frac{\partial f}{\partial y})^T$ 简称$grad f(x,y)$ | $\Delta f(x,y)$,对于点为$(x_0,y_0)$,他的梯度向量值为$(\frac{\partial f}{\partial x_0},\frac{\partial f}{\partial y_0})^T$ | $\Delta f(x_0,y_0)$,如果为三个变量，就为：$\Delta f(x,y,z)$,以此类推。 那为什么要找到函数$f(x,y)$的梯度呢？因为梯度向量是函数下降(增加)速度最快的地方。比如说，在初始点$(x_0,y_0)$ 沿着梯度向量$\Delta f(x_0,y_0)$ (-$\Delta f(x_0,y_0)$)，增加最快(下降最快)的方向 ，我们能够更快的找到函数的最小值(最大值)。 2.梯度上升与梯度下降在机器学习背景当中，求损失函数的最小值，是非常常见的。对于梯度来说，求梯度向量给予不同的正负，就能够使得在函数上走向增加最快的方向(+)和下降最快的方向(-)。即为$f(\theta)$和$-f(\theta)$。 3.梯度下降算法详解3.1梯度下降算法的直观解释梯度下降算法如下图所示，从图中我们可以看出，从初始点出发，通过迭代不断的朝着下降速度最快的方向前进。但是在不同的step size (learning rate)下，他走向了不同的地方，因为函数可能有多个峰值和谷值，所以会找到不同谷底的最小值，使得最终的结果可能是局部最优。当然梯度下降算法分为：批量梯度下降算法(BGD),随机梯度下降算法(SGD)和小批量随机梯度算法(MBGD)(算法区别主要在于样本选择)。选择不同的算法，他们在运行时间和结果是否最优解上有较大的差异。(如果函数为凸函数，那么不管怎样都会有全局最优解，比如$x^2$) 3.2 梯度下降算法相关概念由上述介绍，我们总结概念如下： 步长(learning rate)： 步长决定了你梯度下降时，一次迭代你往前进方向走的长度 特征(feature): 指样本输入部分。比如2个但特征样本$(x_0,y_0)(x_1,y_1)$，则第一个样本特征为$x_0$，输出为$y_0$. 假设函数(hypothesis fuction):在监督学习中，为了拟合输入样本，而使用的假设函数，记为$h_\theta(x)$,比如对于某个单个特征的m个样本$(x^{(i)},y^{(i)}) \quad (i=1,2,3,\cdots,m)$,可以采用拟合函数如下:$h_\theta=\theta_0 + \theta_1x$. 损失函数(loss function): 为了评估模型拟合的好坏，通常用损失函数来度量拟合程度。损失函数极小化，以为这拟合度最好，对应的模型参数即为最优函数。在线性回归中，损失函数，通常为样本输出与假设函数的差的平方，即为平方误差(mse).比如m个样本$(x^{(i)},y^{(i)}) \quad (i=1,2,3,\cdots,m)$,采用线性回归，损失函数为：$$J(\theta_0,\theta_1) = \sum_{i=1}^m(h_\theta{(x_i)}-y_i)^2$$ 其中$x_i$表示第$i$个样本特征,$y_i$表示第$i$个样本的输出，$h_\theta(x)$为假设函数。 3.3 梯度下降详细算法类比于最小二乘法章节。梯度下降算法我们以线性回归来进行举例，它亦有代数式和矩阵式两种求解方式，下面我们将进行分别讨论。 3.3.1. 梯度下降代数式算法 确定假设函数和损失函数 ​ 对于线性回归的假设函数为$h_\theta(x_1,x_2,…x_n)=\theta_0+\theta_1x_1+…+\theta_{n−1}x_{n−1}$,其中$x_i$为样本特征，$\theta_i$为 模型参数，同最小二乘法，我们可以令$x_0=1$,可以简化为$h_θ(x_1,x_2,…x_n)=\sum_{i=0}^{n}\theta_ix_i$,因此利用均方误差作为损失函数为 $$J(\theta_0,\theta_1,\cdots,\theta_j) =\frac{1}{2m}\sum_{i=1}^m(h_θ(x_0^{(i)},x_1^{(i)},\cdots,x_j^{(i)}) - y^{(j)})^2=\frac{1}{2m}\sum_{i=1}^n(\sum_{j=1}^m\theta_jx_j^{(i)}-y^{(i)})^2$$ 算法参数的初始化 ​ 主要初始化模型参数$\theta_i$、终止距离$\epsilon $、步长$\alpha$和最大迭代次数max_iters.在没有先知经验下，我喜欢把数$\theta_i$初始化为0，$\epsilon $初始化为0.0001和$\alpha$初始化为0.38,max_iters初始化为1000. 3.算法过程 1）对损失函数$\theta_i$求偏导，得到梯度向量，即线性回归梯度为: $$\frac{\partial }{\partial \theta_i}J(\theta_0,\theta_1,\cdots,\theta_j) =\frac{1}{m}\sum_{i=1}^n(\sum_{j=1}^m\theta_jx_j^{(i)}-y^{(i)})x_j^{(i)}$$​ 2）利用步长乘以损失函数梯度，得到当前位置下降的距离。 ​ 3）确定当前所有$\theta_i$下降距离是否都小于$\epsilon$,如果小于或者达到最大迭代次数结束max_iters就终止训练，即 最佳参数为当前$\theta_i$,如果没有就进行步骤4。 ​ 4） 更新每个参数$\theta_i$,更新后进入步骤1，知道满足步骤3或者达到最大迭代次数结束max_iters$$\theta_i=\theta_i-\alpha\frac{1}{m}\sum_{i=1}^n(\sum_{j=1}^m\theta_jx_j^{(i)}-y^{(i)})x_j^{(i)}$$3.3.2. 梯度下降矩阵式算法 ​ 基本思想和线性代数解法一致，只是由矩阵进行表示 ​ 1. 确定假设函数和损失函数 ​ 对于简化后的$h_\theta$可知，能够得到矩阵表达式为:$$h_\theta(X) = \theta X$$ ​ 化简为矩阵损失函数 $J(θ)=\frac{1}{2}(θX−Y)^T(θX−Y)$，其中， 假设函数$h_{\theta}(X)$为mx1的向量,$\theta$为nx1的 向量，里面有n个代数法的模型参数。$X$为mxn维的矩阵。m代表样本的个数，n代表样本的特征数. 算法参数的初始化 除$\theta_i$变为矩阵向量表示，其余和上述一致 算法过程 1) 对损失函数$\theta_i$求偏导，得到梯度向量，即线性回归梯度为~ $$\frac{\partial }{\partial \theta}J(\theta)=X^T(\theta X-Y)$$ ​ 2) 利用步长乘以损失函数梯度，得到当前位置下降的距离。 ​ 3）确定当前所有$\theta_i$下降距离是否都小于$\epsilon$,如果小于或者达到最大迭代次数结束max_iters就终止训练，即最佳参数为当前$\theta_i$,如果没有就进行步骤4， ​ 4） 更新每个参数$\theta_i$,更新后进入步骤1，直到满足步骤3。$$\theta = \theta-\alpha X^T(\theta X-Y)$$ 3.3.3. 梯度下降算法代码实践 ​ 现在我们举一个实际的栗子。对于函数$f(x)=x^4-3x^3+2$,求导可以得到$f^\prime(x)=4x^3-9x^2$.我们令$f^\prime(x)=0$可以解出$x=\frac{9}{4}=2.25 \quad and\quad x=0$,我们需要全局最小值，所以取得$x=2.25$.下面我们通过梯度下降算法去解出$x$的值： 1234567891011121314151617181920next_x = 6 #初始化值xlearning_rate = 0.01 # 学习率epsilon = 0.00001 # 迭代值相差阈值 如果相差太小就停止模型。max_iters = 10000 #最大迭代数#导函数def df(x): return 4 * x**3 - 9 * x**2for _i in range(max_iters): current_x = next_x next_x = current_x - learning_rate * df(current_x) step = next_x - current_x if abs(step) &lt;= epsilon: breakprint("Minimum at ", next_x)# 最终输出求最小近似值x: "2.2499646074278457" 3.4 梯度下降算法调参​ 1.learning_rate(步长)的选择，在不同阶数函数当中，峰值与谷值高低不一，造成步长的长度一定决定是否会错过全局最优峰值，或者会在局部峰值停滞不前。所以呢？根据我的经验来说：构建模型时，我们应该把步长设置得较大一点比如0.5，这样模型会更快的收敛，这样会更快的找到模型构建是否正确。当模型完全没问题时，应该逐渐减小步长，免得错过更好的峰值。 初始值设定。站在不同的高度，领略不同的风景。所以需要细心调整初始值。当然在深度学习当中对初始值的设定要求会更高。 归一化。在线性模型当中，归一化可以使模型更快的收敛。不会各种低峰饶很久，才回收敛。最常见归一化就是特征值$(x-avg(x))/std(x)$，就是减去平均值，然后除以方差。 3.5梯度下降算法的区别1.批量梯度下降算法(BGD) ​ 批量梯度下降算法，直观而言。就是对全部样本的数据进行参数更新$$\theta_i=\theta_i-\alpha\frac{1}{m}\sum_{i=1}^n(\sum_{j=1}^m\theta_jx_j^{(i)}-y^{(i)})x_j^{(i)}$$2.随机梯度下降算法(SGD) ​ 同理，随机梯度下降算法，就是随机在样本中选择一个样本进行更新参数$\theta_i$ . 3.小批量随机梯度算法(MBGD) ​ 小批量随机梯度算法,是对前两种算法的综合。即为随机选择小批量的样本进行更新参数$\theta_i$ . 参考文献梯度下降算法原理 gradient descent theory 为什么要归一化|标准化]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chapter5-逻辑斯谛回归-LogisticRegression]]></title>
    <url>%2F2019%2F11%2F20%2Fchapter5-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92-LogisticRegression%2F</url>
    <content type="text"><![CDATA[chapter5-逻辑斯谛回归-LogisticRegressionstatistics learning1.浅谈线性回归由于前面最小二乘法和梯度下降算法，已经大力讨论了回归模型，因此，本章只进行简单的回顾回归模型。分析线性回归原理和与最小二乘法之间的区别。 线性回归与最小二乘法的最大区别，就在于损失函数的迭代。也就是如何优化损失函数。最小二乘法顾名思义，就是采用最小二乘法进行迭代，损失函数如下：$$J(\theta_0,\theta_1,\cdots,\theta_j) =\sum_{i=1}^m(h_θ(x_0^{(i)},x_1^{(i)},\cdots,x_j^{(i)}) - y^{(j)})^2=\sum_{i=1}^n(\sum_{j=1}^m\theta_jx_j^{(i)}-y^{(i)})^2$$ 对损失函数求导为，更新参数$\theta$：$$\theta = (X^TX)^-1X^TY$$对于线性回归算法来说，就是利用梯度下降算法，损失函数如下：$$J(\theta_0,\theta_1,\cdots,\theta_j) =\frac{1}{2m}\sum_{i=1}^m(h_θ(x_0^{(i)},x_1^{(i)},\cdots,x_j^{(i)}) - y^{(j)})^2=\frac{1}{2m}\sum_{i=1}^n(\sum_{j=1}^m\theta_jx_j^{(i)}-y^{(i)})^2$$ 对损失函数求偏导，更新参数$\theta$：$$\theta = \theta-\alpha X^T(\theta X-Y)$$ 综合上述，对于线性回归来说，利用最小二乘法与梯度下降算法去优化模型，区别就在于求全导(每一个错误样本都会更新)，还是偏导上(逐渐逼近最佳拟合函数)。相对于不同的数据量来说，小样本，最小二乘法会更快的收敛，时间会更少。当样本量较大时，最小二乘法的计算量会逐渐增大，这时，没有梯度下降算法收敛得快，但不一定是最优解。 2. LogisticRegression theory1) 线性回归和逻辑回归的关系​ 逻辑斯谛回归是在线性回归的基础之上，加入了非线性函数，就是sigmod函数，进行分类或者多分类。 因此logisticRegression是分类模型，那为什么带有回归两字呢？因为线性回归的y是连续的，而分类问题，y是离散的。那怎么做才能让连续分类问题转化为离散分类问题呢？利用sigmod函数，可以在闭区间$[0,1]$中的连续值，转化为0和1标签，多分类同理。sigmod函数如下：$$g(z) = \frac{1}{1+e^{-z}}$$可视化如图所示： 它有一个非常好的性质，即当z趋于正无穷时，g(z)趋于1，而当z趋于负无穷时，g(z)趋于0，这非常适合于我们的分类概率模型。另外，它还有一个很好的导数性质： $$g^{‘}(z) = g(z)(1-g(z))$$这个通过函数对g(z)求导很容易得到，后面我们会用到这个式子。 如果我们令g(z)中的z为：${z = \theta x}$，这样就得到了二元逻辑回归模型的一般形式：$$h_{\theta}(x) = \frac{1}{1+e^{-\theta x}}$$ 其中x为样本输入，$h_{\theta}(x)$为模型输出，可以理解为某一分类的概率大小。而$\theta$为分类模型的要求出的模型参数。对于模型输出$h_{\theta}(x)$，让它和二元样本输出y（假设为0和1）有这样的对应关系，如果$h_{\theta}(x)$ &gt;0.5 ，即$\theta x &gt; 0$, 则y为1。如果$h_{\theta}(x) &lt; 0.5$，即$x\theta &lt; 0$, 则y为0。$y=0.5$是临界情况，此时$\theta x = 0$为， 从逻辑回归模型本身无法确定分类。 $h_{\theta}(x)$的值越小，而分类为0的的概率越高，反之，值越大的话分类为1的的概率越高。如果靠近临界点，则分类准确率会下降。 此处我们也可以将模型写成矩阵模式：$$h_{\theta}(X) = \frac{1}{1+e^{-X\theta}}$$ 其中$h_{\theta}(X)$为模型输出，为$ m \times 1$的维度。$X$为样本特征矩阵，为$m\times n$的维度。$\theta$为分类的模型系数，为$n\times1$的向量。 理解了二元分类回归的模型，接着我们就要看模型的损失函数了，我们的目标是极小化损失函数来得到对应的模型系数$\theta$。 2) 二元逻辑回归的损失函数回顾下线性回归的损失函数，由于线性回归是连续的，所以可以使用模型误差的的平方和来定义损失函数。但是逻辑回归不是连续的，自然线性回归损失函数定义的经验就用不上了。不过我们可以用最大似然法来推导出我们的损失函数。 我们知道，按照第二节二元逻辑回归的定义，假设我们的样本输出是0或者1两类。那么我们有$$P(y=1|x,\theta ) = h_{\theta}(x)\P(y=0|x,\theta ) = 1- h_{\theta}(x)$$ 把这两个式子写成一个式子(服从伯努利分布)，就是：$$P(y|x,\theta ) = h_{\theta}(x)^y(1-h_{\theta}(x))^{1-y}$$其中y的取值只能是0或者1。 得到了y的概率分布函数表达式，我们就可以用似然函数最大化来求解我们需要的模型系数$\theta$。 为了方便求解，这里我们用对数似然函数最大化，对数似然函数取反即为我们的损失函数$J\theta$。其中： 似然函数的代数表达式为：$$L(\theta) = \prod\limits_{i=1}^{m}(h_{\theta}(x^{(i)}))^{y^{(i)}}(1-h_{\theta}(x^{(i)}))^{1-y^{(i)}}$$其中m为样本的个数。 对似然函数对数化取反的表达式，即损失函数表达式为：$$J(\theta) = -lnL(\theta) = -\sum\limits_{i=1}^{m}(y^{(i)}log(h_{\theta}(x^{(i)}))+ (1-y^{(i)})log(1-h_{\theta}(x^{(i)})))$$损失函数用矩阵法表达更加简洁：$$J(\theta) = -Y^Tlogh_{\theta}(X) - (E-Y)^T log(E-h_{\theta}(X))$$其中E为全1向量。 3) 二元逻辑回归损失函数的优化对于二元逻辑回归的损失函数极小化，有比较多的方法，最常见的有梯度下降法，坐标轴下降法，牛顿法等。这里推导出梯度下降法中$\theta$每次迭代的公式。由于代数法推导比较的繁琐，我习惯于用矩阵法来做损失函数的优化过程，这里给出矩阵法推导二元逻辑回归梯度的过程。 对于$J(\theta) = -Y^T logh_{\theta}(X) - (E-Y)^T log(E-h_{\theta}(X))$，我们用$J(\theta)$对$\theta$向量求导可得：$$\frac{\partial}{\partial\theta}J(\theta) = X^T[\frac{1}{h_{\theta}(X)}\odot h_{\theta}(X)\odot (E-h_{\theta}(X))\odot (-Y)] \ \qquad + X^T[\frac{1}{E-h_{\theta}(X)}\odot h_{\theta}(X)\odot (E-h_{\theta}(X))\odot (E-Y)]$$这一步我们用到了向量求导的链式法则，和下面三个基础求导公式的矩阵形式：$$\frac{\partial}{\partial x}logx = 1/x \ \\frac{\partial}{\partial z}g(z) = g(z)(1-g(z)) \quad (g(z)为sigmoid函数) \\frac{\partial x\theta}{\partial \theta} = x$$对于刚才的求导公式我们进行化简可得：$$\frac{\partial}{\partial\theta}J(\theta) = X^T(h_{\theta}(X) - Y )$$从而在梯度下降法中每一步向量$\theta$的迭代公式如下：$$\theta = \theta - \alpha X^T(h_{\theta}(X) - Y )$$其中，$\alpha$为梯度下降法的步长。 实践中，我们一般不用操心优化方法，大部分机器学习库都内置了各种逻辑回归的优化方法，不过了解至少一种优化方法还是有必要的。 4) 二元逻辑回归的正则化 逻辑回归也会面临过拟合问题，所以我们也要考虑正则化。常见的有$L1$正则化和$L2$正则化。 逻辑回归的$L1$正则化的损失函数表达式如下，相比普通的逻辑回归损失函数，增加了$L1$的范数做作为惩罚，超参数$\alpha$作为惩罚系数，调节惩罚项的大小。 二元逻辑回归的$L1$正则化损失函数表达式如下：$$J(\theta) = -Y^T\bullet logh_{\theta}(X) - (E-Y)^T\bullet log(E-h_{\theta}(X)) +\alpha ||\theta||_1$$其中$||\theta||_1$为$\theta$的$L1$范数。 逻辑回归的$L1$正则化损失函数的优化方法常用的有坐标轴下降法和最小角回归法。 二元逻辑回归的L2正则化损失函数表达式如下： $$ J(\theta) = -Y^T\bullet logh_{\theta}(X) - (E-Y)^T\bullet log(E-h_{\theta}(X)) + \frac{1}{2}\alpha||\theta||_2^2$$其中$||\theta||_2$为$\theta$的$L2$范数。 逻辑回归的$L2$正则化损失函数的优化方法和普通的逻辑回归类似。 5） 多元逻辑回归前面几节我们的逻辑回归的模型和损失函数都局限于二元逻辑回归，实际上二元逻辑回归的模型和损失函数很容易推广到多元逻辑回归。比如总是认为某种类型为正值，其余为0值，这种方法为最常用的$one-vs-rest$，简称$OvR$. 另一种多元逻辑回归的方法是$Many-vs-Many(MvM)$，它会选择一部分类别的样本和另一部分类别的样本来做逻辑回归二分类。最常用的是$One-Vs-One（OvO）$。$OvO$是$MvM$的特例。每次我们选择两类样本来做二元逻辑回归。 这里只介绍多元逻辑回归的softmax回归的一种特例推导： 首先回顾下二元逻辑回归 $$P(y=1|x,\theta ) = h_{\theta}(x) = \frac{1}{1+e^{-x\theta}} = \frac{e^{x\theta}}{1+e^{x\theta}}\ P(y=0|x,\theta ) = 1- h_{\theta}(x) = \frac{1}{1+e^{x\theta}}$$ 其中y只能取到0和1。则有：$$ln\frac{P(y=1|x,\theta )}{P(y=0|x,\theta)} = \theta x$$ 如果我们要推广到多元逻辑回归，则模型要稍微做下扩展。 我们假设是K元分类模型,即样本输出y的取值为$1，2，\dots，K$。 根据二元逻辑回归的经验，我们有：$$ln\frac{P(y=1|x,\theta )}{P(y=K|x,\theta)} = \theta_1 x \ ln\frac{P(y=2|x,\theta )}{P(y=K|x,\theta)} = \theta_2 x \ …\ ln\frac{P(y=K-1|x,\theta )}{P(y=K|x,\theta)} = \theta_{K-1} x\$$ 上面有$K-1$个方程。 加上概率之和为1的方程如下：$$\sum\limits_{i=1}^{K}P(y=i|x,\theta ) = 1$$从而得到K个方程，里面有K个逻辑回归的概率分布。 解出这个K元一次方程组，得到K元逻辑回归的概率分布如下：$$P(y=k|x,\theta ) = e^{x\theta_k} \bigg/ 1+\sum\limits_{t=1}^{K-1}e^{x\theta_t} k = 1,2,…K-1 \P(y=K|x,\theta ) = 1 \bigg/ 1+\sum\limits_{t=1}^{K-1}e^{x\theta_t}$$多元逻辑回归的损失函数推导以及优化方法和二元逻辑回归类似，这里就不累述。 meaching learninga. 手动创建模型 导入相关工具包12345678from math import expimport numpy as npimport pandas as pdimport matplotlib.pyplot as plt%matplotlib inlinefrom sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_split 导入数据123456789101112# datadef create_data(): iris = load_iris() df = pd.DataFrame(iris.data, columns=iris.feature_names) df['label'] = iris.target df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label'] data = np.array(df.iloc[:100, [0,1,-1]]) # print(data) return data[:,:2], data[:,-1]#split train and test set data X, y = create_data()X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) 创建模型123456789101112131415161718192021222324252627282930313233343536373839class LogisticReressionClassifier: def __init__(self, max_iter=200, learning_rate=0.01): self.max_iter = max_iter self.learning_rate = learning_rate def sigmoid(self, x): return 1 / (1 + exp(-x)) def data_matrix(self, X): data_mat = [] for d in X: data_mat.append([1.0, *d]) return data_mat def fit(self, X, y): # label = np.mat(y) data_mat = self.data_matrix(X) # m*n self.weights = np.zeros((len(data_mat[0]), 1), dtype=np.float32) for iter_ in range(self.max_iter): for i in range(len(X)): result = self.sigmoid(np.dot(data_mat[i], self.weights)) error = y[i] - result self.weights += self.learning_rate * error * np.transpose( [data_mat[i]]) print('LogisticRegression Model(learning_rate=&#123;&#125;,max_iter=&#123;&#125;)'.format( self.learning_rate, self.max_iter)) # def f(self, x): # return -(self.weights[0] + self.weights[1] * x) / self.weights[2] def score(self, X_test, y_test): right = 0 X_test = self.data_matrix(X_test) for x, y in zip(X_test, y_test): result = np.dot(x, self.weights) if (result &gt; 0 and y == 1) or (result &lt; 0 and y == 0): right += 1 return right / len(X_test) 训练模型与可视化12345678910111213lr_clf = LogisticReressionClassifier()lr_clf.fit(X_train, y_train)lr_clf.score(X_test, y_test)x_ponits = np.arange(4, 8)y_ = -(lr_clf.weights[1]*x_ponits + lr_clf.weights[0])/lr_clf.weights[2]plt.plot(x_ponits, y_)#lr_clf.show_graph()plt.scatter(X[:50,0],X[:50,1], label='0')plt.scatter(X[50:,0],X[50:,1], label='1')plt.legend() 结果如图： b. sklearn 工具包 创建与训练12345678910111213141516171819from sklearn.linear_model import LogisticRegression #创建模型clf = LogisticRegression(max_iter=200)#模型训练clf.fit(X_train, y_train)#得到分数clf.score(X_test, y_test) #1.0#输出参数print(clf.coef_, clf.intercept_) #[[ 1.92439982 -3.1874392 ]] [-0.57523308]x_ponits = np.arange(4, 8)y_ = -(clf.coef_[0][0]*x_ponits + clf.intercept_)/clf.coef_[0][1]plt.plot(x_ponits, y_)plt.plot(X[:50, 0], X[:50, 1], 'bo', color='blue', label='0')plt.plot(X[50:, 0], X[50:, 1], 'bo', color='orange', label='1')plt.xlabel('sepal length')plt.ylabel('sepal width')plt.legend() 结果如下： 参考链接逻辑回归原理 什么是概率分布函数 概率分布函数与似然函数的关系]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chapter1-统计学习与深度学习方法概论]]></title>
    <url>%2F2019%2F11%2F19%2Fchapter1-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[chapter1-统计学习方法与深度学习方法概论 什么是统计学(statistics learning)​ 统计学习是关于计算机基于数据构建概率统计模型并运用模型对数据进行分析与预测的一门学科。统计学习包括监督学习、非监督学习、半监督学习和强化学习。 统计学三要素​ 方法 = 模型 + 策略 + 算法 ​ 模型、策略 、算法三要素是理解统计学习中，起到提纲挈领的作用。 ​ 模型(model)：亦为假设空间(hypothesis),包含所有可能的概率分布或者决策函数。 ​ 策略(strategy): 亦为评价准则(evaluation criterion)，评价模型经验风险最小化与结构风险最小化。不同模型有不同的风险函数 ​ 算法(algorithm): 学习模型的具体计算方法。 ​ 统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型。即为最优化问题。 模型选择与泛化​ 统计学三要素的建立算是打好了地基。如何针对问题进行建模，如何增加模型的泛化能力，即鲁棒性(robust)，亦是我们主要的探讨问题。 模型​ 分类问题、标注问题和回归问题都是监督学习的重要问题。我们将利用统计学知识以及深度学习理论去实践，解决问题—-建模。对于无监督学习问题，我们将另开一类进行探讨。 机器学习(machine learning)​ 机器学习与统计推断学联系尤为密切，也被称为统计学习理论。相比较统计学习，机器学习理论关注可以实现的，行之有效的学习算法，是基于统计学理论知识支撑的。所以，没有产生机器学习分支，而是根据统计学知识，进行代码实现，实践相关真实问题的过程，即为机器学习。如同学界与业界之间的区别，着重点不同，却也息息相关。 深度学习(deep learning)​ 相比较深度学习，利用统计学知识实践，产生机器学习，则为传统的机器学习。也就是常见的十大算法。而深度学习亦属于机器学习。它亦趋于实践，只是在算法实现上，与传统机器学习有较大的不同，所以独立进行命名。当然深度学习现在亦成为主流，灵活性也比传统的机器学习高，但是对于数据和计算资源的要求也更高。 数据挖掘​ 理论与算法，在学界中，显得格外的重要。在业界中，数据挖掘亦是格外的耀眼。数据挖掘，简单的说，就是通过提炼数据，数据存储，挖掘数据，构建模型，模型优化，结果评价以及结果展示的过程。使得能够在社会中，获得效益。 ​ 总之，统计学习、机器学习、深度学习，随之年代和知识逐渐的提升，更加适应现代需求。并且他们之间理论和算法实现都有较大的联系。如果您想知道它们之间的联系的话，请一同与我探讨数据挖掘吧！！！ 注：]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[statistics algorithms learning]]></title>
    <url>%2F2019%2F11%2F15%2Fstatistics-algorithms-learning%2F</url>
    <content type="text"><![CDATA[李航统计学代码实现 李航-统计学与吴恩达-深度学习理论与代码实践目录统计学习方法与深度学习概论 最小二乘法完整实践理论 感知机 统计学与深度学习中的回归支持向量机 FM与FFM… k近邻算法 决策树 随机森林 极限树 提升算法 xgboostlightgbm catboost EM算法以及推广 朴素贝叶斯 循环神经网络 隐尔马可夫模型卷积神经网络 条件随机场 监督学习方法总结 无监督学习概论 强化学习autoML 序言​ 温故知新也，从大二懵进实验室，到毕业，仿佛稚嫩的自己还是昨天的自己，只是时间已是2019.11.19 学了许多，却似乎什么都没有学。借此blog，总结统计学(机器学习)与深度学习之间联系以及相关理论与算法实践。留此印记，源得您人心。 概要​ 本文，主要通过李航-统计学与吴恩达-深度学习，主要对数据挖掘全蓝图概要。写作顺序，如目录：由简至繁，且相互之间关联顺序，进行归纳总结以及代码实践。 总结​ 还没有开始写正文，哈哈哈！希望能够把所想以及所知的，能够以逻辑清晰的顺序写出。]]></content>
      <categories>
        <category>python</category>
        <category>algorithms</category>
      </categories>
      <tags>
        <tag>statistics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim技巧]]></title>
    <url>%2F2019%2F11%2F09%2Fvim%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[shell脚本案列大全 shell系列教程 goole-shell开发规范 1.vim总结技巧vim键盘图 vi/vim 按键说明除了上面简易范例的 i, Esc, :wq 之外，其实 vim 还有非常多的按键可以使用。 第一部分：一般模式可用的光标移动、复制粘贴、搜索替换等 移动光标的方法 h 或 向左箭头键(←) 光标向左移动一个字符 j 或 向下箭头键(↓) 光标向下移动一个字符 k 或 向上箭头键(↑) 光标向上移动一个字符 l 或 向右箭头键(→) 光标向右移动一个字符 如果你将右手放在键盘上的话，你会发现 hjkl 是排列在一起的，因此可以使用这四个按钮来移动光标。 如果想要进行多次移动的话，例如向下移动 30 行，可以使用 “30j” 或 “30↓” 的组合按键， 亦即加上想要进行的次数(数字)后，按下动作即可！ [Ctrl] + [f] 屏幕『向下』移动一页，相当于 [Page Down]按键 (常用) [Ctrl] + [b] 屏幕『向上』移动一页，相当于 [Page Up] 按键 (常用) [Ctrl] + [d] 屏幕『向下』移动半页 [Ctrl] + [u] 屏幕『向上』移动半页 + 光标移动到非空格符的下一行 - 光标移动到非空格符的上一行 n 那个 n 表示『数字』，例如 20 。按下数字后再按空格键，光标会向右移动这一行的 n 个字符。例如 20 则光标会向后面移动 20 个字符距离。 0 或功能键[Home] 这是数字『 0 』：移动到这一行的最前面字符处 (常用) $ 或功能键[End] 移动到这一行的最后面字符处(常用) H 光标移动到这个屏幕的最上方那一行的第一个字符 M 光标移动到这个屏幕的中央那一行的第一个字符 L 光标移动到这个屏幕的最下方那一行的第一个字符 G 移动到这个档案的最后一行(常用) nG n 为数字。移动到这个档案的第 n 行。例如 20G 则会移动到这个档案的第 20 行(可配合 :set nu) gg 移动到这个档案的第一行，相当于 1G 啊！ (常用) n n 为数字。光标向下移动 n 行(常用) 搜索替换 /word 向光标之下寻找一个名称为 word 的字符串。例如要在档案内搜寻 vbird 这个字符串，就输入 /vbird 即可！ (常用) ?word 向光标之上寻找一个字符串名称为 word 的字符串。 n 这个 n 是英文按键。代表重复前一个搜寻的动作。举例来说， 如果刚刚我们执行 /vbird 去向下搜寻 vbird 这个字符串，则按下 n 后，会向下继续搜寻下一个名称为 vbird 的字符串。如果是执行 ?vbird 的话，那么按下 n 则会向上继续搜寻名称为 vbird 的字符串！ N 这个 N 是英文按键。与 n 刚好相反，为『反向』进行前一个搜寻动作。 例如 /vbird 后，按下 N 则表示『向上』搜寻 vbird 。 使用 /word 配合 n 及 N 是非常有帮助的！可以让你重复的找到一些你搜寻的关键词！ :n1,n2s/word1/word2/g n1 与 n2 为数字。在第 n1 与 n2 行之间寻找 word1 这个字符串，并将该字符串取代为 word2 ！举例来说，在 100 到 200 行之间搜寻 vbird 并取代为 VBIRD 则： 『:100,200s/vbird/VBIRD/g』。(常用) :1,$s/word1/word2/g 或 :%s/word1/word2/g 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！(常用) :1,$s/word1/word2/gc或 :%s/word1/word2/gc 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！且在取代前显示提示字符给用户确认 (confirm) 是否需要取代！(常用) 删除、复制与贴上 x, X 在一行字当中，x 为向后删除一个字符 (相当于 [del] 按键)， X 为向前删除一个字符(相当于 [backspace] 亦即是退格键) (常用) nx n 为数字，连续向后删除 n 个字符。举例来说，我要连续删除 10 个字符， 『10x』。 dd 删除游标所在的那一整行(常用) ndd n 为数字。删除光标所在的向下 n 行，例如 20dd 则是删除 20 行 (常用) d1G 删除光标所在到第一行的所有数据 dG 删除光标所在到最后一行的所有数据 d$ 删除游标所在处，到该行的最后一个字符 d0 那个是数字的 0 ，删除游标所在处，到该行的最前面一个字符 yy 复制游标所在的那一行(常用) nyy n 为数字。复制光标所在的向下 n 行，例如 20yy 则是复制 20 行(常用) y1G 复制游标所在行到第一行的所有数据 yG 复制游标所在行到最后一行的所有数据 y0 复制光标所在的那个字符到该行行首的所有数据 y$ 复制光标所在的那个字符到该行行尾的所有数据 p, P p 为将已复制的数据在光标下一行贴上，P 则为贴在游标上一行！ 举例来说，我目前光标在第 20 行，且已经复制了 10 行数据。则按下 p 后， 那 10 行数据会贴在原本的 20 行之后，亦即由 21 行开始贴。但如果是按下 P 呢？ 那么原本的第 20 行会被推到变成 30 行。 (常用) J 将光标所在行与下一行的数据结合成同一行 c 重复删除多个数据，例如向下删除 10 行，[ 10cj ] u 复原前一个动作。(常用) [Ctrl]+r 重做上一个动作。(常用) 这个 u 与 [Ctrl]+r 是很常用的指令！一个是复原，另一个则是重做一次～ 利用这两个功能按键，你的编辑，嘿嘿！很快乐的啦！ . 不要怀疑！这就是小数点！意思是重复前一个动作的意思。 如果你想要重复删除、重复贴上等等动作，按下小数点『.』就好了！ (常用) 第二部分：一般模式切换到编辑模式的可用的按钮说明 进入输入或取代的编辑模式 i, I 进入输入模式(Insert mode)： i 为『从目前光标所在处输入』， I 为『在目前所在行的第一个非空格符处开始输入』。 (常用) a, A 进入输入模式(Insert mode)： a 为『从目前光标所在的下一个字符处开始输入』， A 为『从光标所在行的最后一个字符处开始输入』。(常用) o, O 进入输入模式(Insert mode)： 这是英文字母 o 的大小写。o 为『在目前光标所在的下一行处输入新的一行』； O 为在目前光标所在处的上一行输入新的一行！(常用) r, R 进入取代模式(Replace mode)： r 只会取代光标所在的那一个字符一次；R会一直取代光标所在的文字，直到按下 ESC 为止；(常用) 上面这些按键中，在 vi 画面的左下角处会出现『–INSERT–』或『–REPLACE–』的字样。 由名称就知道该动作了吧！！特别注意的是，我们上面也提过了，你想要在档案里面输入字符时， 一定要在左下角处看到 INSERT 或 REPLACE 才能输入喔！ [Esc] 退出编辑模式，回到一般模式中(常用) 第三部分：一般模式切换到指令行模式的可用的按钮说明 指令行的储存、离开等指令 :w 将编辑的数据写入硬盘档案中(常用) :w! 若文件属性为『只读』时，强制写入该档案。不过，到底能不能写入， 还是跟你对该档案的档案权限有关啊！ :q 离开 vi (常用) :q! 若曾修改过档案，又不想储存，使用 ! 为强制离开不储存档案。 注意一下啊，那个惊叹号 (!) 在 vi 当中，常常具有『强制』的意思～ :wq 储存后离开，若为 :wq! 则为强制储存后离开 (常用) ZZ 这是大写的 Z 喔！若档案没有更动，则不储存离开，若档案已经被更动过，则储存后离开！ :w [filename] 将编辑的数据储存成另一个档案（类似另存新档） :r [filename] 在编辑的数据中，读入另一个档案的数据。亦即将 『filename』 这个档案内容加到游标所在行后面 :n1,n2 w [filename] 将 n1 到 n2 的内容储存成 filename 这个档案。 :! command 暂时离开 vi 到指令行模式下执行 command 的显示结果！例如 『:! ls /home』即可在 vi 当中察看 /home 底下以 ls 输出的档案信息！ vim 环境的变更 :set nu 显示行号，设定之后，会在每一行的前缀显示该行的行号 :set nonu 与 set nu 相反，为取消行号！ 特别注意，在 vi/vim 中，数字是很有意义的！数字通常代表重复做几次的意思！ 也有可能是代表去到第几个什么什么的意思。 举例来说，要删除 50 行，则是用 『50dd』 对吧！ 数字加在动作之前，如我要向下移动 20 行呢？那就是『20j』或者是『20↓』即可。 vim巧技1.vim替换总结1234567891011121314151617181920212223242526vim替换 总结 §vi test.sh 文本:no pain,no gain:n行 1.全局:%s/source_pattern/target_pattern/g :/g 表示所有匹配串如想把所有的pain换成gain，那么:%s/pain/gain/g就可以了。2.局部：s/gain/pain/ 替换当前行第一个 gain 为 pain：s/gain/pain/g 替换当前行所有 gain 为 pain：n，$s/gain/pain/ 替换第 n 行开始到最后一行中每一行的第一个 gain 为 pain：n，$s/gain/pain/g 替换第 n 行开始到最后一行中每一行所有 gain 为 painn 为数字，若 n 为 .，表示从当前行开始到最后一行：%s/gain/pain/（等同于 ：g/gain/s//pain/） 替换每一行的第一个 gain 为 pain：%s/gain/pain/g（等同于 ：g/gain/s//pain/g） 替换每一行中所有 gain 为 pain可以使用 # 作为分隔符，此时中间出现的 / 不会作为分隔符：s#gain/#pain/# 替换当前行第一个 gain/ 为 pain/：%s /home/etc/ /snail/life/ （使用 来 替换 / ）： /home/etc/替换成/snail/life/：s/str1/str2/ 用字符串 str2 替换行中首次出现的字符串 str1：s/str1/str2/g 用字符串 str2 替换行中所有出现的字符串 str1：§，$ s/str1/str2/g 用字符串 str2 替换正文当前行到末尾所有出现的字符串 str1：1，$ s/str1/str2/g 用字符串 str2 替换正文中所有出现的字符串 str1：g/str1/s//str2/g 功能同上从上述替换命令可以看到：g 放在命令末尾，表示对搜索字符串的每次出现进行替换；不加 g，表示只对搜索字符串的首次出现进行替换；g 放在命令开头，表示对正文中所有包含搜索字符串的行进行替换操作§]]></content>
      <categories>
        <category>-巧技</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive 脚本用户 and beeline]]></title>
    <url>%2F2019%2F11%2F09%2Fhive-%E8%84%9A%E6%9C%AC%E7%94%A8%E6%88%B7-and-beeline%2F</url>
    <content type="text"><![CDATA[HiveServer2 Clients HiveServer2Clients简介1.beeline是什么​ Beeline，是HiveServer2的JDBC客户端，基于SQLLine命令行接口。Beeline Shell可以工作在嵌入式模式和远程模式，在嵌入式模式中，它运行一个嵌入式的Hive（类似于Hive CLI），在远程模式中，通过Thrift连接到一个单独的HiveServer2进程，从Hive 0.14开始，当Beeline和HiveServer2一起使用时，它会从HiveServer2打印执行查询的日志信息到STDERR。建议在生产环境使用远程HiveServer2模式，因为这样更安全，不需要为用户授予直接的HDFS/Metastore访问权限 2.beeline具体应用 1234567891011121314151617181920212223242526272829303132333435363738394041:beeline -help Usage: java org.apache.hive.cli.beeline.BeeLine -u &lt;database url&gt; the JDBC URL to connect to -n &lt;username&gt; the username to connect as -p &lt;password&gt; the password to connect as -d &lt;driver class&gt; the driver class to use -i &lt;init file&gt; script file for initialization -e &lt;query&gt; query that should be executed -f &lt;exec file&gt; script file that should be executed -w (or) --password-file &lt;password file&gt; the password file to read password from --hiveconf property=value Use value for given property --hivevar name=value hive variable name and value This is Hive specific settings in which variables can be set at session level and referenced in Hive commands or queries. --color=[true/false] control whether color is used for display --showHeader=[true/false] show column names in query results --headerInterval=ROWS; the interval between which heades are displayed --fastConnect=[true/false] skip building table/column list for tab-completion --autoCommit=[true/false] enable/disable automatic transaction commit --verbose=[true/false] show verbose error messages and debug info --showWarnings=[true/false] display connection warnings --showNestedErrs=[true/false] display nested errors --numberFormat=[pattern] format numbers using DecimalFormat pattern --entireLineAsCommand=[true/false] control whether entire line treats as one command --force=[true/false] continue running script even after errors --maxWidth=MAXWIDTH the maximum width of the terminal --maxColumnWidth=MAXCOLWIDTH the maximum width to use when displaying columns --silent=[true/false] be more silent --autosave=[true/false] automatically save preferences --outputformat=[table/vertical/csv2/tsv2/dsv/csv/tsv] format mode for result display Note that csv, and tsv are deprecated - use csv2, tsv2 instead --truncateTable=[true/false] truncate table column when it exceeds length --delimiterForDSV=DELIMITER specify the delimiter for delimiter-separated values output format (default: |) --isolation=LEVEL set the transaction isolation level --nullemptystring=[true/false] set to true to get historic behavior of printing null as empty string --addlocaldriverjar=DRIVERJARNAME Add driver jar file in the beeline client side --addlocaldrivername=DRIVERNAME Add drvier name needs to be supported in the beeline client side --incremental=[true/false] Print output incrementally --help display this message hive sql 运行常见的错误 \1. java.lang.nullpointerexception这个异常大家肯定都经常遇到，异常的解释是”程序遇上了空指针”，简单地说就是调用了未经初始化的对象或者是不存在的对象，这个错误经常出现在创建图片，调用数组这些操作中，比如图片未经初始化，或者图片创建时的路径错误等等。对数组操作中出现空指针，很多情况下是一些刚开始学习编程的朋友常犯的错误，即把数组的初始化和数组元素的初始化混淆起来了。数组的初始化是对数组分配需要的空间，而初始化后的数组，其中的元素并没有实例化，依然是空的，所以还需要对每个元素都进行初始化（如果要调用的话） \2. java.lang.classnotfoundexception这个异常是很多原本在jb等开发环境中开发的程序员，把jb下的程序包放在wtk下编译经常出现的问题，异常的解释是”指定的类不存在”，这里主要考虑一下类的名称和路径是否正确即可，如果是在jb下做的程序包，一般都是默认加上package的，所以转到wtk下后要注意把package的路径加上。 \3. java.lang.arithmeticexception这个异常的解释是”数学运算异常”，比如程序中出现了除以零这样的运算就会出这样的异常，对这种异常，大家就要好好检查一下自己程序中涉及到数学运算的地方，公式是不是有不妥了。 \4. java.lang.arrayindexoutofboundsexception这个异常相信很多朋友也经常遇到过，异常的解释是”数组下标越界“，现在程序中大多都有对数组的操作，因此在调用数组的时候一定要认真检查，看自己调用的下标是不是超出了数组的范围，一般来说，显示（即直接用常数当下标）调用不太容易出这样的错，但隐式（即用变量表示下标）调用就经常出错了，还有一种情况，是程序中定义的数组的长度是通过某些特定方法决定的，不是事先声明的，这个时候，最好先查看一下数组的length，以免出现这个异常。 \5. java.lang.illegalargumentexception这个异常的解释是”方法的参数错误”，很多j2me的类库中的方法在一些情况下都会引发这样的错误，比如音量调节方法中的音量参数如果写成负数就会出现这个异常，再比如g.setcolor(int red,int green,int blue)这个方法中的三个值，如果有超过255的也会出现这个异常，因此一旦发现这个异常，我们要做的，就是赶紧去检查一下方法调用中的参数传递是不是出现了错误。 \6. java.lang.illegalaccessexception这个异常的解释是”没有访问权限“，当应用程序要调用一个类，但当前的方法即没有对该类的访问权限便会出现这个异常。对程序中用了package的情况下要注意这个异常。 其他还有很多异常，我就不一一列举了，我要说明的是，一个合格的程序员，需要对程序中常见的问题有相当的了解和相应的解决办法，否则仅仅停留在写程序而不会改程序的话，会极大影响到自己的开发的。关于异常的全部说明，在api里都可以查阅。 算术异常类：ArithmeticExecption 空指针异常类：NullPointerException 类型强制转换异常：ClassCastException 数组负下标异常：NegativeArrayException 数组下标越界异常：ArrayIndexOutOfBoundsException 违背安全原则异常：SecturityException 文件已结束异常：EOFException 文件未找到异常：FileNotFoundException 字符串转换为数字异常：NumberFormatException 操作数据库异常：SQLException 输入输出异常：IOException 方法未找到异常：NoSuchMethodException java.lang.AbstractMethodError 抽象方法错误。当应用试图调用抽象方法时抛出。 java.lang.AssertionError 断言错。用来指示一个断言失败的情况。 java.lang.ClassCircularityError 类循环依赖错误。在初始化一个类时，若检测到类之间循环依赖则抛出该异常。 java.lang.ClassFormatError 类格式错误。当Java虚拟机试图从一个文件中读取Java类，而检测到该文件的内容不符合类的有效格式时抛出。 java.lang.Error 错误。是所有错误的基类，用于标识严重的程序运行问题。这些问题通常描述一些不应被应用程序捕获的反常情况。 java.lang.ExceptionInInitializerError 初始化程序错误。当执行一个类的静态初始化程序的过程中，发生了异常时抛出。静态初始化程序是指直接包含于类中的static语句段。 java.lang.IllegalAccessError 违法访问错误。当一个应用试图访问、修改某个类的域（Field）或者调用其方法，但是又违反域或方法的可见性声明，则抛出该异常。 java.lang.IncompatibleClassChangeError 不兼容的类变化错误。当正在执行的方法所依赖的类定义发生了不兼容的改变时，抛出该异常。一般在修改了应用中的某些类的声明定义而没有对整个应用重新编译而直接运行的情况下，容易引发该错误。 java.lang.InstantiationError 实例化错误。当一个应用试图通过Java的new操作符构造一个抽象类或者接口时抛出该异常. java.lang.InternalError 内部错误。用于指示Java虚拟机发生了内部错误。 java.lang.LinkageError 链接错误。该错误及其所有子类指示某个类依赖于另外一些类，在该类编译之后，被依赖的类改变了其类定义而没有重新编译所有的类，进而引发错误的情况。 java.lang.NoClassDefFoundError 未找到类定义错误。当Java虚拟机或者类装载器试图实例化某个类，而找不到该类的定义时抛出该错误。 java.lang.NoSuchFieldError 域不存在错误。当应用试图访问或者修改某类的某个域，而该类的定义中没有该域的定义时抛出该错误。 java.lang.NoSuchMethodError 方法不存在错误。当应用试图调用某类的某个方法，而该类的定义中没有该方法的定义时抛出该错误。 java.lang.OutOfMemoryError 内存不足错误。当可用内存不足以让Java虚拟机分配给一个对象时抛出该错误。 java.lang.StackOverflowError 堆栈溢出错误。当一个应用递归调用的层次太深而导致堆栈溢出时抛出该错误。 java.lang.ThreadDeath 线程结束。当调用Thread类的stop方法时抛出该错误，用于指示线程结束。 java.lang.UnknownError 未知错误。用于指示Java虚拟机发生了未知严重错误的情况。 java.lang.UnsatisfiedLinkError 未满足的链接错误。当Java虚拟机未找到某个类的声明为native方法的本机语言定义时抛出。 java.lang.UnsupportedClassVersionError 不支持的类版本错误。当Java虚拟机试图从读取某个类文件，但是发现该文件的主、次版本号不被当前Java虚拟机支持的时候，抛出该错误。 java.lang.VerifyError 验证错误。当验证器检测到某个类文件中存在内部不兼容或者安全问题时抛出该错误。 java.lang.VirtualMachineError 虚拟机错误。用于指示虚拟机被破坏或者继续执行操作所需的资源不足的情况。 java.lang.ArithmeticException 算术条件异常。譬如：整数除零等。 java.lang.ArrayIndexOutOfBoundsException 数组索引越界异常。当对数组的索引值为负数或大于等于数组大小时抛出。 java.lang.ArrayStoreException 数组存储异常。当向数组中存放非数组声明类型对象时抛出。 java.lang.ClassCastException 类造型异常。假设有类A和B（A不是B的父类或子类），O是A的实例，那么当强制将O构造为类B的实例时抛出该异常。该异常经常被称为强制类型转换异常。 java.lang.ClassNotFoundException 找不到类异常。当应用试图根据字符串形式的类名构造类，而在遍历CLASSPAH之后找不到对应名称的class文件时，抛出该异常。 java.lang.CloneNotSupportedException 不支持克隆异常。当没有实现Cloneable接口或者不支持克隆方法时,调用其clone()方法则抛出该异常。 java.lang.EnumConstantNotPresentException 枚举常量不存在异常。当应用试图通过名称和枚举类型访问一个枚举对象，但该枚举对象并不包含常量时，抛出该异常。 java.lang.Exception 根异常。用以描述应用程序希望捕获的情况。 java.lang.IllegalAccessException 违法的访问异常。当应用试图通过反射方式创建某个类的实例、访问该类属性、调用该类方法，而当时又无法访问类的、属性的、方法的或构造方法的定义时抛出该异常。 java.lang.IllegalMonitorStateException 违法的监控状态异常。当某个线程试图等待一个自己并不拥有的对象（O）的监控器或者通知其他线程等待该对象（O）的监控器时，抛出该异常。 java.lang.IllegalStateException 违法的状态异常。当在Java环境和应用尚未处于某个方法的合法调用状态，而调用了该方法时，抛出该异常。 java.lang.IllegalThreadStateException 违法的线程状态异常。当县城尚未处于某个方法的合法调用状态，而调用了该方法时，抛出异常。 java.lang.IndexOutOfBoundsException 索引越界异常。当访问某个序列的索引值小于0或大于等于序列大小时，抛出该异常。 java.lang.InstantiationException 实例化异常。当试图通过newInstance()方法创建某个类的实例，而该类是一个抽象类或接口时，抛出该异常。 java.lang.InterruptedException 被中止异常。当某个线程处于长时间的等待、休眠或其他暂停状态，而此时其他的线程通过Thread的interrupt方法终止该线程时抛出该异常。 java.lang.NegativeArraySizeException 数组大小为负值异常。当使用负数大小值创建数组时抛出该异常。 java.lang.NoSuchFieldException 属性不存在异常。当访问某个类的不存在的属性时抛出该异常。 java.lang.NoSuchMethodException 方法不存在异常。当访问某个类的不存在的方法时抛出该异常。 java.lang.NullPointerException 空指针异常。当应用试图在要求使用对象的地方使用了null时，抛出该异常。譬如：调用null对象的实例方法、访问null对象的属性、计算null对象的长度、使用throw语句抛出null等等。 java.lang.NumberFormatException 数字格式异常。当试图将一个String转换为指定的数字类型，而该字符串确不满足数字类型要求的格式时，抛出该异常。 java.lang.RuntimeException 运行时异常。是所有Java虚拟机正常操作期间可以被抛出的异常的父类。 java.lang.SecurityException 安全异常。由安全管理器抛出，用于指示违反安全情况的异常。 java.lang.StringIndexOutOfBoundsException 字符串索引越界异常。当使用索引值访问某个字符串中的字符，而该索引值小于0或大于等于序列大小时，抛出该异常。 java.lang.TypeNotPresentException 类型不存在异常。当应用试图]]></content>
      <categories>
        <category>hive</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux菜鸟]]></title>
    <url>%2F2019%2F11%2F05%2Flinux%E8%8F%9C%E9%B8%9F%2F</url>
    <content type="text"><![CDATA[菜鸟-linux命令总结linux命令大全教程 linux搜索大全 linux命令搜索教程岚 linux安装教程-bigData shell脚本案列大全 1. 命令大全文件传输1bye、ftp、ftpcount、ftpshut、ftpwho、ncftp、tftp、uucico、uucp、uupick、uuto、scp 备份压缩1ar、bunzip2、bzip2、bzip2recover、compress、cpio、dump、gunzip、gzexe、gzip、lha、restore、tar、unarj、unzip、zip、zipinfo 文件管理1diff、diffstat、file、find、git、gitview、ln、locate、lsattr、mattrib、mc、mcopy、mdel、mdir、mktemp、mmove、mread、mren、mshowfat、mtools、mtoolstest、mv、od、paste、patch、rcp、rhmask、rm、slocate、split、tee、tmpwatch、touch、umask、whereis、which、cat、chattr、chgrp、chmod、chown、cksum、cmp、cp、cut、indent 磁盘管理1cd、df、dirs、du、edquota、eject、lndir、ls、mcd、mdeltree、mdu、mkdir、mlabel、mmd、mmount、mrd、mzip、pwd、quota、quotacheck、quotaoff、quotaon、repquota、rmdir、rmt、stat、tree、umount 磁盘维护1badblocks、cfdisk、dd、e2fsck、ext2ed、fdisk、fsck.ext2、fsck、fsck.minix、fsconf、hdparm、losetup、mbadblocks、mformat、mkbootdisk、mkdosfs、mke2fs、mkfs.ext2、mkfs、mkfs.minix、mkfs.msdos、mkinitrd、mkisofs、mkswap、mpartition、sfdisk、swapoff、swapon、symlinks、sync 系统设置1alias、apmd、aumix、bind、chkconfig、chroot、clock、crontab、declare、depmod、dircolors、dmesg、enable、eval、export、fbset、grpconv、grpunconv、hwclock、insmod、kbdconfig、lilo、liloconfig、lsmod、minfo、mkkickstart、modinfo、modprobe、mouseconfig、ntsysv、passwd、pwconv、pwunconv、rdate、resize、rmmod、rpm、set、setconsole、setenv、setup、sndconfig、SVGAText Mode、timeconfig、ulimit、unalias、unset 系统管理1adduser、chfn、chsh、date、exit、finger、free、fwhois、gitps、groupdel、groupmod、halt、id、kill、last、lastb、login、logname、logout、logrotate、newgrp、nice、procinfo、ps、pstree、reboot、renice、rlogin、rsh、rwho、screen、shutdown、sliplogin、su、sudo、suspend、swatch、tload、top、uname、useradd、userconf、userdel、usermod、vlock、w、who、whoami、whois 文本处理1awk、col、colrm、comm、csplit、ed、egrep、ex、fgrep、fmt、fold、grep、ispell、jed、joe、join、look、mtype、pico、rgrep、sed、sort、spell、tr、uniq、vi、wc 网络通讯1dip、getty、mingetty、ppp-off、smbd(samba daemon)、telnet、uulog、uustat、uux、cu、dnsconf、efax、httpd、ip、ifconfig、mesg、minicom、nc、netconf、netconfig、netstat、ping、pppstats、samba、setserial、shapecfg(shaper configuration)、smbd(samba daemon)、statserial(status ofserial port)、talk、tcpdump、testparm(test parameter)、traceroute、tty(teletypewriter)、uuname、wall(write all)、write、ytalk、arpwatch、apachectl、smbclient(samba client)、pppsetup 设备管理1dumpkeys、loadkeys、MAKEDEV、rdev、setleds 电子邮件与新闻组1archive、ctlinnd、elm、getlist、inncheck、mail、mailconf、mailq、messages、metamail、mutt、nntpget、pine、slrn、X WINDOWS SYSTEM、reconfig、startx(start X Window)、Xconfigurator、XF86Setup、xlsatoms、xlsclients、xlsfonts 其他命令1yes linux常用命令1. tar创建一个新的tar文件 1$ tar cvf archive_name.tar dirname/ 解压tar文件 1$ tar xvf archive_name.tar 查看tar文件 1$ tar tvf archive_name.tar 更多示例：The Ultimate Tar Command Tutorial with 10 Practical Examples 2. grep在文件中查找字符串(不区分大小写) 1$ grep -i "the" demo_file 输出成功匹配的行，以及该行之后的三行 1$ grep -A 3 -i "example" demo_text 在一个文件夹中递归查询包含指定字符串的文件 1$ grep -r "ramesh" * 更多示例：Get a Grip on the Grep! – 15 Practical Grep Command Examples 3. find查找指定文件名的文件(不区分大小写) 1$ find -iname "MyProgram.c" 对找到的文件执行某个命令 1$ find -iname "MyProgram.c" -exec md5sum &#123;&#125; \; 查找home目录下的所有空文件 1$ find ~ -empty 更多示例：Mommy, I found it! — 15 Practical Linux Find Command Examples 4. ssh登录到远程主机 1$ ssh -l jsmith remotehost.example.com 调试ssh客户端 1$ ssh -v -l jsmith remotehost.example.com 显示ssh客户端版本 1$ ssh -V 更多示例：5 Basic Linux SSH Client Commands 5. sed当你将Dos系统中的文件复制到Unix/Linux后，这个文件每行都会以\r\n结尾，sed可以轻易将其转换为Unix格式的文件，使用\n结尾的文件 1$ sed 's/.$//' filename 反转文件内容并输出 1$ sed -n '1!G; h; p' filename 为非空行添加行号 1$ sed '/./=' thegeekstuff.txt | sed 'N; s/\n/ /' 更多示例：Advanced Sed Substitution Examples 6. awk删除重复行 1$ awk '!($0 in array) &#123; array[$0]; print&#125;' temp 打印/etc/passwd中所有包含同样的uid和gid的行 1$ awk -F ':' '$3=$4' /etc/passwd 打印文件中的指定部分的字段 1$ awk '&#123;print $2,$5;&#125;' employee.txt 更多示例：8 Powerful Awk Built-in Variables – FS, OFS, RS, ORS, NR, NF, FILENAME, FNR 7. vim打开文件并跳到第10行 1$ vim +10 filename.txt 打开文件跳到第一个匹配的行 1$ vim +/search-term filename.txt 以只读模式打开文件 1$ vim -R /etc/passwd 更多示例：How To Record and Play in Vim Editor 8. diff比较的时候忽略空白符 1$ diff -w name_list.txt name_list_new.txt 9. sort以升序对文件内容排序 1$ sort names.txt 以降序对文件内容排序 1$ sort -r names.txt 以第三个字段对/etc/passwd的内容排序 1$ sort -t: -k 3n /etc/passwd | more 10. export输出跟字符串oracle匹配的环境变量 12345$ export | grep ORCALEdeclare -x ORACLE_BASE="/u01/app/oracle"declare -x ORACLE_HOME="/u01/app/oracle/product/10.2.0"declare -x ORACLE_SID="med"declare -x ORACLE_TERM="xterm" 设置全局环境变量 1$ export ORACLE_HOME=/u01/app/oracle/product/10.2.0 11. xargs将所有图片文件拷贝到外部驱动器 1$ ls *.jpg | xargs -n1 -i cp &#123;&#125; /external-hard-drive/directory 将系统中所有jpd文件压缩打包 1$ find / -name *.jpg -type f -print | xargs tar -cvzf images.tar.gz 下载文件中列出的所有url对应的页面 1$ cat url-list.txt | xargs wget –c 12. ls以易读的方式显示文件大小(显示为MB,GB…) 12$ ls -lh-rw-r----- 1 ramesh team-dev 8.9M Jun 12 15:27 arch-linux.txt.gz 以最后修改时间升序列出文件 1$ ls -ltr 在文件名后面显示文件类型 1$ ls -F 更多示例：Unix LS Command: 15 Practical Examples 13. pwd输出当前工作目录 14. cdcd -可以在最近工作的两个目录间切换 使用shopt -s cdspell可以设置自动对cd命令进行拼写检查 更多示例：6 Awesome Linux cd command Hacks 15. gzip创建一个*.gz的压缩文件 1$ gzip test.txt 解压*.gz文件 1$ gzip -d test.txt.gz 显示压缩的比率 123$ gzip -l *.gz compressed uncompressed ratio uncompressed_name 23709 97975 75.8% asp-patch-rpms.txt 16. bzip2创建*.bz2压缩文件 1$ bzip2 test.txt 解压*.bz2文件 1bzip2 -d test.txt.bz2 更多示例：BZ is Eazy! bzip2, bzgrep, bzcmp, bzdiff, bzcat, bzless, bzmore examples 17. uzip解压*.zip文件 1$ unzip test.zip 查看*.zip文件的内容 12345678$ unzip -l jasper.zipArchive: jasper.zipLength Date Time Name-------- ---- ---- ----40995 11-30-98 23:50 META-INF/MANIFEST.MF32169 08-25-98 21:07 classes_15964 08-25-98 21:07 classes_names10542 08-25-98 21:07 classes_ncomp 18. shutdown关闭系统并立即关机 1$ shutdown -h now 10分钟后关机 1$ shutdown -h +10 重启 1$ shutdown -r now 重启期间强制进行系统检查 1$ shutdown -Fr now 19. ftpftp命令和sftp命令的用法基本相似连接ftp服务器并下载多个文件 12$ ftp IP/hostnameftp&gt; mget *.html 显示远程主机上文件列表 123456ftp&gt; mls *.html -/ftptest/features.html/ftptest/index.html/ftptest/othertools.html/ftptest/samplereport.html/ftptest/usage.html 更多示例：FTP and SFTP Beginners Guide with 10 Examples 20. crontab查看某个用户的crontab入口 1$ crontab -u john -l 设置一个每十分钟执行一次的计划任务 1*/10 * * * * /home/ramesh/check-disk-space 更多示例：Linux Crontab: 15 Awesome Cron Job Examples 21. serviceservice命令用于运行System V init脚本，这些脚本一般位于/etc/init.d文件下，这个命令可以直接运行这个文件夹里面的脚本，而不用加上路径 查看服务状态 1$ service ssh status 查看所有服务状态 1$ service --status-all 重启服务 1$ service ssh restart 22. psps命令用于显示正在运行中的进程的信息，ps命令有很多选项，这里只列出了几个 查看当前正在运行的所有进程 1$ ps -ef | more 以树状结构显示当前正在运行的进程，H选项表示显示进程的层次结构 1$ ps -efH | more 23. free这个命令用于显示系统当前内存的使用情况，包括已用内存、可用内存和交换内存的情况 默认情况下free会以字节为单位输出内存的使用量 12345$ free total used free shared buffers cachedMem: 3566408 1580220 1986188 0 203988 902960-/+ buffers/cache: 473272 3093136Swap: 4000176 0 4000176 如果你想以其他单位输出内存的使用量，需要加一个选项，-g为GB，-m为MB，-k为KB，-b为字节 12345$ free -g total used free shared buffers cachedMem: 3 1 1 0 0 0-/+ buffers/cache: 0 2Swap: 3 0 3 如果你想查看所有内存的汇总，请使用-t选项，使用这个选项会在输出中加一个汇总行 123456ramesh@ramesh-laptop:~$ free -t total used free shared buffers cachedMem: 3566408 1592148 1974260 0 204260 912556-/+ buffers/cache: 475332 3091076Swap: 4000176 0 4000176Total: 7566584 1592148 5974436 24. toptop命令会显示当前系统中占用资源最多的一些进程（默认以CPU占用率排序）如果你想改变排序方式，可以在结果列表中点击O（大写字母O）会显示所有可用于排序的列，这个时候你就可以选择你想排序的列 1234567Current Sort Field: P for window 1:DefSelect sort field via field letter, type any other key to return a: PID = Process Id v: nDRT = Dirty Pages count d: UID = User Id y: WCHAN = Sleeping in Function e: USER = User Name z: Flags = Task Flags ........ 如果只想显示某个特定用户的进程，可以使用-u选项 1$ top -u oracle 更多示例：Can You Top This? 15 Practical Linux Top Command Examples 25. df显示文件系统的磁盘使用情况，默认情况下df -k将以字节为单位输出磁盘的使用量 1234$ df -kFilesystem 1K-blocks Used Available Use% Mounted on/dev/sda1 29530400 3233104 24797232 12% //dev/sda2 120367992 50171596 64082060 44% /home 使用-h选项可以以更符合阅读习惯的方式显示磁盘使用量 12345678$ df -hFilesystem Size Used Avail Capacity iused ifree %iused Mounted on/dev/disk0s2 232Gi 84Gi 148Gi 37% 21998562 38864868 36% /devfs 187Ki 187Ki 0Bi 100% 648 0 100% /devmap -hosts 0Bi 0Bi 0Bi 100% 0 0 100% /netmap auto_home 0Bi 0Bi 0Bi 100% 0 0 100% /home/dev/disk0s4 466Gi 45Gi 421Gi 10% 112774 440997174 0% /Volumes/BOOTCAMP//app@izenesoft.cn/public 2.7Ti 1.3Ti 1.4Ti 48% 0 18446744073709551615 0% /Volumes/public 使用-T选项显示文件系统类型 1234$ df -TFilesystem Type 1K-blocks Used Available Use% Mounted on/dev/sda1 ext4 29530400 3233120 24797216 12% //dev/sda2 ext4 120367992 50171596 64082060 44% /home 26. killkill用于终止一个进程。一般我们会先用ps -ef查找某个进程得到它的进程号，然后再使用kill -9 进程号终止该进程。你还可以使用killall、pkill、xkill来终止进程 1234$ ps -ef | grep vimramesh 7243 7222 9 22:43 pts/2 00:00:00 vim$ kill -9 7243 更多示例：4 Ways to Kill a Process – kill, killall, pkill, xkill 27. rm删除文件前先确认 1$ rm -i filename.txt 在文件名中使用shell的元字符会非常有用。删除文件前先打印文件名并进行确认 1$ rm -i file* 递归删除文件夹下所有文件，并删除该文件夹 1$ rm -r example 28. cp拷贝文件1到文件2，并保持文件的权限、属主和时间戳 1$ cp -p file1 file2 拷贝file1到file2，如果file2存在会提示是否覆盖 1$ cp -i file1 file2 29. mv将文件名file1重命名为file2，如果file2存在则提示是否覆盖 1$ mv -i file1 file2 注意如果使用-f选项则不会进行提示 -v会输出重命名的过程，当文件名中包含通配符时，这个选项会非常方便 1$ mv -v file1 file2 30. cat你可以一次查看多个文件的内容，下面的命令会先打印file1的内容，然后打印file2的内容 1$ cat file1 file2 -n命令可以在每行的前面加上行号 1234567$ cat -n /etc/logrotate.conf 1 /var/log/btmp &#123; 2 missingok 3 monthly 4 create 0660 root utmp 5 rotate 1 6 &#125; 31. mount如果要挂载一个文件系统，需要先创建一个目录，然后将这个文件系统挂载到这个目录上 123# mkdir /u01# mount /dev/sdb1 /u01 也可以把它添加到fstab中进行自动挂载，这样任何时候系统重启的时候，文件系统都会被加载 1/dev/sdb1 /u01 ext2 defaults 0 2 32. chmodchmod用于改变文件和目录的权限 给指定文件的属主和属组所有权限(包括读、写、执行) 1$ chmod ug+rwx file.txt 删除指定文件的属组的所有权限 1$ chmod g-rwx file.txt 修改目录的权限，以及递归修改目录下面所有文件和子目录的权限 1$ chmod -R ug+rwx file.txt 更多示例：7 Chmod Command Examples for Beginners 33. chownchown用于改变文件属主和属组 同时将某个文件的属主改为oracle，属组改为db 1$ chown oracle:dba dbora.sh 使用-R选项对目录和目录下的文件进行递归修改 1$ chown -R oracle:dba /home/oracle 34. passwdpasswd用于在命令行修改密码，使用这个命令会要求你先输入旧密码，然后输入新密码 1$ passwd 超级用户可以用这个命令修改其他用户的密码，这个时候不需要输入用户的密码 1# passwd USERNAME passwd还可以删除某个用户的密码，这个命令只有root用户才能操作，删除密码后，这个用户不需要输入密码就可以登录到系统 1# passwd -d USERNAME 35. mkdir在home目录下创建一个名为temp的目录 1$ mkdir ~/temp 使用-p选项可以创建一个路径上所有不存在的目录 1$ mkdir -p dir1/dir2/dir3/dir4/ 36. ifconfigifconfig用于查看和配置Linux系统的网络接口 查看所有网络接口及其状态 1$ ifconfig -a 使用up和down命令启动或停止某个接口 123$ ifconfig eth0 up$ ifconfig eth0 down 更多示例：Ifconfig: 7 Examples To Configure Network Interface 37. unameuname可以显示一些重要的系统信息，例如内核名称、主机名、内核版本号、处理器类型之类的信息 12$ uname -aLinux john-laptop 2.6.32-24-generic #41-Ubuntu SMP Thu Aug 19 01:12:52 UTC 2010 i686 GNU/Linux 38. whereis当你不知道某个命令的位置时可以使用whereis命令，下面使用whereis查找ls的位置 12$ whereis lsls: /bin/ls /usr/share/man/man1/ls.1.gz /usr/share/man/man1p/ls.1p.gz 当你想查找某个可执行程序的位置，但这个程序又不在whereis的默认目录下，你可以使用-B选项，并指定目录作为这个选项的参数。下面的命令在/tmp目录下查找lsmk命令 12$ whereis -u -B /tmp -f lsmklsmk: /tmp/lsmk 39. whatiswathis显示某个命令的描述信息 12345$ whatis lsls (1) - list directory contents$ whatis ifconfigifconfig (8) - configure a network interface 40. locatelocate命名可以显示某个指定文件（或一组文件）的路径，它会使用由updatedb创建的数据库 下面的命令会显示系统中所有包含crontab字符串的文件 123456789$ locate crontab/etc/anacrontab/etc/crontab/usr/bin/crontab/usr/share/doc/cron/examples/crontab2english.pl.gz/usr/share/man/man1/crontab.1.gz/usr/share/man/man5/anacrontab.5.gz/usr/share/man/man5/crontab.5.gz/usr/share/vim/vim72/syntax/crontab.vim 41. man显示某个命令的man页面 1$ man crontab 有些命令可能会有多个man页面，每个man页面对应一种命令类型 1$ man SECTION-NUMBER commandname man页面一般可以分为8种命令类型 用户命令 系统调用 c库函数 设备与网络接口 文件格式 游戏与屏保 环境、表、宏 系统管理员命令和后台运行命令 例如，我们执行whatis crontab，你可以看到crontab有两个命令类型1和5，所以我们可以通过下面的命令查看命令类型5的man页面 12345$ whatis crontabcrontab (1) - maintain crontab files for individual users (V3)crontab (5) - tables for driving cron$ man 5 crontab 42. tailtail命令默认显示文件最后的10行文本 1$ tail filename.txt 你可以使用-n选项指定要显示的行数 1$ tail -n N filename.txt 你也可以使用-f选项进行实时查看，这个命令执行后会等待，如果有新行添加到文件尾部，它会继续输出新的行，在查看日志时这个选项会非常有用。你可以通过CTRL-C终止命令的执行 1$ tail -f log-file 更多示例：3 Methods To View tail -f output of Multiple Log Files in One Terminal 43. less这个命名可以在不加载整个文件的前提下显示文件内容，在查看大型日志文件的时候这个命令会非常有用 1$ less huge-log-file.log 当你用less命令打开某个文件时，下面两个按键会给你带来很多帮助，他们用于向前和向后滚屏 12CTRL+F – forward one windowCTRL+B – backward one window 更多示例：Unix Less Command: 10 Tips for Effective Navigation 44. susu命令用于切换用户账号，超级用户使用这个命令可以切换到任何其他用户而不用输入密码 1$ su - USERNAME 用另外一个用户名执行一个命令下面的示例中用户john使用raj用户名执行ls命令，执行完后返回john的账号 123[john@dev-server]$ su - raj -c 'ls'[john@dev-server]$ 用指定用户登录，并且使用指定的shell程序，而不用默认的 1$ su -s 'SHELLNAME' USERNAME 45. mysqlmysql可能是Linux上使用最广泛的数据库，即使你没有在你的服务器上安装mysql，你也可以使用mysql客户端连接到远程的mysql服务器 连接一个远程数据库，需要输入密码 1$ mysql -u root -p -h 192.168.1.2 连接本地数据库 1$ mysql -u root -p 你也可以在命令行中输入数据库密码，只需要在-p后面加上密码作为参数，可以直接写在p后面而不用加空格 46. yum使用yum安装apache 1$ yum install httpd 更新apache 1$ yum update httpd 卸载/删除apache 1$ yum remove httpd 47. rpm使用rpm安装apache 1# rpm -ivh httpd-2.2.3-22.0.1.el5.i386.rpm 更新apache 1# rpm -uvh httpd-2.2.3-22.0.1.el5.i386.rpm 卸载/删除apache 1# rpm -ev httpd 更多示例：RPM Command: 15 Examples to Install, Uninstall, Upgrade, Query RPM Packages 48. pingping一个远程主机，只发5个数据包 1$ ping -c 5 gmail.com 更多示例：Ping Tutorial: 15 Effective Ping Command Examples 49. date设置系统日期 1# date -s "01/31/2010 23:59:53" 当你修改了系统时间，你需要同步硬件时间和系统时间 123# hwclock –systohc# hwclock --systohc –utc 50. wget使用wget从网上下载软件、音乐、视频 1$ wget http://prdownloads.sourceforge.net/sourceforge/nagios/nagios-3.2.1.tar.gz 下载文件并以指定的文件名保存文件 1$ wget -O taglist.zip http://www.vim.org/scripts/download_script.php?src_id=7701]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Win10设置电脑内网连接网线，外网连接wifi]]></title>
    <url>%2F2019%2F11%2F04%2FWin10%E8%AE%BE%E7%BD%AE%E7%94%B5%E8%84%91%E5%86%85%E7%BD%91%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BA%BF%EF%BC%8C%E5%A4%96%E7%BD%91%E8%BF%9E%E6%8E%A5wifi%2F</url>
    <content type="text"><![CDATA[Win10设置电脑内网连接网线，外网连接wifi win10一台电脑即可使用内网又可使用外网原理 ​ 您可以把电脑比喻为一个路由器。就像打电话的移动服务器一样，一台服务器可以多个用户使用，就是因为每一个用户有专用的电话号码，然后通过中转服务器转到你所到达的属地，再到达相应的用用户。 ​ 所以你就是用户，电脑就是中转器，你访问不同的页面，通过路由转到不同的网段，就可以使用相应的网络了。当然内网和外网是有优先级的。也就是说你访问的网页，优先使用哪一个网段。选取看你电脑哪一个网段是常用的。比如说我，外网常用，当然使用外网，并且外网的访问ip是很复杂的，分配网段比较复杂，分配内容比较容易。 route 常用命令的使用 a. win+r 或者搜索栏输入cmd，然后右键，选择管理员运行win10命令串口。输入route，回显示帮助界面 b. route -f 清空配置路由 c. route print 查看路由 d. route delete 删除路由 c. route -p add 内网(外网)ip地址 mask 子网掩码 内网(外网)网关 注：都可以通配符使用，比如route print 10.* route 具体使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869操作网络路由表。ROUTE [-f] [-p] [-4|-6] command [destination] [MASK netmask] [gateway] [METRIC metric] [IF interface] -f 清除所有网关项的路由表。如果与某个 命令结合使用，在运行该命令前， 应清除路由表。 -p 与 ADD 命令结合使用时，将路由设置为 在系统引导期间保持不变。默认情况下，重新启动系统时， 不保存路由。忽略所有其他命令， 这始终会影响相应的永久路由。 -4 强制使用 IPv4。 -6 强制使用 IPv6。 command 其中之一: PRINT 打印路由 ADD 添加路由 DELETE 删除路由 CHANGE 修改现有路由 destination 指定主机。 MASK 指定下一个参数为“netmask”值。 netmask 指定此路由项的子网掩码值。 如果未指定，其默认设置为 255.255.255.255。 gateway 指定网关。 interface 指定路由的接口号码。 METRIC 指定跃点数，例如目标的成本。用于目标的所有符号名都可以在网络数据库文件 NETWORKS 中进行查找。用于网关的符号名称都可以在主机名称数据库文件 HOSTS 中进行查找。如果命令为 PRINT 或 DELETE。目标或网关可以为通配符，(通配符指定为星号“*”)，否则可能会忽略网关参数。如果 Dest 包含一个 * 或 ?，则会将其视为 Shell 模式，并且只打印匹配目标路由。“*”匹配任意字符串，而“?”匹配任意一个字符。示例: 157.*.1、157.*、127.*、*224*。只有在 PRINT 命令中才允许模式匹配。诊断信息注释: 无效的 MASK 产生错误，即当 (DEST &amp; MASK) != DEST 时。 示例: &gt; route ADD 157.0.0.0 MASK 155.0.0.0 157.55.80.1 IF 1 路由添加失败: 指定的掩码参数无效。 (Destination &amp; Mask) != Destination。示例: &gt; route PRINT &gt; route PRINT -4 &gt; route PRINT -6 &gt; route PRINT 157* .... 只打印那些匹配 157* 的项 &gt; route ADD 157.0.0.0 MASK 255.0.0.0 157.55.80.1 METRIC 3 IF 2 destination^ ^mask ^gateway metric^ ^ Interface^ 如果未给出 IF，它将尝试查找给定网关的最佳 接口。 &gt; route ADD 3ffe::/32 3ffe::1 &gt; route CHANGE 157.0.0.0 MASK 255.0.0.0 157.55.80.5 METRIC 2 IF 2 CHANGE 只用于修改网关和/或跃点数。 &gt; route DELETE 157.0.0.0 &gt; route DELETE 3ffe::/32 配置网络流程 使用route pirnt 查看内网外网的ip网段和网关(route print | ipconfig/all | win设置以太网和wlan进行查看属性) 先把外网关掉，先配内网，然后配外网 route配置 route delete 0.0.0.0 -p 删掉0.0.0.0网段，因为同时连接会出现两个默认网段（内网和外网）,如果有会出现冲突，导致都不能够使用网络。 route -p add 内网网段 mask 子网掩码 内网网关（分配内网网段）（添加-p 为永久添加，开始检验的时候，可以不添加-p） 1234比如 route -p add 10.0.0.0 mask 255.0.0.0 10.10.171.201 （内网网关）1.10.0.0.0中零的数量和255.0.0.0 数量一致2.意思内网33.*都是使用外网类比 route -p add 10.10.0.0 mask 255.255.0.0 10.10.171.201 查看内网是否可以访问，如果可以了，直接连接wife，就可以内网外网都可以使用了（因为连接外网会直接生成0.0.0.0,外网默认访问字段）。 当然，也可以使用 1route -p add 0.0.0.0 mask 0.0.0.0 192.168.43.1（外网网关） 注意 使用内网时候，一定注意先把往往关掉，然后重启，查看是否配置好。 你也可以在适配器选项修改相应以太网的ipv4的ip和网关，再进行相应的分配。 如果有多个内网网段，可以继续添加，只要不是0.0.0.0默认ip可以添加许多不同的路由网段。]]></content>
      <categories>
        <category>巧技</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[asyncc实践]]></title>
    <url>%2F2019%2F10%2F31%2Fasyncc%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[协程异步实践aiohttp: 是一个为Python提供异步HTTP 客户端/服务端编程，基于asyncio(Python用于支持异步编程的标准库)的异步库。 ​ 此代码，通过aiohttp异步请求四个网页，并且异步解析网页，存储为四个文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120"""It's example of usage asyncio+aiohttp to downloading.You should install aiohttp for using:(You can use virtualenv to testing)pip install -r /path/to/requirements.txt"""import asyncioimport concurrent.futures as cofufrom os.path import basenameimport aiohttpdef download(ways): if not ways: print('Ways list is empty. Downloading is impossible') return print('downloading..') success_files = set() failure_files = set() event_loop = asyncio.get_event_loop() try: event_loop.run_until_complete( async_downloader(ways, event_loop, success_files, failure_files) ) finally: event_loop.close() print('Download complete') print('-' * 100) if success_files: print('success:') for file in success_files: print(file) if failure_files: print('failure:') for file in failure_files: print(file)#请求网页async def async_downloader(ways, loop, success_files=set(), failure_files=set()): async with aiohttp.ClientSession() as session: coroutines = [ download_file_by_url( url, session=session, ) for url in ways] completed, pending = await asyncio.wait(coroutines, return_when=cofu.FIRST_COMPLETED) while pending: for task in completed: fail, url = task.result() if fail: failure_files.add(url) else: success_files.add(url) completed, pending = await asyncio.wait(pending, return_when=cofu.FIRST_COMPLETED) for task in completed: fail, url = task.result() if fail: failure_files.add(url) else: success_files.add(url)#解析网页async def download_file_by_url(url, session=None): fail = True file_name = basename(url) assert session try: async with session.get(url) as response: if response.status == 404: print('\t&#123;&#125; from &#123;&#125; : Failed : &#123;&#125;'.format(file_name, url, '404 - Not found')) return fail, url if not response.status == 200: print('\t&#123;&#125; from &#123;&#125; : Failed : HTTP response &#123;&#125;'.format(file_name, url, response.status)) return fail, url data = await response.read() with open(file_name, 'wb') as file: file.write(data) except asyncio.TimeoutError as err: print('\t&#123;&#125; from &#123;&#125;: Failed : &#123;&#125;'.format(file_name, url, 'Timeout error')) except aiohttp.client_exceptions.ClientConnectionError as err: print('\t&#123;&#125; from &#123;&#125;: Failed : &#123;&#125;'.format(file_name, url, 'Client connection error')) else: print('\t&#123;&#125; from &#123;&#125; : Success'.format(file_name, url)) fail = False return fail, url#多多益善def test(): ways = ['https://www.baidu.com', 'https://www.jd.com', 'https://www.cn.bing.com', 'https://www.snailfrying.github.io', ] download(ways)if __name__ == "__main__": test()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chapter1_string_algorithm]]></title>
    <url>%2F2019%2F10%2F30%2Fchapter1-string-algorithm%2F</url>
    <content type="text"><![CDATA[chapter1_string_algorithm此章节过于leetcode类，全部是关于字符串方面的算法题，包括解题思路，以及Python代码 1.1 旋转字符串题目描述给定一个字符串，要求把字符串前面的若干个字符移动到字符串的尾部，如把字符串“abcdef”前面的2个字符’a’和’b’移动到字符串的尾部，使得原字符串变成字符串“cdefab”。请写一个函数完成此功能，要求对长度为n的字符串操作的时间复杂度为 O(n)，空间复杂度为 O(1)。 方法：三步反转法对于这个问题，换一个角度思考一下。 将一个字符串分成X和Y两个部分，在每部分字符串上定义反转操作，如X^T，即把X的所有字符反转（如，X=”abc”，那么X^T=”cba”），那么就得到下面的结论：(X^TY^T)^T=YX，显然就解决了字符串的反转问题。 例如，字符串 abcdef ，若要让def翻转到abc的前头，只要按照下述3个步骤操作即可： 首先将原字符串分为两个部分，即X:abc，Y:def； 将X反转，X-&gt;X^T，即得：abc-&gt;cba；将Y反转，Y-&gt;Y^T，即得：def-&gt;fed。 反转上述步骤得到的结果字符串X^TY^T，即反转字符串cbafed的两部分（cba和fed）给予反转，cbafed得到defabc，形式化表示为(X^TY^T)^T=YX，这就实现了整个反转。 代码则可以这么写： 12345678910111213141516171819#反转字符串def ReverseString(s,left,right): s = list(s) while(left &lt; right): s[left], s[right] = s[right], s[left] left += 1 right -= 1 s = ''.join(s) return sdef leftRotateString(s, n, m): m %= n #若要左移动大于n位，那么和%n 是等价的 s = ReverseString(s,0,m-1) s = ReverseString(s,m,n-1) s = ReverseString(s,0,n-1) print(s)s = "123456"leftRotateString(s,len(s),4)#运行结果： 561234 1.2 字符串匹配​ 连续子串在主串中匹配位置,返回第一个匹配的index：如 ​ main_string: ‘thequickbrownfoxjumpsoverthelazydog’ ​ pattern_string: ‘jump’ ​ result: 16 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748def simple_hash(s, start, end): """ 计算子串的哈希值 每个字符取acs-ii码后求和 :param s: :param start: :param end: :return: """ assert start &lt;= end ret = 0 for c in s[start: end+1]: ret += ord(c) return retdef rk(main, pattern): n = len(main) m = len(pattern) if n &lt;= m: return 0 if pattern == main else -1 # 子串哈希值表 hash_memo = [None] * (n-m+1) hash_memo[0] = simple_hash(main, 0, m-1) print(hash_memo[0])# for i in range(1, n-m+1): hash_memo[i] = hash_memo[i-1] - simple_hash(main, i-1, i-1) + simple_hash(main, i+m-1, i+m-1) print(hash_memo) # 模式串哈希值 hash_p = simple_hash(pattern, 0, m-1) print(hash_p) for i, h in enumerate(hash_memo): # 可能存在哈希冲突 if h == hash_p: if pattern == main[i:i+m]: return i else: continue return -1 print('--- search ---')m_str = 'thequickbrownfoxjumpsoverthelazydog'p_str = 'jump'print('[rk] result:', rk(m_str, p_str))#[rk] result: 16 1.3 各种字符串算法（easy）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187#1. 字符串循环移位包含def string_in(): s1 = 'CDAA' s2 = 'AABCD' #方法一 def string_in1(): res = False for idx, v in enumerate(s2): temp = s2[ idx: ] + s2[ :idx ] if s1 in temp: res = True print(res) return res # 方法二 def string_in2( ): ''' s2的翻转是s2s2的子串，因此，s1直接判断s2s2即可 :return: ''' res = False if s1 in s2+s2: res = True print(res) return res string_in1() string_in2()#2. 字符串循环移位def move_k_string(): ''' 将字符串向右循环移动 k 位。 将 abcd123 中的 abcd 和 123 单独翻转， 得到 dcba321，然后对整个字符串进行翻转，得到 123abcd。 :return: ''' k = 4 s = 'abcd123' temp = str(s[:k])[::-1] + str(s[k:])[::-1] print(temp[::-1])#3. 字符串中单词的翻转def transer_string(): #将每个单词翻转，然后将整个字符串翻转。 s = "I am a student" res1 = ' '.join([v[::-1] for v in s[:: -1].split()]) print(res1) s1 = s.split(" ") s2 = [v[::-1] for v in s1] res2 = ' '.join(s2)[::-1] print(res2)#4. 两个字符串包含的字符是否完全相同from collections import Counterdef is_different_string(): s = "anagram" t = "nagaram" def is_different_str1(): s1 = Counter(s) t1 = Counter(t) print(s1==t1) def is_different_str2(): resb = True res = [ 0 ] * 26 for v in s: res[ ord(v) - ord("a") ] += 1 for v in t: res[ ord(v) - ord("a") ] -= 1 for v in res: if v != 0: resb = False print(resb) is_different_str1() is_different_str2()#5. 计算一组字符集合可以组成的回文字符串的最大长度def longestPalindrome(): #能够构成回文字符串，偶数放两边，奇数的放中间,所以要最大长度，偶数全要，奇数最大即可 s = "abccccdd" s1 = Counter(s) print(s1) odd_number = [] even_number = [] for k,v in s1.items(): if v%2 == 0: even_number.append(v) else: odd_number.append(v) print(sum(even_number) + max(odd_number))#6. 字符串同构def isIsomorphic(): #记录一个字符上次出现的位置，如果两个字符串中的字符上次出现的位置一样，那么就属于同构。 t, s = "paper", "title" res = True ti, si = [0]*26, [0]*26 if len(t) != len(s): print(True) for i,v in enumerate(t): tn = ord(t[i])-ord('a') sn = ord(s[i])-ord('a') if ti[tn] != si[sn]: res = False ti[tn] += 1 si[sn] += 1 print(res)# 7. 回文子字符串个数def count_sub_string(): #遍历字符每一个字符，然后重这个字符一奇数和偶数去拓展字符，判断是否相同，如果相同就是回文子串+1 s = 'cbaac' cnt = 0 def is_count_sub(s, start, end): nonlocal cnt while((start &gt;= 0 and end &lt;= len(s)-1) and (s[start] == s[end])): start -= 1 end += 1 cnt += 1 for i,v in enumerate(s): is_count_sub(s,i,i) is_count_sub(s,i,i+1) print(cnt)# 8. 判断一个整数是否是回文数def isPalindrome(): ''' 要求不能使用额外空间，也就不能将整数转换为字符串进行判断。 将整数分成左右两部分，右边那部分需要转置，然后判断这两部分是否相等。 :return: ''' n = 121 def is_subStr(): nonlocal n if n &gt;= 0 and n &lt; 10: return True if n % 10 == 0: return False right = 0 while(n &gt; right): right = right * 10 + n % 10 n /= 10 return (n == right or n == right/10) res = is_subStr() print(res)# 9. 统计二进制字符串中连续 1 和连续 0 数量相同的子字符串个数def countBinarySubstrings(): # 从第二个字符开始，保留已经遍历的连续字符长度prel，在转折不同字符的时候， # 连续相同字符长度curl.即当前连续字符个数为min(curl,prel) s = "00110011" res,curl,prel = 0, 1, 0 for i in range(1,len(s)): if s[i] == s[i-1]: curl += 1 else: prel = curl curl = 1 if(prel &gt;= curl): res += 1 print(res)if __name__ == '__main__': # string_in() # move_k_string() # transer_string() # is_different_string() # longestPalindrome() # isIsomorphic() # count_sub_string() # isPalindrome() countBinarySubstrings()]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>algorithms</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chapter2_array_matrix_algorithm]]></title>
    <url>%2F2019%2F10%2F30%2Fchapter2-array-matrix-algorithm%2F</url>
    <content type="text"><![CDATA[chapter2_array_matrix_algorithm此章节过于leetcode类，全部是关于数组与矩阵方面的算法题，包括解题思路，以及Python代码 1234567891011# 1. 把数组中的 0 移到末尾def moveZeroes(): #遍历，数组，前面记住不为0的值，往依次迁移，遍历完数组，除记录不为0的数，直接填充为0 nums = [ 0, 1, 0, 3, 12 ] vn = 0 for i,v in enumerate(nums): if v != 0: nums[vn] = v vn += 1 nums[vn:] = [0]*(len(nums)-vn) print(nums) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309import numpy as np# 2. 改变矩阵维度def matrixReshape(r,c): #先判断，改变数组是否符合要求.创建需要改变的数组, # 通过数组之间行与列的关系，直接遍历数组进行填充。 nums =[ [ 1, 2 ],[ 3, 4 ] ] r1, c1 = len(nums), len(nums[0]) assert (r != r1 or c != c1) M_r2 = [[ 0 for j in range(c)] for i in range(r)] index = 0 for i in range(r1): for j in range(c1): r2, c2 = index // c, index % c M_r2[r2][c2] = nums[i][j] index += 1 print(M_r2) M_r1 = np.array(nums).reshape(r,c) print(M_r1)# 3. 找出数组中最长的连续 1def findMaxConsecutiveOnes(): #遍历数组，每次记录连续1的长度，到转折的时候，求最大即可 nums = [0,0,0,1,1,0,1,1,1] maxc,temp = 0,0 for i,v in enumerate(nums): if v == 1: temp += 1 else: maxc = max(temp,maxc) temp = 0 print(temp) return tempdef searchMatrix(): #由于行和列都是有顺序的，所以直接通过使用一次为规律去判断就行， # 时间复杂度为O(pow((m**2+n**2),1/2)) # matrix = [ # [ 1, 5, 9 ], # [ 10, 11, 13 ], # [ 12, 13, 15 ] # ] matrix =[[1,4,7,11,15],[2,5,8,12,19],[3,6,9,16,22],[10,13,14,17,24],[18,21,23,26,30]] target = 20 #起始值从(0,0)开始 def sm(): for m in matrix: if target in m: return True return False #起始值从(0,n)开始,从此开始会比从(0,0)开始快 def sm1(): if matrix == None or len(matrix) == 0 or len(matrix[0]) == 0: return False i, j, m, n = 0, len(matrix[0])-1, len(matrix), len(matrix[ 0 ])-1 while (i &lt; m and j &gt;= 0): if matrix[ i ][ j ] == target: return True if target &lt;= matrix[ i ][ j ] : j -= 1 else: i += 1 return False res = sm() print(res) res = sm1() print(res)# 5. 有序矩阵的 Kth Elementdef kthSmallest(): # 由于是有序数组，每一个矩阵块（当前矩阵的子矩阵）最后一列都是当前行最大值， # 利用二分查找的思想，通过到达中值的次数为指标，进行分离左右查找，当找到计数为k，即为第k个数 matrix = [[1,2],[1,3]] def ks(matrix,k): k -= 1 lv, rv, m, n = matrix[0][0], matrix[-1][-1], len(matrix), len(matrix[ 0 ]) while(lv &lt;= rv): mid, cnt = lv + (rv - lv)//2, 0 i, j = 0, n-1 while(i &lt; m and j &gt;= 0): if matrix[i][j] &lt;= mid: cnt += (j + 1) i += 1 else: j -= 1 if (k &lt; cnt): rv = mid - 1 else: lv = mid + 1 print(lv) return lv ks(matrix,3)# 6. 一个数组元素在 [1, n] 之间，其中一个数被替换为另一个数，找出重复的数和丢失的数def findErrorNums(): #由于是[1,n]的数，且只重复一次，所以直接通过数学公式就可以算出 nums = [2,3,2] r = sum(nums) - sum(set(nums)) r1 = sum(range(1, len(nums) + 1)) - sum(set(nums)) print([r,r1])# 7. 找出数组中重复的数，数组值在 [1, n] 之间def findDuplicate(): # 由于是[1, n] 之间，所以值v&lt;len(nums),因此，利用二分查找，遍历数组，记录小于mid值的个数cnt， # 如果cnt &gt; mid 说明小于mid中的数值，是有重复的，反之大于等于mid的数是有重复的。 nums = [ 3, 1, 3, 4, 2 ] def fd1(): l, r = 1, len(nums) - 1 while (l &lt;= r): mid = l + (r - l) // 2 cnt = 0 for i in range(len(nums)): if nums[ i ] &lt;= mid: cnt += 1 if cnt &gt; mid: r = mid - 1 else: l = mid + 1 print(l) return l #因为只有一个值是重复的，所以直接可以算出来 def fd2(): return (sum(nums) - sum(set(nums))) // (len(nums) - len(set(nums))) #双指针解法，类似于有环链表中找出环的入口： def fd3(): if len(nums) &gt; 1: slow = nums[ 0 ] fast = nums[ nums[ 0 ] ] while slow != fast: slow = nums[ slow ] fast = nums[ nums[ fast ] ] print(slow, fast) entry = 0 while entry != slow: entry = nums[ entry ] slow = nums[ slow ] print(slow, entry) return entry fd1() fd2() fd3()# 数组相邻差值的个数def constructArray(): # 先弄k个间隔数据，再弄n-k的数组，由于间隔相差值问题，通过观察，数值奇偶部分， # 相差数值是低高规律分布，因此流程如下： n = 10; k = 5 data = [1 for i in range(n)] intervel = k for i in range(1,k+1): print(i) if i % 2 == 1: data[i] = data[i-1] + intervel else: data[i] = data[i-1] - intervel intervel -= 1 print(data) if k + 1 &lt;= n: for i in range(k+1,n): data[i] = i+1 print(data) return data# 9. 数组的度def findShortestSubArray(): #使用map数据结果 ，记录数据的第一个index和最后一个index 然后求出最大频率的值，输出长度即可 #方法1 nums = [ 1, 1 ] def fssa1(): from collections import Counter v = Counter(nums) maxv = Counter(nums).most_common(1)[ 0 ][ 1 ] print(maxv) k = [ k for k, v in v.items() if v == maxv ] print(k) res = 1e100 for c in k: x, y = 0, 0 cc = maxv for i, v in enumerate(nums): if v == c and cc &gt;= 1: cc -= 1 if v == c and cc == maxv - 1: x = i if v == c and cc == 0: y = i res = min(res, y - x + 1) print(res) return res #方法2 def fssa2(): left, right, count = &#123;&#125;, &#123;&#125;, &#123;&#125; for i, x in enumerate(nums): if x not in left: left[ x ] = i right[ x ] = i count[ x ] = count.get(x, 0) + 1 ans = len(nums) degree = max(count.values()) for x in count: if count[ x ] == degree: ans = min(ans, right[ x ] - left[ x ] + 1) return ans fssa1() fssa2()# 10. 对角元素相等的矩阵def isToeplitzMatrix(): # 遍历行row和列col，通过分别+1,到达下个数，判断是否相等。如果相等，继续判断， # 如果不相等，就返回False结束，遍历完返回True matrix = [ [ 1, 2, 3, 4 ], [ 5, 1, 2, 3 ], [ 9, 2, 1, 2 ] ] def itm(): m, n = len(matrix), len(matrix[ 0 ]) def check(mv, matrix, i, j, m, n ): if (i &gt;= m or j &gt;= n): return True if (mv != matrix[ i ][j]): return False b = check(mv, matrix, i + 1, j + 1, m, n) return b for i in range(m): if not check(matrix[i][0],matrix, i, 0, m, n): return False for i in range(n): if not check(matrix[ 0 ][ i ], matrix, 0, i, m, n): return False return True print(itm())# 12. 分隔数组def arrayNesting(): # 题目描述：S[i] 表示一个集合，集合的第一个元素是 A[i]，第二个元素是 A[A[i]]，如此嵌套下去。求最大的 S[i]。 # 此题就如同一个链表，只是有v-index-v-index：值-索引之间转化进行连接。我们做的就是找到出现相同索引的时候就停止， # 这时就是一个区间，就如果链表中的一个环。而要找到一个最大的最环，在不同的起点，会出现不同的环。 # 要做的是，遍历过的环，就不在遍历，并且记录遍历过环的最大长度即可 nums = [0,2,1] maxv = 0 for i, a in enumerate(nums): cnt = 0 j = i while(nums[j] != -1): cnt += 1 t = nums[j] nums[j] = -1 j = t l = set(nums) if l == &#123;-1&#125; and l.__sizeof__() == 1 : break print(l) maxv = max(maxv,cnt) print(maxv) return maxv# 11. 嵌套数组def maxChunksToSorted(): # 题目描述：分隔数组，使得对每部分排序后数组就为有序。 # 解题思路，我们通过观察，从左一直遍历到右，已当前值为后面最小值为划分区间就能够划分， # 比如index=0开始，index=1 v=0是后面[2:]区间的组最小值，即划分一个区间， # 类比 2,3,4分别是后面的最小值，所以划分的区间是4。 # 因此，可以整理思路，如果前面区间的最大值等于index，就可以划分区间。原因。数据是属于[1,...,n]的 arr =[1,0,2,3,4] maxv,res_c = 0, 0 for i, v in enumerate(arr): maxv = max(maxv,v) if maxv == i: res_c += 1 print(res_c) return res_cif __name__ == '__main__': # moveZeroes() # matrixReshape(1,4) # findMaxConsecutiveOnes() # searchMatrix() # kthSmallest() # findErrorNums() # findDuplicate() # constructArray() # findShortestSubArray() # arrayNesting() # maxChunksToSorted() isToeplitzMatrix()]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>algorithms</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python algorithms string]]></title>
    <url>%2F2019%2F10%2F30%2Fpython-algorithms-string%2F</url>
    <content type="text"><![CDATA[1.1 旋转字符串题目描述给定一个字符串，要求把字符串前面的若干个字符移动到字符串的尾部，如把字符串“abcdef”前面的2个字符’a’和’b’移动到字符串的尾部，使得原字符串变成字符串“cdefab”。请写一个函数完成此功能，要求对长度为n的字符串操作的时间复杂度为 O(n)，空间复杂度为 O(1)。 方法：三步反转法对于这个问题，换一个角度思考一下。 将一个字符串分成X和Y两个部分，在每部分字符串上定义反转操作，如X^T，即把X的所有字符反转（如，X=”abc”，那么X^T=”cba”），那么就得到下面的结论：(X^TY^T)^T=YX，显然就解决了字符串的反转问题。 例如，字符串 abcdef ，若要让def翻转到abc的前头，只要按照下述3个步骤操作即可： 首先将原字符串分为两个部分，即X:abc，Y:def； 将X反转，X-&gt;X^T，即得：abc-&gt;cba；将Y反转，Y-&gt;Y^T，即得：def-&gt;fed。 反转上述步骤得到的结果字符串X^TY^T，即反转字符串cbafed的两部分（cba和fed）给予反转，cbafed得到defabc，形式化表示为(X^TY^T)^T=YX，这就实现了整个反转。 代码则可以这么写： 12345678910111213141516171819#反转字符串def ReverseString(s,left,right): s = list(s) while(left &lt; right): s[left], s[right] = s[right], s[left] left += 1 right -= 1 s = ''.join(s) return sdef leftRotateString(s, n, m): m %= n #若要左移动大于n位，那么和%n 是等价的 s = ReverseString(s,0,m-1) s = ReverseString(s,m,n-1) s = ReverseString(s,0,n-1) print(s)s = "123456"leftRotateString(s,len(s),4)#运行结果： 561234 1.2 字符串匹配​ 连续子串在主串中匹配位置,返回第一个匹配的index：如 ​ main_string: ‘thequickbrownfoxjumpsoverthelazydog’ ​ pattern_string: ‘jump’ ​ result: 16 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748def simple_hash(s, start, end): """ 计算子串的哈希值 每个字符取acs-ii码后求和 :param s: :param start: :param end: :return: """ assert start &lt;= end ret = 0 for c in s[start: end+1]: ret += ord(c) return retdef rk(main, pattern): n = len(main) m = len(pattern) if n &lt;= m: return 0 if pattern == main else -1 # 子串哈希值表 hash_memo = [None] * (n-m+1) hash_memo[0] = simple_hash(main, 0, m-1) print(hash_memo[0])# for i in range(1, n-m+1): hash_memo[i] = hash_memo[i-1] - simple_hash(main, i-1, i-1) + simple_hash(main, i+m-1, i+m-1) print(hash_memo) # 模式串哈希值 hash_p = simple_hash(pattern, 0, m-1) print(hash_p) for i, h in enumerate(hash_memo): # 可能存在哈希冲突 if h == hash_p: if pattern == main[i:i+m]: return i else: continue return -1 print('--- search ---')m_str = 'thequickbrownfoxjumpsoverthelazydog'p_str = 'jump'print('[rk] result:', rk(m_str, p_str))#[rk] result: 16 1.3 各种字符串算法（easy）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187#1. 字符串循环移位包含def string_in(): s1 = 'CDAA' s2 = 'AABCD' #方法一 def string_in1(): res = False for idx, v in enumerate(s2): temp = s2[ idx: ] + s2[ :idx ] if s1 in temp: res = True print(res) return res # 方法二 def string_in2( ): ''' s2的翻转是s2s2的子串，因此，s1直接判断s2s2即可 :return: ''' res = False if s1 in s2+s2: res = True print(res) return res string_in1() string_in2()#2. 字符串循环移位def move_k_string(): ''' 将字符串向右循环移动 k 位。 将 abcd123 中的 abcd 和 123 单独翻转， 得到 dcba321，然后对整个字符串进行翻转，得到 123abcd。 :return: ''' k = 4 s = 'abcd123' temp = str(s[:k])[::-1] + str(s[k:])[::-1] print(temp[::-1])#3. 字符串中单词的翻转def transer_string(): #将每个单词翻转，然后将整个字符串翻转。 s = "I am a student" res1 = ' '.join([v[::-1] for v in s[:: -1].split()]) print(res1) s1 = s.split(" ") s2 = [v[::-1] for v in s1] res2 = ' '.join(s2)[::-1] print(res2)#4. 两个字符串包含的字符是否完全相同from collections import Counterdef is_different_string(): s = "anagram" t = "nagaram" def is_different_str1(): s1 = Counter(s) t1 = Counter(t) print(s1==t1) def is_different_str2(): resb = True res = [ 0 ] * 26 for v in s: res[ ord(v) - ord("a") ] += 1 for v in t: res[ ord(v) - ord("a") ] -= 1 for v in res: if v != 0: resb = False print(resb) is_different_str1() is_different_str2()#5. 计算一组字符集合可以组成的回文字符串的最大长度def longestPalindrome(): #能够构成回文字符串，偶数放两边，奇数的放中间,所以要最大长度，偶数全要，奇数最大即可 s = "abccccdd" s1 = Counter(s) print(s1) odd_number = [] even_number = [] for k,v in s1.items(): if v%2 == 0: even_number.append(v) else: odd_number.append(v) print(sum(even_number) + max(odd_number))#6. 字符串同构def isIsomorphic(): #记录一个字符上次出现的位置，如果两个字符串中的字符上次出现的位置一样，那么就属于同构。 t, s = "paper", "title" res = True ti, si = [0]*26, [0]*26 if len(t) != len(s): print(True) for i,v in enumerate(t): tn = ord(t[i])-ord('a') sn = ord(s[i])-ord('a') if ti[tn] != si[sn]: res = False ti[tn] += 1 si[sn] += 1 print(res)# 7. 回文子字符串个数def count_sub_string(): #遍历字符每一个字符，然后重这个字符一奇数和偶数去拓展字符，判断是否相同，如果相同就是回文子串+1 s = 'cbaac' cnt = 0 def is_count_sub(s, start, end): nonlocal cnt while((start &gt;= 0 and end &lt;= len(s)-1) and (s[start] == s[end])): start -= 1 end += 1 cnt += 1 for i,v in enumerate(s): is_count_sub(s,i,i) is_count_sub(s,i,i+1) print(cnt)# 8. 判断一个整数是否是回文数def isPalindrome(): ''' 要求不能使用额外空间，也就不能将整数转换为字符串进行判断。 将整数分成左右两部分，右边那部分需要转置，然后判断这两部分是否相等。 :return: ''' n = 121 def is_subStr(): nonlocal n if n &gt;= 0 and n &lt; 10: return True if n % 10 == 0: return False right = 0 while(n &gt; right): right = right * 10 + n % 10 n /= 10 return (n == right or n == right/10) res = is_subStr() print(res)# 9. 统计二进制字符串中连续 1 和连续 0 数量相同的子字符串个数def countBinarySubstrings(): # 从第二个字符开始，保留已经遍历的连续字符长度prel，在转折不同字符的时候， # 连续相同字符长度curl.即当前连续字符个数为min(curl,prel) s = "00110011" res,curl,prel = 0, 1, 0 for i in range(1,len(s)): if s[i] == s[i-1]: curl += 1 else: prel = curl curl = 1 if(prel &gt;= curl): res += 1 print(res)if __name__ == '__main__': # string_in() # move_k_string() # transer_string() # is_different_string() # longestPalindrome() # isIsomorphic() # count_sub_string() # isPalindrome() countBinarySubstrings()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[window10 快捷键]]></title>
    <url>%2F2019%2F10%2F30%2Fwindow10-%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[1.常用window10 快捷键菜单 Win+D：显示桌面 Win+E：打开资源管理器 Win+I：打开设置界面 Win+L：锁定屏幕 Win+R：打开运行窗口 Win+P：打开投影选择界面 Win+Q/S：打开Cortana搜索框 Win+W：打开Windows INK工作区 Ctrl+Alt+Del：打开资源管理器 Win+A： 打开操作中心 Win + V：打开云剪贴板 Ctrl+Shift+F：简体繁体文字 Ctrl+W: 关闭chrome当前网页 Ctrl+Shift+T： 恢复chrome网页 win+P键: 打开投影 Win+ T: 在任务栏上循环切换应用** Win + Shift + M: 将最小化的窗口还原到桌面 Alt + D: 选择地址栏 Ctrl + E: 选择搜索框 Ctrl + F: 选择搜索框 Ctrl + N: 打开新窗口 Ctrl + W: 关闭活动窗口 Ctrl + 鼠标滚轮: 更改文件和文件夹图标的大小及外观 Ctrl + Shift + E: 显示选定文件夹上的所有文件夹 Ctrl + Shift + N: 创建一个新文件夹 Num Lock + 星号 (*): 显示选定文件夹下的所有子文件夹 Num Lock + 加号 (+): 显示选定文件夹的内容 Num Lock + 减号 (-): 折叠选定文件夹 Alt + P: 显示预览面板 Alt + Enter: 打开选定项的“属性”对话框 Alt + 向右键: 查看下一个文件夹 Alt + 向上键: 查看上一级文件夹 Alt + 向左键: 查看上一个文件夹 Backspace: 查看上一个文件夹 2. window10 巧技​ 1.虚拟桌面 ​ win10中加入了对虚拟桌面的支持。虚拟桌面简单得说：就是保留现有桌面全部设置的情况下。打开 一个全新的空白桌面供用户使用。适合在做现有工作的间中临时插入一套新工作进行。 ​ ​ 下边是一组关于虚拟桌面的快捷键，关于虚拟桌面的详细内容有机会我会另外出文介绍： ​ Win + Ctrl + D 创建虚拟桌面 ​ Win + Ctrl + F4 关闭当前虚拟桌面 ​ Win + Ctrl + ← 向左切换虚拟桌面 ​ Win + Ctrl + → 向右切换虚拟桌面 ​ ​ 2. 召唤Windows截图（Win + Shift + S） ​ 在win10之前笔者一直使用QQ截图。就为了这个，每次开电脑的还需要去登陆QQ。换到win10之后，发 现它自带的截图功能非常好用，快捷键 Win + Shift + S呼出，可以选择截屏幕的任意区域，任意形状，以及全 面屏幕截图。截图之后可以马上进入编辑模式。 ​ 3. Windows的夜间模式 手机中的夜间模式非常好用，苹果iOS13也特别增加了夜间模式。什么是夜间模式，也就是大部分系统中的白色空旷显示区域都会变成暗色，比如黑色或者黑灰色，这样在夜晚使用电子产品的时候，光线就不会刺眼。 普通模式 夜间模式 其实Windows系统也有夜间模式，只是大家不知道在哪里打开而已。其实很简单，打开设置菜单，然后选择个性化，然后选择颜色，往下拉菜单，找到选择默认应用模式，将其选项选为暗，马上就可以看到效果了。白色的显示窗口马上就变成了黑色，这样夜间观看就不会觉得刺眼了，也起到了护眼的作用，笔者认为比护眼灯更值得。 4.*平级显示控制面板内容*** 每次打开控制面板，是不是被一级一级的菜单选项搞晕了，找一个内容有的时候需要翻遍很多个选项菜单归类才能够找到。如果能全部显示出来，然后平级查找，是不是就更方便一些呢，实际上，这个可以实现。 注：红框内就是新的图标 这个操作其实特别简单，在桌面上新建一个文件夹，将文件夹重命名，把“ Control Panel。{ED7BA470-8E54-465E-825C-99712043E01C} ”这段代码粘为新的文件夹命名，然后就可以看到这个文件夹在桌面的图标变了。点击新的桌面图标，就可以打开看到平级显示的控制面板的各个菜单选项了，查找起来很方便。 反转色和色盲的福音 在Windows系统中，还有一个颜色滤镜功能，这个功能可以通过打开设置里面的轻松使用，然后选择颜色滤镜即可。进入之后可以打开快捷键Win+Ctrl+C，因为快捷键默认是关闭的。 反转颜色后的效果 关闭颜色滤镜，我们看到Windows系统的色彩就是正常的，我们也可以选择反转、灰度、反转灰度这些选项，达到不同色彩的显示效果，对于很多不同行业的人来说，这个功能其实是有用的。 蓝-黄选项效果 另外，对于色盲人士还有个单独的选项，选项分为三个，其中两个是红-绿，分别针对红色色弱和色盲、绿色色弱和色盲人士；另一个选项是蓝-黄，针对蓝色盲人士。这个设计非常贴心了，而且很友好。 ​ 6. 固定文件夹到快速访问 我们打开我的电脑或者文件资源管理器的时候，左侧总会显示一大长串的各种盘符和文件夹快捷方式，实际上我们日常并不是常用这些文件夹，可能总会使用的也就是其中几个而已。 固定到快速访问 这种情况下，我们可以将文件夹固定到最顶部的快速访问中，这样下次打开我的电脑或者文件资源管理器就能够快速找到入口。操作方式就更简单了，在文件夹上点击右键，出现一个菜单，在菜单中找到固定到快速访问这个选项，点击左键即可完成。这样，你需要的文件夹就固定到快速访问上了。 7. 图片批量更改编号 我们有的时候会为文件、图片、文件夹编号，如果只有几个，那么我们直接在要更改的名称区域内慢速双击即可选中，然后打字重新编号。如果是要同时更改几十个甚至几百个文件呢，我们总不能一个一个更改吧。所以我们可以使用批量更改编号。 ​ 图片批量更改编号 这个方法特别简单，选中要更改的图片或者其他文件，然后还是在名称区域慢速双击一个图片，输入新的名称，然后系统就会自动给你选中的所有图片或者文件进行重命名。这个命名是“你输入的新名称+（数字）”的形式。你如你更改的一个文件是“ZOL”，那么其他文件就依次为“ZOL（1）”、“ZOL（2）”、“ZOL（3）”，以此类推。是不是很方便。 09 放大缩小图标 Ctrl键+鼠标滚轮可以直接缩放大小 Windows系统中，显示的图标或者称之为预览是有大有小的，比如列表、中图标、大图标，超大图标等等。那么怎么能够快速的调节，而不需要点右键这么繁琐的方法呢。答案很简单，即使按住Ctrl键，然后滚动鼠标滚轮。往上滚动是放大图片，往下滚动是缩小图片，操作是不是很简答。 8. 抖动实现最小化其他窗口 除了显示桌面的快捷键之外，从Windows 7系统开始，就增加了一个很有娱乐性的最小化窗口的操作。就是随便选择一个窗口或者程序的上栏，也就是顶部，按下鼠标左键之后开始抖动，就会自动实现除了抖动的窗口或者程序之外，其余全部都会被最小化。 ​ 抖动之后只留下被抖动的这个窗口，其余都最小化了 我们在最小化的时候不是每次都希望所有窗口最小化，我们需要保留一个自己要用的窗口，这个操作正是满足这种需求。比如我们需要往一个窗口内拖拽桌面的文件或者图片，抖动之后其他窗口都最小化了，直接可以看到桌面上文件，方便我们进行拖拽操作。这个用途比较小众，但是确实有用。 9. 管理开机自启动的程序 以往，在Windows 7时代，我们想要设置开机自动启动的程序，除了程序内有选项之外，就需要在“系统配置（msconfig）”应用里面选择，非常繁琐，且用户找寻入口非常麻烦。 现在简单多了，在任务管理器中就有这个选项了，名字叫启动。在启动界面里，就有开机所启动的所有程序，你可以自己选择启动哪些、关闭哪些，达到提升开机速度的效果。 打开任务管理器的快捷键是Ctrl+Alt+Del，或者在任务栏点击右键，菜单中也有选项。]]></content>
      <categories>
        <category>巧技</category>
      </categories>
      <tags>
        <tag>win10快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[协程与异步I/O]]></title>
    <url>%2F2019%2F10%2F29%2F%E5%8D%8F%E7%A8%8B%E4%B8%8E%E5%BC%82%E6%AD%A5I-O%2F</url>
    <content type="text"><![CDATA[原链接 通常在Python中我们进行并发编程一般都是使用多线程或者多进程来实现的，对于CPU计算密集型任务由于GIL的存在通常使用多进程来实现，而对于IO密集型任务可以通过线程调度来让线程在执行IO任务时让出GIL，从而实现表面上的并发。 其实对于IO密集型任务我们还有一种选择就是协程。协程，又称微线程，英文名Coroutine，是运行在单线程中的“并发”，协程相比多线程的一大优势就是省去了多线程之间的切换开销，获得了更高的运行效率。Python中的异步IO模块asyncio就是基本的协程模块。 Python中的协程经历了很长的一段发展历程。最初的生成器yield和send()语法，然后在Python3.4中加入了asyncio模块，引入@asyncio.coroutine装饰器和yield from语法，在Python3.5上又提供了async/await语法，目前正式发布的Python3.6中asynico也由临时版改为了稳定版。 1. 协程：协程的切换不同于线程切换，是由程序自身控制的，没有切换的开销。协程不需要多线程的锁机制，因为都是在同一个线程中运行，所以没有同时访问数据的问题，执行效率比多线程高很多。 因为协程是单线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。 如果你还无法理解协程的概念，那么可以这么简单的理解： 进程/线程：操作系统提供的一种并发处理任务的能力。 协程：程序员通过高超的代码能力，在代码执行流程中人为的实现多任务并发，是单个线程内的任务调度技巧。 多进程和多线程体现的是操作系统的能力，而协程体现的是程序员的流程控制能力。看下面的例子，甲，乙两个工人模拟两个工作任务交替进行，在单线程内实现了类似多线程的功能。 1234567891011121314151617181920212223242526#!/usr/bin/env python# -*- coding:utf-8 -*-import timedef task1(): while True: yield "&lt;甲&gt;也累了，让&lt;乙&gt;工作一会儿" time.sleep(1) print("&lt;甲&gt;工作了一段时间.....")def task2(t): next(t) while True: print("-----------------------------------") print("&lt;乙&gt;工作了一段时间.....") time.sleep(2) print("&lt;乙&gt;累了，让&lt;甲&gt;工作一会儿....") ret = t.send(None) print(ret) t.close()if __name__ == '__main__': t = task1() task2(t) 运行结果： 12345678910111213141516&lt;乙&gt;工作了一段时间.....&lt;乙&gt;累了，让&lt;甲&gt;工作一会儿....&lt;甲&gt;工作了一段时间.....&lt;甲&gt;也累了，让&lt;乙&gt;工作一会儿-----------------------------------&lt;乙&gt;工作了一段时间.....&lt;乙&gt;累了，让&lt;甲&gt;工作一会儿....&lt;甲&gt;工作了一段时间.....&lt;甲&gt;也累了，让&lt;乙&gt;工作一会儿-----------------------------------&lt;乙&gt;工作了一段时间.....&lt;乙&gt;累了，让&lt;甲&gt;工作一会儿....&lt;甲&gt;工作了一段时间.....&lt;甲&gt;也累了，让&lt;乙&gt;工作一会儿-----------------------------------&lt;乙&gt;工作了一段时间..... 2. yield最早的时候，Python提供了yield关键字，用于制造生成器。也就是说，包含有yield的函数，都是一个生成器！ yield的语法规则是：在yield这里暂停函数的执行，并返回yield后面表达式的值（默认为None），直到被next()方法再次调用时，从上次暂停的yield代码处继续往下执行。当没有可以继续next()的时候，抛出异常，该异常可被for循环处理。 1234567891011121314151617181920212223&gt;&gt;&gt; def fib(n): a, b = 0, 1 i = 0 while i &lt; n: yield b a, b = b, a+b i += 1&gt;&gt;&gt; f = fib(5)&gt;&gt;&gt; next(f)1&gt;&gt;&gt; next(f)1&gt;&gt;&gt; next(f)2&gt;&gt;&gt; next(f)3&gt;&gt;&gt; next(f)5&gt;&gt;&gt; next(f)Traceback (most recent call last): File "&lt;pyshell#9&gt;", line 1, in &lt;module&gt; next(f)StopIteration 下面是通过for循环不断地使fib生成下一个数，实际上就是不断地调用next()方法。 123456789101112def fib(n): a, b = 0, 1 i = 0 while i &lt; n: yield b a, b = b, a+b i += 1if __name__ == '__main__': f = fib(10) for item in f: print(item) 3. send()最初的yield只能返回并暂停函数，并不能实现协程的功能。后来，Python为它定义了新的功能——接收外部发来的值，这样一个生成器就变成了协程。 每个生成器都可以执行send()方法，为生成器内部的yield语句发送数据。此时yield语句不再只是yield xxxx的形式，还可以是var = yield xxxx的赋值形式。它同时具备两个功能，一是暂停并返回函数，二是接收外部send()方法发送过来的值，重新激活函数，并将这个值赋值给var变量！ 12345678910def simple_coroutine(): print('-&gt; 启动协程') y = 10 x = yield y print('-&gt; 协程接收到了x的值:', x)my_coro = simple_coroutine()ret = next(my_coro)print(ret)my_coro.send(10) 协程可以处于下面四个状态中的一个。当前状态可以导入inspect模块，使用inspect.getgeneratorstate(…) 方法查看，该方法会返回下述字符串中的一个。 ‘GEN_CREATED’ 等待开始执行。 ‘GEN_RUNNING’ 协程正在执行。 ‘GEN_SUSPENDED’ 在yield表达式处暂停。 ‘GEN_CLOSED’ 执行结束。 因为send()方法的参数会成为暂停的yield表达式的值，所以，仅当协程处于暂停状态时才能调用 send()方法，例如my_coro.send(10)。不过，如果协程还没激活（状态是&#39;GEN_CREATED&#39;），就立即把None之外的值发给它，会出现TypeError。因此，始终要先调用next(my_coro)激活协程（也可以调用my_coro.send(None)），这一过程被称作预激活。 除了send()方法，其实还有throw()和close()方法： generator.throw(exc_type[, exc_value[, traceback]]) 使生成器在暂停的yield表达式处抛出指定的异常。如果生成器处理了抛出的异常，代码会向前执行到下一个yield表达式，而产出的值会成为调用generator.throw()方法得到的返回值。如果生成器没有处理抛出的异常，异常会向上冒泡，传到调用方的上下文中。 generator.close() 使生成器在暂停的yield表达式处抛出GeneratorExit异常。如果生成器没有处理这个异常，或者抛出了StopIteration异常（通常是指运行到结尾），调用方不会报错。如果收到GeneratorExit异常，生成器一定不能产出值，否则解释器会抛出RuntimeError异常。生成器抛出的其他异常会向上冒泡，传给调用方。 4. @asyncio.coroutine与yield from@asyncio.coroutine：asyncio模块中的装饰器，用于将一个生成器声明为协程。 yield from 其实就是等待另外一个协程的返回。 12345def func(): for i in range(10): yield iprint(list(func())) 可以写成： 1234def func(): yield from range(10)print(list(func())) 从Python3.4开始asyncio模块加入到了标准库，通过asyncio我们可以轻松实现协程来完成异步IO操作。asyncio是一个基于事件循环的异步IO模块,通过yield from，我们可以将协程asyncio.sleep()的控制权交给事件循环，然后挂起当前协程；之后，由事件循环决定何时唤醒asyncio.sleep,接着向后执行代码。 下面这段代码，我们创造了一个协程display_date(num, loop)，然后它使用关键字yield from来等待协程asyncio.sleep(2)()的返回结果。而在这等待的2s之间它会让出CPU的执行权，直到asyncio.sleep(2)返回结果。asyncio.sleep(2)模拟的其实就是一个耗时2秒的IO读写操作。 123456789101112131415import asyncioimport datetime@asyncio.coroutine # 声明一个协程def display_date(num, loop): end_time = loop.time() + 10.0 while True: print("Loop: &#123;&#125; Time: &#123;&#125;".format(num, datetime.datetime.now())) if (loop.time() + 1.0) &gt;= end_time: break yield from asyncio.sleep(2) # 阻塞直到协程sleep(2)返回结果loop = asyncio.get_event_loop() # 获取一个event_looptasks = [display_date(1, loop), display_date(2, loop)]loop.run_until_complete(asyncio.gather(*tasks)) # "阻塞"直到所有的tasks完成loop.close() 运行结果： 123456789101112Loop: 2 Time: 2017-10-17 21:19:45.438511Loop: 1 Time: 2017-10-17 21:19:45.438511Loop: 2 Time: 2017-10-17 21:19:47.438626Loop: 1 Time: 2017-10-17 21:19:47.438626Loop: 2 Time: 2017-10-17 21:19:49.438740Loop: 1 Time: 2017-10-17 21:19:49.438740Loop: 2 Time: 2017-10-17 21:19:51.438855Loop: 1 Time: 2017-10-17 21:19:51.438855Loop: 2 Time: 2017-10-17 21:19:53.438969Loop: 1 Time: 2017-10-17 21:19:53.438969Loop: 2 Time: 2017-10-17 21:19:55.439083Loop: 1 Time: 2017-10-17 21:19:55.439083 5. async和awaitPython3.5中对协程提供了更直接的支持，引入了async/await关键字。上面的代码可以这样改写：使用async代替@asyncio.coroutine，使用await代替yield from，代码变得更加简洁可读。从Python设计的角度来说，async/await让协程独立于生成器而存在，不再使用yield语法。 123456789101112131415import asyncioimport datetimeasync def display_date(num, loop): # 注意这一行的写法 end_time = loop.time() + 10.0 while True: print("Loop: &#123;&#125; Time: &#123;&#125;".format(num, datetime.datetime.now())) if (loop.time() + 1.0) &gt;= end_time: break await asyncio.sleep(2) # 阻塞直到协程sleep(2)返回结果loop = asyncio.get_event_loop() # 获取一个event_looptasks = [display_date(1, loop), display_date(2, loop)]loop.run_until_complete(asyncio.gather(*tasks)) # "阻塞"直到所有的tasks完成loop.close() 6. asyncio模块asyncio的使用可分三步走： 创建事件循环 指定循环模式并运行 关闭循环 通常我们使用asyncio.get_event_loop()方法创建一个循环。 运行循环有两种方法：一是调用run_until_complete()方法，二是调用run_forever()方法。run_until_complete()内置add_done_callback回调函数，run_forever()则可以自定义add_done_callback()，具体差异请看下面两个例子。 使用run_until_complete()方法： 123456789101112131415import asyncioasync def func(future): await asyncio.sleep(1) future.set_result('Future is done!')if __name__ == '__main__': loop = asyncio.get_event_loop() future = asyncio.Future() asyncio.ensure_future(func(future)) print(loop.is_running()) # 查看当前状态时循环是否已经启动 loop.run_until_complete(future) print(future.result()) loop.close() 使用run_forever()方法： 12345678910111213141516171819import asyncioasync def func(future): await asyncio.sleep(1) future.set_result('Future is done!')def call_result(future): print(future.result()) loop.stop()if __name__ == '__main__': loop = asyncio.get_event_loop() future = asyncio.Future() asyncio.ensure_future(func(future)) future.add_done_callback(call_result) # 注意这行 try: loop.run_forever() finally: loop.close()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>thread</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python thread 基础概念与方法]]></title>
    <url>%2F2019%2F10%2F29%2Fpython-thread-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[原链接 在Python3中，通过threading模块提供线程的功能。原来的thread模块已废弃。但是threading模块中有个Thread类（大写的T，类名），是模块中最主要的线程类，一定要分清楚了，千万不要搞混了。 threading模块提供了一些比较实用的方法或者属性，例如： 方法与属性 描述 current_thread() 返回当前线程 active_count() 返回当前活跃的线程数，1个主线程+n个子线程 get_ident() 返回当前线程 enumerater() 返回当前活动 Thread 对象列表 main_thread() 返回主 Thread 对象 settrace(func) 为所有线程设置一个 trace 函数 setprofile(func) 为所有线程设置一个 profile 函数 stack_size([size]) 返回新创建线程栈大小；或为后续创建的线程设定栈大小为 size TIMEOUT_MAX Lock.acquire(), RLock.acquire(), Condition.wait() 允许的最大超时时间 threading模块包含下面的类： Thread：基本线程类 Lock：互斥锁 RLock：可重入锁，使单一进程再次获得已持有的锁(递归锁) Condition：条件锁，使得一个线程等待另一个线程满足特定条件，比如改变状态或某个值。 Semaphore：信号锁。为线程间共享的有限资源提供一个”计数器”，如果没有可用资源则会被阻塞。 Event：事件锁，任意数量的线程等待某个事件的发生，在该事件发生后所有线程被激活 Timer：一种计时器 Barrier：Python3.2新增的“阻碍”类，必须达到指定数量的线程后才可以继续执行。 1. 多线程有两种方式来创建线程：一种是继承Thread类，并重写它的run()方法；另一种是在实例化threading.Thread对象的时候，将线程要执行的任务函数作为参数传入线程。 第一种方法： 12345678910111213import threadingclass MyThread(threading.Thread): def __init__(self, thread_name): # 注意：一定要显式的调用父类的初始化函数。 super(MyThread, self).__init__(name=thread_name) def run(self): print("%s正在运行中......" % self.name)if __name__ == '__main__': for i in range(10): MyThread("thread-" + str(i)).start() 第二种方法： 1234567891011import threadingimport timedef show(arg): time.sleep(1) print('thread '+str(arg)+" running....")if __name__ == '__main__': for i in range(10): t = threading.Thread(target=show, args=(i,)) t.start() 对于Thread类，它的定义如下： 12threading.Thread(self, group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None) 参数group是预留的，用于将来扩展； 参数target是一个可调用对象，在线程启动后执行； 参数name是线程的名字。默认值为“Thread-N“，N是一个数字。 参数args和kwargs分别表示调用target时的参数列表和关键字参数。 Thread类定义了以下常用方法与属性： 方法与属性 说明 start() 启动线程，等待CPU调度 run() 线程被cpu调度后自动执行的方法 getName()、setName()和name 用于获取和设置线程的名称。 setDaemon() 设置为后台线程或前台线程（默认是False，前台线程）。如果是后台线程，主线程执行过程中，后台线程也在进行，主线程执行完毕后，后台线程不论成功与否，均停止。如果是前台线程，主线程执行过程中，前台线程也在进行，主线程执行完毕后，等待前台线程执行完成后，程序才停止。 ident 获取线程的标识符。线程标识符是一个非零整数，只有在调用了start()方法之后该属性才有效，否则它只返回None。 is_alive() 判断线程是否是激活的（alive）。从调用start()方法启动线程，到run()方法执行完毕或遇到未处理异常而中断这段时间内，线程是激活的。 isDaemon()方法和daemon属性 是否为守护线程 join([timeout]) 调用该方法将会使主调线程堵塞，直到被调用线程运行结束或超时。参数timeout是一个数值类型，表示超时时间，如果未提供该参数，那么主调线程将一直堵塞到被调线程结束。 在多线程执行过程中，有一个特点要注意，那就是每个线程各执行各的任务，不等待其它的线程，自顾自的完成自己的任务，比如下面的例子： 1234567891011121314import timeimport threadingdef doWaiting(): print('start waiting:', time.strftime('%H:%M:%S')) time.sleep(3) print('stop waiting', time.strftime('%H:%M:%S'))t = threading.Thread(target=doWaiting)t.start()# 确保线程t已经启动time.sleep(1)print('start job')print('end job') 执行结果是： 1234start waiting: 10:50:35start jobend jobstop waiting 10:50:38 Python默认会等待最后一个线程执行完毕后才退出。上面例子中，主线程没有等待子线程t执行完毕，而是啥都不管，继续往下执行它自己的代码，执行完毕后也没有结束整个程序，而是等待子线程t执行完毕，整个程序才结束。 有时候我们希望主线程等等子线程，不要“埋头往前跑”。那要怎么办？使用join()方法！如下所示： 12345678910111213141516import timeimport threadingdef doWaiting(): print('start waiting:', time.strftime('%H:%M:%S')) time.sleep(3) print('stop waiting', time.strftime('%H:%M:%S'))t = threading.Thread(target=doWaiting)t.start()# 确保线程t已经启动time.sleep(1)print('start join')# 将一直堵塞，直到t运行结束。t.join()print('end join') 执行结果： 1234start waiting: 10:54:03start joinstop waiting 10:54:06end join 我们还可以使用setDaemon(True)把所有的子线程都变成主线程的守护线程，当主线程结束后，守护子线程也会随之结束，整个程序也跟着退出。 12345678910111213141516import threadingimport timedef run(): print(threading.current_thread().getName(), "开始工作") time.sleep(2) # 子线程停2s print("子线程工作完毕")for i in range(3): t = threading.Thread(target=run,) t.setDaemon(True) # 把子线程设置为守护线程，必须在start()之前设置 t.start()time.sleep(1) # 主线程停1秒print("主线程结束了！")print(threading.active_count()) # 输出活跃的线程数 执行结果： 12345Thread-1 开始工作Thread-2 开始工作Thread-3 开始工作主线程结束了！4 2. 自定义线程类对于threading模块中的Thread类，本质上是执行了它的run方法。因此可以自定义线程类，让它继承Thread类，然后重写run方法。 1234567891011121314151617181920import threadingclass MyThreading(threading.Thread): def __init__(self, func, arg): super(MyThreading,self).__init__() self.func = func self.arg = arg def run(self): self.func(self.arg)def my_func(args): """ 你可以把任何你想让线程做的事定义在这里 """ passobj = MyThreading(my_func, 123)obj.start() 3.线程锁由于线程之间的任务执行是CPU进行随机调度的，并且每个线程可能只执行了n条指令之后就被切换到别的线程了。当多个线程同时操作一个对象，如果没有很好地保护该对象，会造成程序结果的不可预期，这被称为“线程不安全”。为了保证数据安全，我们设计了线程锁，即同一时刻只允许一个线程操作该数据。线程锁用于锁定资源，可以同时使用多个锁，当你需要独占某一资源时，任何一个锁都可以锁这个资源，就好比你用不同的锁都可以把相同的一个箱子锁住是一个道理。 我们先看一下没有锁的情况下，脏数据是如何产生的。 123456789101112131415161718import threadingimport timenumber = 0def plus(): global number # global声明此处的number是外面的全局变量number for _ in range(1000000): # 进行一个大数级别的循环加一运算 number += 1 print("子线程%s运算结束后，number = %s" % (threading.current_thread().getName(), number))for i in range(2): # 用2个子线程，就可以观察到脏数据 t = threading.Thread(target=plus) t.start()time.sleep(2) # 等待2秒，确保2个子线程都已经结束运算。print("主线程执行完毕后，number = ", number) 执行结果（每次数值可能都不一样）： 123子线程Thread-2运算结束后，number = 1144974子线程Thread-1运算结束后，number = 1181608主线程执行完毕后，number = 1181608 结果并不等于2,000,000，可以很明显地看出脏数据的情况。这是因为两个线程在运行过程中，CPU随机调度，你算一会我算一会，在没有对number进行保护的情况下，就发生了数据错误。如果想获得正确结果，可以使用join()方法，让多线程变成顺序执行，如下修改代码片段： 1234for i in range(2): t = threading.Thread(target=plus) t.start() t.join() # 添加这一行就让两个子线程变成了顺序执行 上面为了防止脏数据而使用join()的方法，其实是让多线程变成了单线程，属于因噎废食的做法，正确的做法是使用线程锁。Python在threading模块中定义了几种线程锁类，分别是： Lock 互斥锁 RLock 可重入锁 Semaphore 信号 Event 事件 Condition 条件 Barrier “阻碍” 3.1 互斥锁Lock互斥锁是一种独占锁，同一时刻只有一个线程可以访问共享的数据。使用很简单，初始化锁对象，然后将锁当做参数传递给任务函数，在任务中加锁，使用后释放锁。 1234567891011121314151617181920import threadingimport timenumber = 0lock = threading.Lock()def plus(lk): global number # global声明此处的number是外面的全局变量number lk.acquire() # 开始加锁 for _ in range(1000000): # 进行一个大数级别的循环加一运算 number += 1 print("子线程%s运算结束后，number = %s" % (threading.current_thread().getName(), number)) lk.release() # 释放锁，让别的线程也可以访问numberif __name__ == '__main__': for i in range(2): # 用2个子线程，就可以观察到脏数据 t = threading.Thread(target=plus, args=(lock,)) # 需要把锁当做参数传递给plus函数 t.start() time.sleep(2) # 等待2秒，确保2个子线程都已经结束运算。 print("主线程执行完毕后，number = ", number) RLock的使用方法和Lock一模一样，只不过它支持重入锁。该锁对象内部维护着一个Lock和一个counter对象。counter对象记录了acquire的次数，使得资源可以被多次require。最后，当所有RLock被release后，其他线程才能获取资源。在同一个线程中，RLock.acquire()可以被多次调用，利用该特性，可以解决部分死锁问题。 3.2 信号Semaphore类名：BoundedSemaphore。这种锁允许一定数量的线程同时更改数据，它不是互斥锁。比如地铁安检，排队人很多，工作人员只允许一定数量的人进入安检区，其它的人继续排队。 1234567891011121314import timeimport threadingdef run(n, se): se.acquire() print("run the thread: %s" % n) time.sleep(1) se.release()# 设置允许5个线程同时运行semaphore = threading.BoundedSemaphore(5)for i in range(20): t = threading.Thread(target=run, args=(i,semaphore)) t.start() 运行后，可以看到5个一批的线程被放行。 3.3 事件Event类名：Event 事件线程锁的运行机制：全局定义了一个Flag，如果Flag的值为False，那么当程序执行wait()方法时就会阻塞，如果Flag值为True，线程不再阻塞。这种锁，类似交通红绿灯（默认是红灯），它属于在红灯的时候一次性阻挡所有线程，在绿灯的时候，一次性放行所有排队中的线程。 事件主要提供了四个方法set()、wait()、clear()和is_set()。 调用clear()方法会将事件的Flag设置为False。 调用set()方法会将Flag设置为True。 调用wait()方法将等待“红绿灯”信号。 is_set():判断当前是否”绿灯放行”状态 下面是一个模拟红绿灯，然后汽车通行的例子： 123456789101112131415161718192021222324252627282930313233343536#利用Event类模拟红绿灯import threadingimport timeevent = threading.Event()def lighter(): green_time = 5 # 绿灯时间 red_time = 5 # 红灯时间 event.set() # 初始设为绿灯 while True: print("\33[32;0m 绿灯亮...\033[0m") time.sleep(green_time) event.clear() print("\33[31;0m 红灯亮...\033[0m") time.sleep(red_time) event.set()def run(name): while True: if event.is_set(): # 判断当前是否"放行"状态 print("一辆[%s] 呼啸开过..." % name) time.sleep(1) else: print("一辆[%s]开来，看到红灯，无奈的停下了..." % name) event.wait() print("[%s] 看到绿灯亮了，瞬间飞起....." % name)if __name__ == '__main__': light = threading.Thread(target=lighter,) light.start() for name in ['奔驰', '宝马', '奥迪']: car = threading.Thread(target=run, args=(name,)) car.start() 运行结果： 12345678910111213141516171819绿灯亮...一辆[奔驰] 呼啸开过...一辆[宝马] 呼啸开过...一辆[奥迪] 呼啸开过...一辆[奥迪] 呼啸开过......... 红灯亮...一辆[宝马]开来，看到红灯，无奈的停下了...一辆[奥迪]开来，看到红灯，无奈的停下了...一辆[奔驰]开来，看到红灯，无奈的停下了...绿灯亮...[奥迪] 看到绿灯亮了，瞬间飞起.....一辆[奥迪] 呼啸开过...[奔驰] 看到绿灯亮了，瞬间飞起.....一辆[奔驰] 呼啸开过...[宝马] 看到绿灯亮了，瞬间飞起.....一辆[宝马] 呼啸开过...一辆[奥迪] 呼啸开过......... 3.3 条件Condition类名：Condition Condition称作条件锁，依然是通过acquire()/release()加锁解锁。 wait([timeout])方法将使线程进入Condition的等待池等待通知，并释放锁。使用前线程必须已获得锁定，否则将抛出异常。 notify()方法将从等待池挑选一个线程并通知，收到通知的线程将自动调用acquire()尝试获得锁定（进入锁定池），其他线程仍然在等待池中。调用这个方法不会释放锁定。使用前线程必须已获得锁定，否则将抛出异常。 notifyAll()方法将通知等待池中所有的线程，这些线程都将进入锁定池尝试获得锁定。调用这个方法不会释放锁定。使用前线程必须已获得锁定，否则将抛出异常。 下面的例子，有助于你理解Condition的使用方法： 1234567891011121314151617181920212223242526272829303132333435363738import threadingimport timenum = 0con = threading.Condition()class Foo(threading.Thread): def __init__(self, name, action): super(Foo, self).__init__() self.name = name self.action = action def run(self): global num con.acquire() print("%s开始执行..." % self.name) while True: if self.action == "add": num += 1 elif self.action == 'reduce': num -= 1 else: exit(1) print("num当前为：", num) time.sleep(1) if num == 5 or num == 0: print("暂停执行%s！" % self.name) con.notify() con.wait() print("%s开始执行..." % self.name) con.release()if __name__ == '__main__': a = Foo("线程A", 'add') b = Foo("线程B", 'reduce') a.start() b.start() 如果不强制停止，程序会一直执行下去，并循环下面的结果： 12345678910111213141516171819202122线程A开始执行...num当前为： 1num当前为： 2num当前为： 3num当前为： 4num当前为： 5暂停执行线程A！线程B开始执行...num当前为： 4num当前为： 3num当前为： 2num当前为： 1num当前为： 0暂停执行线程B！线程A开始执行...num当前为： 1num当前为： 2num当前为： 3num当前为： 4num当前为： 5暂停执行线程A！线程B开始执行... 4. 定时器Timer定时器Timer类是threading模块中的一个小工具，用于指定n秒后执行某操作。一个简单但很实用的东西。 12345678from threading import Timerdef hello(): print("hello, world")# 表示1秒后执行hello函数t = Timer(1, hello)t.start() 5. 通过with语句使用线程锁所有的线程锁都有一个加锁和释放锁的动作，非常类似文件的打开和关闭。在加锁后，如果线程执行过程中出现异常或者错误，没有正常的释放锁，那么其他的线程会造到致命性的影响。通过with上下文管理器，可以确保锁被正常释放。其格式如下： 12with some_lock: # 执行任务... 这相当于： 12345some_lock.acquire()try: # 执行任务..finally: some_lock.release() 6. 全局解释器锁（GIL）既然介绍了多线程和线程锁，那就不得不提及Python的GIL问题。 在大多数环境中，单核CPU情况下，本质上某一时刻只能有一个线程被执行，多核CPU时则 可以支持多个线程同时执行。但是在Python中，无论CPU有多少核，同时只能执行一个线程。这是由于GIL的存在导致的。 GIL的全称是Global Interpreter Lock(全局解释器锁)，是Python设计之初为了数据安全所做的决定。Python中的某个线程想要执行，必须先拿到GIL。可以把GIL看作是执行任务的“通行证”，并且在一个Python进程中，GIL只有一个。拿不到通行证的线程，就不允许进入CPU执行。GIL只在CPython解释器中才有，因为CPython调用的是c语言的原生线程，不能直接操作cpu，只能利用GIL保证同一时间只能有一个线程拿到数据。在PyPy和JPython中没有GIL。 Python多线程的工作流程： 拿到公共数据 申请GIL Python解释器调用操作系统原生线程 cpu执行运算 当该线程执行一段时间消耗完，无论任务是否已经执行完毕，都会释放GIL 下一个被CPU调度的线程重复上面的过程 Python针对不同类型的任务，多线程执行效率是不同的： 对于CPU密集型任务(各种循环处理、计算等等)，由于计算工作多，ticks计数很快就会达到阈值，然后触发GIL的释放与再竞争（多个线程来回切换是需要消耗资源的），所以Python下的多线程对CPU密集型任务并不友好。 IO密集型任务(文件处理、网络通信等涉及数据读写的操作)，多线程能够有效提升效率(单线程下有IO操作会进行IO等待，造成不必要的时间浪费，而开启多线程能在线程A等待时，自动切换到线程B，可以不浪费CPU的资源，从而能提升程序执行效率)。所以Python的多线程对IO密集型任务比较友好。 为什么不能去掉GIL？ 首先，在早期的Python解释器依赖较多的全局状态，传承下来，使得想要移除当今的GIL变得更加困难。其次，对于程序员而言，仅仅是理解GIL的实现就需要对操作系统设计、多线程编程、C语言、解释器设计和CPython解释器的实现有着非常彻底的理解，更不用说对它进行修改删除了。总之，整体技术难度大，会对当前内部框架产生根本性的影响，牵一发而动全身。 在1999年，针对Python1.5，一个叫做“freethreading”的补丁已经尝试移除GIL，用细粒度的锁来代替。然而，GIL的移除给单线程程序的执行速度带来了一定的负面影响。当用单线程执行时，速度大约降低了40%。虽然使用两个线程时在速度上得到了提高，但这个提高并没有随着核数的增加而线性增长。因此这个补丁没有被采纳。 虽然，在Python的不同解释器实现中，如PyPy就移除了GIL，其执行速度更快（不单单是去除GIL的原因）。但是，我们通常使用的CPython解释器版本占有着统治地位的使用量，所以，你懂的。 在实际使用中的建议： Python中想要充分利用多核CPU，就用多进程。因为每个进程有各自独立的GIL，互不干扰，这样就可以真正意义上的并行执行。在Python中，多进程的执行效率优于多线程(仅仅针对多核CPU而言)。同时建议在IO密集型任务中使用多线程，在计算密集型任务中使用多进程。另外，深入研究Python的协程机制，你会有惊喜的。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>-- thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python thread tutorial]]></title>
    <url>%2F2019%2F10%2F29%2Fpython-thread-tutorial%2F</url>
    <content type="text"><![CDATA[python thread tutorial参考链接 1. python 线程与进程的区别进程是程序（软件，应用）的一个执行实例，每个运行中的程序，可以同时创建多个进程，但至少要有一个。每个进程都提供执行程序所需的所有资源，都有一个虚拟的地址空间、可执行的代码、操作系统的接口、安全的上下文（记录启动该进程的用户和权限等等）、唯一的进程ID、环境变量、优先级类、最小和最大的工作空间（内存空间）。进程可以包含线程，并且每个进程必须有至少一个线程。每个进程启动时都会最先产生一个线程，即主线程，然后主线程会再创建其他的子线程。 线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。另外，线程是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不独立拥有系统资源，但它可与同属一个进程的其它线程共享该进程所拥有的全部资源。每一个应用程序都至少有一个进程和一个线程。在单个程序中同时运行多个线程完成不同的被划分成一块一块的工作，称为多线程。 举个例子，某公司要生产一种产品，于是在生产基地建设了很多厂房，每个厂房内又有多条流水生产线。所有厂房配合将整个产品生产出来，单个厂房内的流水线负责生产所属厂房的产品部件，每个厂房都拥有自己的材料库，厂房内的生产线共享这些材料。公司要实现生产必须拥有至少一个厂房一条生产线。换成计算机的概念，那么这家公司就是应用程序，厂房就是应用程序的进程，生产线就是某个进程的一个线程。 线程的特点： 线程是一个execution context（执行上下文），即一个cpu执行时所需要的一串指令。假设你正在读一本书，没有读完，你想休息一下，但是你想在回来时继续先前的进度。有一个方法就是记下页数、行数与字数这三个数值，这些数值就是execution context。如果你的室友在你休息的时候，使用相同的方法读这本书。你和她只需要这三个数字记下来就可以在交替的时间共同阅读这本书了。 线程的工作方式与此类似。CPU会给你一个在同一时间能够做多个运算的幻觉，实际上它在每个运算上只花了极少的时间，本质上CPU同一时刻只能干一件事，所谓的多线程和并发处理只是假象。CPU能这样做是因为它有每个任务的execution context，就像你能够和你朋友共享同一本书一样。 进程与线程区别： 同一个进程中的线程共享同一内存空间，但进程之间的内存空间是独立的。 同一个进程中的所有线程的数据是共享的，但进程之间的数据是独立的。 对主线程的修改可能会影响其他线程的行为，但是父进程的修改（除了删除以外）不会影响其他子进程。 线程是一个上下文的执行指令，而进程则是与运算相关的一簇资源。 同一个进程的线程之间可以直接通信，但是进程之间的交流需要借助中间代理来实现。 创建新的线程很容易，但是创建新的进程需要对父进程做一次复制。 一个线程可以操作同一进程的其他线程，但是进程只能操作其子进程。 线程启动速度快，进程启动速度慢（但是两者运行速度没有可比性）。 2. 简单Python实列爬取相关常见网站主页，并且获取其中的title 1234567891011import threadingimport requestsimport timefrom bs4 import BeautifulSouphosts = "http://baidu.com", "http://cn.bing.com", "http://taobao.com","http://jd.com"start = time.time()for host in hosts: url = requests.get(host) soup = BeautifulSoup(url.text) print(soup.findAll([ 'title' ])) print("Elapsed Time: %s" % (time.time()- start)) 结果如下： 1234[&lt;title&gt;微软 Bing 搜索 - 国内版&lt;/title&gt;][&lt;title&gt;淘宝网 - 淘！我喜欢&lt;/title&gt;][&lt;title&gt;京东(JD.COM)-正品低价、品质保障、配送及时、轻松购物！&lt;/title&gt;]Elapsed Time: 4.66728138923645 thread优化 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import timeimport queueimport requestsimport threadingfrom bs4 import BeautifulSouphosts = "http://baidu.com", "http://cn.bing.com", "http://taobao.com","http://jd.com"Queue = queue.Queue()out_queue = queue.Queue()class ThreadUrl(threading.Thread): """Threaded Url Grab""" def __init__(self, queue, outqueue): threading.Thread.__init__(self) self.queue = queue self.out_queue = outqueue def run(self): while True: #grabs host from queue host = self.queue.get() #grabs urls of hosts and then grabs chunk of webpage url = requests.get(host) chunk = url.text #place chunk into out queue self.out_queue.put(chunk) #signals to queue job is done self.queue.task_done()class DatamineThread(threading.Thread): """Threaded Url Grab""" def __init__(self, out_queue): threading.Thread.__init__(self) self.out_queue = out_queue def run(self): while True: #grabs host from queue chunk = self.out_queue.get() #parse the chunk soup = BeautifulSoup(chunk) print (soup.findAll(['title'])) #signals to queue job is done self.out_queue.task_done()start = time.time()def main(): #spawn a pool of threads, and pass them queue instance for i in range(5): t = ThreadUrl(Queue, out_queue) t.setDaemon(True) t.start() #populate queue with data for host in hosts: Queue.put(host) for i in range(5): dt = DatamineThread(out_queue) dt.setDaemon(True) dt.start() #wait on the queue until everything has been processed Queue.join() out_queue.join()main()print ("Elapsed Time: %s" % (time.time() - start)) 使用thread结果 1234[&lt;title&gt;微软 Bing 搜索 - 国内版&lt;/title&gt;][&lt;title&gt;京东(JD.COM)-正品低价、品质保障、配送及时、轻松购物！&lt;/title&gt;][&lt;title&gt;淘宝网 - 淘！我喜欢&lt;/title&gt;]Elapsed Time: 1.513925552368164 3. 生产者消费者模型​ 代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import timeimport randomimport loggingimport queueimport threadinglogging.basicConfig(level=logging.DEBUG, format='(%(threadName)-9s) %(message)s',)BUF_SIZE = 10q = queue.Queue(BUF_SIZE)class ProducerThread(threading.Thread): def __init__(self, group=None, target=None, name=None, args=(), kwargs=None, verbose = True): super(ProducerThread,self).__init__() self.target = target self.name = name def run(self): while True: if not q.full(): rand = random.randint(1,10) q.put(rand) logging.debug('Putting '+ str(rand) + ':' + str(q.qsize()) + ' item in queue') time.sleep(random.random())class ConsumerThread(threading.Thread): def __init__( self, group = None, target = None, name = None, args = (), kwargs = None, verbose = True ): super(ConsumerThread, self).__init__() self.target = target self.name = name def run(self): while True: if not q.empty(): item = q.get() logging.debug('Getting ' + str(item) + ' : ' + str(q.qsize()) + ' items in queue') time.sleep(random.random())if __name__ == '__main__': p = ProducerThread( name = 'producer') c = ConsumerThread( name = 'consumer') p.start() time.sleep(2) c.start() time.sleep(2) 4. Python queue工具的认识​ queue是python中的标准库，俗称队列。 ​ 在python中，多个线程之间的数据是共享的，多个线程进行数据交换的时候，不能够保证数据的安全性和一致性，所以当多个线程需要进行数据交换的时候，队列就出现了，队列可以完美解决线程间的数据交换，保证线程间数据的安全性和一致性。 ​ 注意： 在python2.x中，模块名为Queue queue模块有三种队列及构造函数 Python queue模块的FIFO队列先进先出。 queue.Queue(maxsize) LIFO类似于堆，即先进后出。 queue.LifoQueue(maxsize) 还有一种是优先级队列级别越低越先出来。 queue.PriorityQueue(maxsize) queue模块中的常用方法 queue.qsize() 返回队列的大小 queue.empty() 如果队列为空，返回True,反之False queue.full() 如果队列满了，返回True,反之False queue.full 与 maxsize 大小对应 queue.get([block[, timeout]])获取队列，立即取出一个元素， timeout超时时间 queue.put(item[, timeout]]) 写入队列，立即放入一个元素， timeout超时时间 queue.get_nowait() 相当于queue.get(False) queue.put_nowait(item) 相当于queue.put(item, False) queue.join() 阻塞调用线程，直到队列中的所有任务被处理掉, 实际上意味着等到队列为空，再执行别的操作 queue.task_done() 在完成一项工作之后，queue.task_done()函数向任务已经完成的队列发送一个信号 代码实例 以下代码在Python3下通过 创建队列 12import queueq = queue.Queue() empty方法（如果队列为空，返回True） 1234import queueq = queue.Queue()print(q.empty())#输出：True ​ full方法（如果队列满了，返回True） 12345import queueq = queue.Queue(1) #指定队列大小q.put('a')print(q.full())#输出：True ​ put方法和get方法 123456import queueq = queue.Queue()q.put('a')q.put('b')print(q.get())#输出：a ​ qsize方法(返回队列里元素个数) 123456import queueq = queue.Queue()q.put('a')q.put('b')print(q.qsize())#输出：2 5. multiprocessing 进程Python中的multiprocess提供了Process类，实现进程相关的功能。但是它基于fork机制，因此不被windows平台支持。想要在windows中运行，必须使用if __name__ == &#39;__main__:的方式，显然这只能用于调试和学习，不能用于实际环境。另外，在multiprocess中你既可以import大写的Process，也可以import小写的process，这两者是完全不同的东西。这种情况在Python中很多，请一定要小心和注意。 下面是一个简单的多进程例子，Process类的用法和Thread类几乎一模一样。 12345678910111213141516import osimport multiprocessingdef foo(i): # 同样的参数传递方法 print("这里是 ", multiprocessing.current_process().name) print('模块名称:', __name__) print('父进程 id:', os.getppid()) # 获取父进程id print('当前子进程 id:', os.getpid()) # 获取自己的进程id print('------------------------')if __name__ == '__main__': for i in range(5): p = multiprocessing.Process(target=foo, args=(i,)) p.start() 运行结果： 12345678910111213141516171819202122232425这里是 Process-2模块名称: __mp_main__父进程 id: 880当前子进程 id: 5260--------------这里是 Process-3模块名称: __mp_main__父进程 id: 880当前子进程 id: 4912--------------这里是 Process-4模块名称: __mp_main__父进程 id: 880当前子进程 id: 5176--------------这里是 Process-1模块名称: __mp_main__父进程 id: 880当前子进程 id: 5380--------------这里是 Process-5模块名称: __mp_main__父进程 id: 880当前子进程 id: 3520-------------- 1. 进程间的数据共享在Linux中，每个子进程的数据都是由父进程提供的，每启动一个子进程就从父进程克隆一份数据。 创建一个进程需要非常大的开销，每个进程都有自己独立的数据空间，不同进程之间通常是不能共享数据的，要想共享数据，一般通过中间件来实现。 下面我们尝试用一个全局列表来实现进程间的数据共享： 12345678910111213from multiprocessing import Processlis = []def foo(i): lis.append(i) print("This is Process ", i," and lis is ", lis, " and lis.address is ", id(lis))if __name__ == '__main__': for i in range(5): p = Process(target=foo, args=(i,)) p.start() print("The end of list_1:", lis) 运行结果： 123456The end of list_1: []This is Process 2 and lis is [2] and lis.address is 40356744This is Process 1 and lis is [1] and lis.address is 40291208This is Process 0 and lis is [0] and lis.address is 40291208This is Process 3 and lis is [3] and lis.address is 40225672This is Process 4 and lis is [4] and lis.address is 40291208 可以看到，全局列表lis没有起到任何作用，在主进程和子进程中，lis指向内存中不同的列表。 想要在进程之间进行数据共享可以使用Queues、Array和Manager这三个multiprocess模块提供的类。 1.1 使用Array共享数据对于Array数组类，括号内的“i”表示它内部的元素全部是int类型，而不是指字符“i”，数组内的元素可以预先指定，也可以只指定数组的长度。Array类在实例化的时候必须指定数组的数据类型和数组的大小，类似temp = Array(&#39;i&#39;, 5)。对于数据类型有下面的对应关系： 123456'c': ctypes.c_char, 'u': ctypes.c_wchar,'b': ctypes.c_byte, 'B': ctypes.c_ubyte,'h': ctypes.c_short, 'H': ctypes.c_ushort,'i': ctypes.c_int, 'I': ctypes.c_uint,'l': ctypes.c_long, 'L': ctypes.c_ulong,'f': ctypes.c_float, 'd': ctypes.c_double 看下面的例子： 123456789101112from multiprocessing import Processfrom multiprocessing import Arraydef func(i,temp): temp[0] += 100 print("进程%s " % i, ' 修改数组第一个元素后-----&gt;', temp[0])if __name__ == '__main__': temp = Array('i', [1, 2, 3, 4]) for i in range(10): p = Process(target=func, args=(i, temp)) p.start() 运行结果： 12345678910进程2 修改数组第一个元素后-----&gt; 101进程4 修改数组第一个元素后-----&gt; 201进程5 修改数组第一个元素后-----&gt; 301进程3 修改数组第一个元素后-----&gt; 401进程1 修改数组第一个元素后-----&gt; 501进程6 修改数组第一个元素后-----&gt; 601进程9 修改数组第一个元素后-----&gt; 701进程8 修改数组第一个元素后-----&gt; 801进程0 修改数组第一个元素后-----&gt; 901进程7 修改数组第一个元素后-----&gt; 1001 1.2 使用Manager共享数据通过Manager类也可以实现进程间数据的共享。Manager()返回的manager对象提供一个服务进程，使得其他进程可以通过代理的方式操作Python对象。manager对象支持 list, dict, Namespace, Lock, RLock, Semaphore, BoundedSemaphore, Condition, Event, Barrier, Queue, Value ,Array等多种格式。 12345678910111213from multiprocessing import Processfrom multiprocessing import Managerdef func(i, dic): dic["num"] = 100+i print(dic.items())if __name__ == '__main__': dic = Manager().dict() for i in range(10): p = Process(target=func, args=(i, dic)) p.start() p.join() 运行结果： 12345678910[('num', 100)][('num', 101)][('num', 102)][('num', 103)][('num', 104)][('num', 105)][('num', 106)][('num', 107)][('num', 108)][('num', 109)] 1.3 使用queues的Queue类共享数据multiprocessing是一个包，它内部又一个queues模块，提供了一个Queue队列类，可以实现进程间的数据共享，如下例所示： 123456789101112131415import multiprocessingfrom multiprocessing import Processfrom multiprocessing import queuesdef func(i, q): ret = q.get() print("进程%s从队列里获取了一个%s，然后又向队列里放入了一个%s" % (i, ret, i)) q.put(i)if __name__ == "__main__": lis = queues.Queue(20, ctx=multiprocessing) lis.put(0) for i in range(10): p = Process(target=func, args=(i, lis,)) p.start() 运行结果： 12345678910进程1从队列里获取了一个0，然后又向队列里放入了一个1进程4从队列里获取了一个1，然后又向队列里放入了一个4进程2从队列里获取了一个4，然后又向队列里放入了一个2进程6从队列里获取了一个2，然后又向队列里放入了一个6进程0从队列里获取了一个6，然后又向队列里放入了一个0进程5从队列里获取了一个0，然后又向队列里放入了一个5进程9从队列里获取了一个5，然后又向队列里放入了一个9进程7从队列里获取了一个9，然后又向队列里放入了一个7进程3从队列里获取了一个7，然后又向队列里放入了一个3进程8从队列里获取了一个3，然后又向队列里放入了一个8 关于queue和Queue，在Python库中非常频繁的出现，很容易就搞混淆了。甚至是multiprocessing自己还有一个Queue类(大写的Q)，一样能实现queues.Queue的功能，导入方式是from multiprocessing import Queue。 2. 进程锁为了防止和多线程一样的出现数据抢夺和脏数据的问题，同样需要设置进程锁。与threading类似，在multiprocessing里也有同名的锁类RLock，Lock，Event，Condition和 Semaphore，连用法都是一样样的，这一点非常友好！ 12345678910111213141516171819from multiprocessing import Processfrom multiprocessing import Arrayfrom multiprocessing import RLock, Lock, Event, Condition, Semaphoreimport timedef func(i,lis,lc): lc.acquire() lis[0] = lis[0] - 1 time.sleep(1) print('say hi', lis[0]) lc.release()if __name__ == "__main__": array = Array('i', 1) array[0] = 10 lock = RLock() for i in range(10): p = Process(target=func, args=(i, array, lock)) p.start() 运行结果： 12345678910say hi 9say hi 8say hi 7say hi 6say hi 5say hi 4say hi 3say hi 2say hi 1say hi 0 3. 进程池Pool类进程启动的开销比较大，过多的创建新进程会消耗大量的内存空间。仿照线程池的做法，我们可以使用进程池控制内存开销。 比较幸运的是，Python给我们内置了一个进程池，不需要像线程池那样要自己写，你只需要简单的from multiprocessing import Pool导入就行。进程池内部维护了一个进程序列，需要时就去进程池中拿取一个进程，如果进程池序列中没有可供使用的进程，那么程序就会等待，直到进程池中有可用进程为止。 进程池中常用的方法： apply() 同步执行（串行） apply_async() 异步执行（并行） terminate() 立刻关闭进程池 join() 主进程等待所有子进程执行完毕。必须在close或terminate()之后。 close() 等待所有进程结束后，才关闭进程池。 123456789101112131415161718from multiprocessing import Poolimport timedef func(args): time.sleep(1) print("正在执行进程 ", args)if __name__ == '__main__': p = Pool(5) # 创建一个包含5个进程的进程池 for i in range(30): p.apply_async(func=func, args=(i,)) p.close() # 等子进程执行完毕后关闭进程池 # time.sleep(2) # p.terminate() # 立刻关闭进程池 p.join()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>thread</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[金字塔原理]]></title>
    <url>%2F2019%2F10%2F28%2F%E9%87%91%E5%AD%97%E5%A1%94%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[《金字塔原理》读书笔记附：金字塔原理.pdf 工作的时候，特别是搞技术的同学，我们通常会有一种感觉，“表达” 比 “做” 难。有时候明明做得挺好的一件事情，表达出来却不是那么回事情，特别是当转正、晋升述职的时候，都不知道怎么来组织自己的思路。平时在和同事、Partner沟通的时候，需要沟通好一会才能把事情说清楚。 如何整理自己的思维逻辑，表达自己想表达的内容；如何能让对方看懂、听明白、记住我们想表达的；如何让对方顺着我们的思路一起思考。这是门很深的学问。 但其实有一些普世方法，在我们初中、高中的语文课上就学习过。其中，有个鼎鼎有名的原理：“金字塔原理”。 学习金字塔原理能够使你的思考、表达和思维都变得既有逻辑又有条理。有些人花一分钟可以找到事情的本质，有些人花上几天时间，可能也还没到入门的诀窍；有些人可能瞬间可以把一件事情说的很清楚，有些人就是结结巴巴，说不出来。其实，有时候并不是能力的问题，而是你是否掌握了一套有效的工具。而金字塔原理，就是这样一套让你可以掌握思考、表达、写作的工具。 为什么要用金字塔结构熟悉的囧境 述职报告述职 PPT 写得一气呵成，拿给老板一看，老板问了一句，“你PPT的思路是什么？”，囧。 文章分享文章挥洒自如，洋洋洒洒，读者读完，找不到重点，囧。 读书一本书，经历多少个夜晚，终于读完了，但两眼一闭，“这本书讲了些啥呢，我全忘了”，囧。 常见偏见 我写不出“好”的文章，是因为我的文笔不够 我画不出“好”的架构图，画不出好的设计图，是因为我没有找到好的软件，或者，我不会很好地应用这个软件 我写不出“好”的ppt，是因为我的ppt模版不行 我读完这本书，全忘了，是因为这本书写的不好或者我记性不好 不管是上面提及熟悉的场景，还是常见的错误想法，我们的关键问题是什么？我们在写文章，或写PPT时，我们自己没有非常清晰的思路，没有梳理清楚自己的表达逻辑。我们表达思想时采用的逻辑顺序和读者的理解力发生了矛盾，我们的表达结构不是读者容易理解的结构。这边多次强调的结构、思路，有个万能法则，那就是本文重点要说的“金字塔原理”。 很早的时候，人类就认识到，人类思维的基本规律是：大脑自动将信息归类分组，以便于理解和记忆。如果你所表达的内容结构，思路呈金字塔结构，由顶部开始逐渐向下展开，这样的思路不仅让自己，也让读者会更清晰，更易懂。 什么是金字塔原理金字塔原理作者介绍： 1金字塔原理是一种重点突出、逻辑清晰、主次分明的逻辑思路、表达方式和规范动作。基本结构：中心思想明确，结论先行(只有一个中心思想，并放在最前面)，以上统下(每一层思想是对下一层思想的总结概括)，归类分组(每一组中的思想符合某一逻辑范畴)，逻辑递进(每组内的思想必须按照逻辑顺序排列)。先重要后次要，先全局后细节，先结论后原因，先结果后过程。训练表达者：关注、挖掘受众的意图、需求、利益点、关注点、兴趣点和兴奋点，想清内容说什么、怎么说，掌握表达的标准结构、规范动作。帮助达到沟通目的：重点突出，思路清晰，主次分明，让受众有兴趣、能理解、能接受、记得住。具体做法：自上而下表达，自下而上思考，纵向疑问回答／总结概括，横向归类分组／演绎归纳，序言讲故事，标题提炼思想精华。 回到作者对金字塔原理的定义——金字塔原理是一种重点突出、逻辑清晰、主次分明的逻辑思路、表达方式和规范动作。关注四个关键词： 重点突出：人通常都是没有耐心的，对未知也是有恐惧的。所以你的表达和文章一开始就得让对方知道你讲的到底是什么，进入了你的表达中，你要像一个导游一样去带领你的沟通对象进入到你的写作和表达的场景中。走着走着你就得告诉你的沟通对象，这里是什么、哪里是什么、重要的景点得提醒他，一般的景色就简单带过。 逻辑清晰：能够看到明显因果关系和逻辑顺序，如时间顺序、空间顺序、程度顺序等。 主次分明的逻辑思路：分清楚主要矛盾和次要矛盾，先处理和展示主要矛盾，然后再展示次要矛盾。 规范动作：使用标准动作健身和使用非标准动作健身，花同样的时间，两者呈现的结果可能是千差万别；金字塔原理也是写作、思考、表达的规范性动作，在前期训练的过程，你会感觉很不舒适，但是一旦动作成型，那么你的写作、思考、表达的记忆性肌肉就炼成了，后期将会释放出力量。 金字塔原理就是用高中写议论文的格式要求来写作和思考。 如何运用金字塔原理？1纵向设定疑问，才能引发读者思考。横向有2个推理，演绎推理和归纳推理。运用MECE(Mutually exclusive and collectively exhaustive,即相互独立,完全穷尽)原则，不重、不剩、不漏。1个中心，3个基本点。 纵向要设定疑问，才能引发读者思考在表达和写作中，我们容易陷入一个困境：自己嗨的要死，对方却毫无感觉。导致这样的结果很有可能就是你的表达和写作前戏不够——在正式表达和写作之前，是否撩动了你的读者。要想撩动你的读者，其实你只需要在你的开篇布局中设置一个疑问，种下一颗好奇的种子就能够撩动他。 纵向如何设定疑问？纵向设定疑问模板：背景+冲突+疑问+解答可以在下次在演讲和写作中使用这个模板表达。当然，在真正使用时，顺序也是可以调换的，下面是一个例子： 1比如，我现在要使用金字塔原理纵向疑问的方式，推荐你使用金字塔原理。背景：在这个时代，对大多数普通人而言，要提升自己的影响力，最好的方式可能就通过写作和演讲，因为写作和演讲基于互联网这一传播介质，你的专业和才能可以最快的传递出去，可以迅速提升自己的影响力。冲突：但是我身边对写作和演讲感兴趣的小伙伴都有这样的困惑：面对一堆材料不知道从何下手，总被人批评说写出来的东西混乱，没有逻辑，在舞台上分享的时候，在台下演讲稿很熟悉，但是上台了就脑瓜子空白了。疑问：不知道你是否在写作和表达中都存在这样的困扰，对写作和演讲充满兴趣，也花时间去学习了，但就是无法突破原有的瓶颈，这到底是什么原因呢？实力不济还是老天爷不赏这碗饭。解答：如果你在写作和表达中也遇到类似棘手的难题，那么我推荐你去阅读一本书——《金字塔原理》，这本书也是被麦肯锡公司必学的一本书，书中提到的金字塔原理也成为了麦肯锡公司重要的一部分，金字塔原理可以快速提高你的逻辑性、条理性，让你能够使规范动作来提升你的表达和写作的能力。 横向有两个推理，演绎推理和归纳推理演绎推理：演绎推理通常由大前提+小前提，推导出结论： 从一般到特殊的的推理，前提和结论有一定的关系，关于演绎推理大家耳熟能详的就是亚里士多德的三段论： 1大前提：所有的人都会死；小前提：苏格拉底是人；结论：苏格拉底会死。 演绎推理的优势在于：能够有效的说服人；但缺点就是：如果前提过多，信息过载，造成理解困难。演绎推理就像是串联一样，如果前面环节不正确，那么后面得出的结论肯定是错误的，所以在使用的时候一定要确保串联起来。 归纳推理：归纳推理通常由若干个具有相似性的事件推导出一个概括思想。 从个别到一般，从一堆事物中，归纳一些共性出来。比如，高效能人士的七个习惯、成功的三要素等。归纳推理的优势在于能够清晰有效的展示你的观点，但对于归纳总结的要求比较高，其次是很难对事物进行完全归纳，如果归纳不完全，容易受到质疑。 如何使用归纳推理：先把结论、观点亮出来；根据结论再去寻找支撑结论理由和要素；用MECE（不重、不剩、不漏）检查你的归纳推理。 说服人就用演绎推理，层层递进。说明理由和总结就用归纳推理，先说结论，然后再说明理由和措施，让对方易于接受。 演绎推理就像是串联，前后是有紧密的关系；在使用的过程中，要想有效说服人，大前提一定要正确，其次最好是3段，超过3段容易让人造成理解困难。 运用MECE原则，不重、不剩、不漏MECE原则是金字塔原理的重要法则，MECE法则的核心就是一条信息各部分之间相互独立和完全穷尽。使用MECE法则可以培养自己的系统思考思维，能够把无序的东西变成有序，反逼你把一件事情想得透彻。 如果面对的是一堆无序、混乱的信息，首先不要着急去单个处理信息，而是要把信息分类，做好分类之后，再一个一个对症下药。在实际运用MECE法则的过程中，知道要用MECE原则，但是如何去分类呢，六种分类方法： 1时间顺序：按照时间顺序来做分类；常用类型：过去现在未来、事情发生前、事情发生中、事情发生、春夏秋冬。空间顺序：按照空间的顺序做分类；常用类型：东南西北、上下左右、国内和国外、从内到外、从整体到局部。逻辑顺序：按照事理的关系来做分类；常用类型：先主要后次要、先简单后复杂、先具体后抽象、先因后果。公式法：按照公式来做分类，公式本身就是被经过认证的，找到公式中的要素，也能够做分类。比如：销售额=流量X转化X客单价，要想提升销售额，就必然要提升流量、转化率、客单价其中的一个要素或者3个要素。模型法：模型都是符合MECE原则的，前人总结的模型也是可以拿过来帮助我们做分类。比如：PEST、STP、SWO、4P、PDCA等等。其他法：其他法是也是可以用来分类，不到万不得已不使用，因为使用其他法就意味着你的信息分类穷尽的不完善。 做一个总结：面对杂乱无序的信息，使用MECE原则可以让信息保持有序和完整，也能够让对方看起来舒服和易懂。 常用的MECE分类法有：时间顺序、空间顺序、逻辑顺序、公式法、模型法、其他法。 1个中心，3个基本点使用三一法则，三一法则就是：1个中心，3个基本点。当要表达或写作一个主题，保证有三个基本点来支撑，用这样的方式刻意去练习自己思考问题的深度和广度；一开始可能会很累，但时间久了后，会产生厚积薄发的力量。 当然，这三个基本点也需要符合MECE法则，不重、不剩、不漏。 构建金字塔结构金字塔结构与树结构很类似，所以我们在构建一个金字塔结构的时候，有两种方法，一种是自上而下法，就是从文章的主题出发，去发散文章的结构。还有一种方法就是指下而上法，这种方法则要求先列出主要的观点，再从这些观点去提炼中心思想。 自上而下法： 确定论述的主题 设想读者的疑问 给出答案 检查主题的背景和冲突是否能够引发读者提出疑问 证实答案并给出关键的论证点 先抛结论，然后列出几点来支持自己的结论，再层层详细展开。自上而下表达，结论先行，整体的思路就是以上的金字塔结构。对于读者来说，最容易理解的顺序是先了解最主要的、抽象的思想，然后再了解次要的、为主要思想提供支持的思想；同时，对自己而言，弄清楚自己思想，也是需要这种结构，这种结构能够使自己的思想考虑周全、抽象化，自己的思维层次上升台阶。 当自己心中对问题已有思路，就差清晰的表达出来时，适合用自上而下法。比如，写年终总结时，基本知道自己要写的主题是什么，平时的成绩、遇到的问题、下一年的规划等也有个大概构思，此时，就可以采用自上而下法构建金字塔结构，条理清晰的表明自己的想法。 自下而上法： 列出文章所有的要点 找出要点之间的关联 得出结论 推导出文章的主题 当自己心中，对于想要表达的内容，思绪还比较混乱时适合用自下而上的方法来构建金字塔。即：先归类分组，然后概括每组思想，最后提炼主题，完善整个思考过程。如果要成文，建议思考时可以自下而上，文章还是采用自上而下的方法写出来，比较直截了当，易于理解。 上面两种方法是根据不同的情况来进行的。对于一个归纳的问题，自上而下的方法可能更合适一些，对于演绎的问题，则自下而上的方法可能更好一些。结构化思想可以让人更容易接受。构建结构化的金字塔应当在不同的情况下采用不同的方法，最终的目的就是需要能够更清晰的表达作者的思想，而读者也跟容易接受。 对于自己非常熟知，非常擅长的领域，通常会直接采用自上而下的方法，比如，作为一个有五六年Java开发经验的同学，对于Java技术规划，都非常擅长且思路清晰，会很快就画出我的整体框架，首先可以划分几个领域：质量、性能、架构、安全等，然后每个领域再进行细分，比如，性能领域可以分为：冷启动、核心页面秒开、内存等等。但如果是我们不太擅长的领域，无法直接构建金字塔结构的顶部。可以采用自下而上思考，通常分这几步： 列出你想表达的所有思想要点（头脑风暴） 找出各要点之间的逻辑关系 得出结论 然后，再将这个过程逆转过来，自上而下地表达。 以上是整体金字塔结构的搭建，那在一个小金字塔结构里面，如何阐述一个观点，常有效的方法有SCQA方法：Situation、Conflict、Question、Action。比如在做一个项目汇报时，就可以用这个方法，背景是什么，遇到到困难是什么，采取了哪些措施，达到了什么效果。SCQA可以不用每项都用，但基本都是这几项。 利用金字塔原理理清文章逻辑 文章的条理清晰，才能让看文章的人一眼明白你想要表达的是什么。 写作要遵循的四个基本原则： 一篇文章必定只有一个中心思想。 任何一个层次上的思想都必须是下一层次思想的概括。 每组中的思想必须属于同一个范围。 每组中的思想必须按照逻辑顺序组织。逻辑顺序常见的有：时间顺序（也可以是步骤，如：第一、第二、第三…）、结构顺序（如：北京、上海、厦门…）、重要性顺序（如：最重要、次重要…）。 工作中常写各种汇报类文档，基本是以开头、正文、结尾的模式在写。这里的开头，即序言，要表达清楚并吸引读者注意，有三个要素： 情境（Situation）：事情发生的时间和地点 冲突（Complication）：中间发生了什么事 疑问（Question）：读者产生了什么疑惑正文部分是对读者产生的疑惑进行回答（Answer），综合起来形成写作的四要素：SCQA。 PPT演讲中的金字塔结构在做演讲的时候，保持良好的结构也是非常重要的，一个好的演讲应当全程能够吸引听众的注意力。所以整个PPT的构建也应当采用这种方法。但是在做PPT的过程中，与文章不同的是，PPT不应当出现大段的文字。而应当使用更多的图表，图标与文字的比例应当在9:1左右。 思考的逻辑通常的情况下，明确一个主题思想，快速搭建好文章总体框架结构总不是太难的事情。但很多时候，我们会发现一些通病。一些主题思想使用“缺乏思想”的句子，思想缺乏内在的逻辑关系。比如，该组织存在两个问题；我们建议进行五项改革等等。 我们要尽可能得避免此类缺乏思想的句子，主要有三大原因： 思想结论不明确存在两个问题，严重？不严重？什么级别的？会造成什么伤害？等等 一个简单的复数名词，无法表达这些内容的逻辑关系存在的两个问题之间有什么关系呢？ 容易遗漏同一级的内容，思考不完整还有没有第三、第四个问题呢？ 这种句子会掩盖思考不完整的事实，是错失一个进行逻辑性和创造性思考的绝好机会。有几个方法可以尽量避免此类问题： 总结句说明行动产生的结果／目标。 罗列的思想中，是否可以往上抽取、概括思想。这些罗列的思想是否是相同层次的。 判断该层级的思想是否已经完全穷尽。 回到实际工作过程中，经常会发现一些会有类似的“缺乏思考”的计划，比如，我这个Q要做哪几条优化点，完全没有拔高一层在思考问题，只是停留在当前具体做事的角度，这样整体的思考就非常的局限和单一，没有往更高的层次思考问题。这也是我们通常说的从点到线，到面的过程。概括分组思想能力的培养，抽象概括能力的提升，是需要不断的打磨锻炼的。对一组思想进行严谨的提炼、概括、总结，必然能够推动思维的发展。举个例子，大学毕业整个准备、答辩过程通常需要1个月的周期，这个过程，大家都觉得像是被扒了一层皮。光是PPT就大改很多次。这个过程就是在提炼自己的思想，概括抽象内容，既能如实叙述自己的成绩，又能让评委老师快速领悟你的要点和亮点。这个非常考验人。一场答辩下来，每个人都是有非常大的成长，这个过程就历练了一个人的整体总结概括能力。 金字塔原理自检清单学生时代写完作业会有老师帮我们做解答和批复，但是成年人只有自己才是自己的救世主；在使用金字塔原理写作和表达之后，可以用这一套清单来检查是否符合金字塔原理，避免陷入伪金字塔原理。 清单要点： 1疑问-回答：纵向设定疑问，给出有效的解决措施。结论先行：每篇文章只有一个中心思想，并放在文章的最前面。以上统下：每一层次以上的思想必须是对下一层思想的总结概括。归类分组：每一组中的思想必须是同一个逻辑范畴。逻辑递进：每一组中的思想必须按照逻辑顺序排列。 附：金字塔原理思维导图 参考链接 Byte_liu]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nonviolent Communication]]></title>
    <url>%2F2019%2F10%2F28%2FNonviolent-Communication%2F</url>
    <content type="text"><![CDATA[非暴力沟通总结笔记一、什么是非暴力沟通非暴力沟通是指提我们要专注于彼此的观察、感受、需要和请求，通过转变谈话和聆听的方式，化解人际间的冲突，获得爱和幸福。非暴力意味着让爱融入生活。让尊重、理解、欣赏、感激、慈悲和友情，而非自私自利、贪婪、憎恨、偏见、怀疑和敌意，来主导生活。 二、非暴力沟通的作用非暴力沟通能够治疗内心深处的隐秘伤痛，超越个人心智和情感的局限性，突破那些引发愤怒、沮丧、焦虑等负面情绪的思维方式，用不带伤害的方式化解人际间的冲突，学会建立和谐的生命体验。 非暴力沟通指导我们转变谈话和聆听的方式。我们不再条件反射地反应，而是去明了自己的观察、感受和愿望，有意识地使用语言。我们既诚实、清晰地表达自己，又尊重与倾听他人。这样，在每一次互动中我们都能聆听到自己和他人心灵深处的呼声。同时，它还促使我们仔细的观察，发现正影响我们的行为和事件，并提出明确的请求。 非暴力沟通提醒我们专注于彼此的观察、感受、需要和请求。它鼓励倾听，培育尊重与爱，使我们情意相通，乐于互助。有些人使用非暴力沟通理解自己，有些人用它改善人际关系，还有人借助它改进工作。在世界各地，非暴力沟通被用来协调各大个层面的争论和冲突。 非暴力沟通运用在哪里 适用于各个层面和环境：密关系；家庭；学校；组织机构；心理疗法及精神辅导；外交和商业谈判；任何性质的争论和冲突 三、是什么蒙蔽了爱？异化的沟通方式：有些沟通方式很难让我们体会到爱，异化的沟通方式使我们难以体会到心中的爱。首先证券就是其中的一种，它将不符合我们价值观的人看作是不道德的或邪恶的。进行比较也是一种评判，它会蒙蔽对人对己的爱意。异化的沟通方式还淡化了我们对自己的思想、情感和行为的责任意识。此外，强人所难也会造成心灵的隔阂。 1、道德评判 ：对他人的评价实际上反映了我们的需要和价值观，道德证券是用道德的标准来评判人，如果一个人的行为不符合我们的价值观，那他就被看作是不道德的或邪恶的 2、进行比较：比较也是评判的一种方式 3、回避责任：我们对自己的思想、情感和行动负有责任。不得不。。。、你让我。。。。 当我们根据以下理由行动时，我们也就试图回避责任。当我们根据以下理由行动时，我们也就试图回避责任。*受说不清楚的力量驱使。——为什么打扫房间？——因为我不得不做。*我们的个人情况、成长历程、自我形象等。——为什么喝酒——因为我是个酒鬼。*其他人的行为。——为什么我要打自己的小孩？——因为他跑到街上去。*上级的命令。——为什么欺骗顾客？——因为老板叫我这样做。*同伴的压力。——为什么抽烟？——因为我所有的朋友都抽烟。*机构的规章制度及政策。——为什么我要将你停职？——因为你违规了。根据学校规定，我必须这么做。*性别角色、社会角色或年龄角色。——为什么我必须做我讨厌的工作？——因为我不仅是一个丈夫，而且还是一个父亲。4、强人所难：我们对别人的要求往往暗含着威胁：如果不配合，他们就会受到惩罚。有些行为值得奖励，而另一些行为必须受罚。 暴力的根源 暴力的根源在于人们忽视彼此的感受与需要，而将冲突归咎于对方 五、非暴力沟通四要素1、观察（清楚地表达观察结果，而不判断或评估） 2、感受：注意区分感受和想法（表达感受，例如受伤、害怕、喜悦、开心、气愤等等） ​ 表达想法的词：被抛弃、被羞辱、被虐待、被打扰、被拒绝、不受重视、被束缚、被欺负、无人理解、得不到支持、无人赏识、被利用、被贬低 1、表达需要被满足时的感受词汇（兴奋，喜悦，欣喜，甜蜜，精力充沛，兴高采烈，感激，感动，乐观，自信，振作，振奋，开心，高兴，快乐，愉快，幸福，陶醉，满足，欣慰，心旷神怡，喜出望外，平静，自在，舒适，放松，踏实，安全，温暖，放心，无忧无虑…… 2、表达需要没有满足时的感受词汇（害怕，担心，焦虑，忧虑，着急，紧张，心神不宁，心烦意乱，忧伤，沮丧，灰心，气馁，泄气，绝望，伤感，凄凉，悲伤，恼怒，愤怒，烦恼，苦恼，生气，厌烦，不满，不快，不耐烦，不高兴，震惊，失望，困惑，茫然，寂寞，孤独，郁闷，难过，悲观，沉重，麻木，精疲力尽，萎靡不振，疲惫不堪，昏昏欲睡，无精打采，尴尬，惭愧，妒忌，遗憾，不舒服…… 3、需要（哪些需要导致那样的感受） 4、请求：为了改善生活，我的请求是什么 1、提出具体的请求 清楚地告诉对方，我们希望他们做什么，我们提出的请求越具体越好。如果我们的意思含糊不清，别人就难了解我们到底想要什么 2、明确谈话的目的 我们期待的是如实的反馈——我们想了解他人的真实想法。当然，有时我们希望他人采取某种行动。对自己的认识越深刻，表达越清楚，我们就越可能得到称心的回应。 3、请求反馈 我们的意思和别人的理解有时可能是两回事。如果无法确实对方是否已经明白，我们可能就需要得到反馈 区分观察和评论不区分观察和评论，人们将倾向于听到批评。非暴力沟通的第一个要素是观察。我们仔细观察正在发生的事情，并清楚地说出观察结果。非暴力沟通不鼓励绝对化的评论，而主张评论要基于特定时间和环境中的观察。 注意：“每次”“曾”等词语在以下句子中表达的是观察结果 “总是”、“从不”等词语在以下句子中表达的是评论。 如果我们的表达言过其实，别人就可能产生逆反心理，而不愿做出友善的回应。 体会和表达感受你越是留意自己内心的声音，就越能听到别人的声音。区分感受与想法，用具体的语言如实陈述自己的感受。 示弱（陈述感受）有助于解决冲突 非暴力沟通的第二个要素是感受： 在非暴力沟通中，我们注意区分感受和想法。当我们说“我觉得”，我们常常并不是在表达感受，而是在表达想法。“我觉得”换成“我认为”也许更恰当。 还有一些词表达的是想法，而非感受。例如：被抛弃、被羞辱、被虐待、被打扰、被拒绝、不受重视、被束缚、被欺负、无人理解、得不到支持、无人赏识、被利用、被贬低 建立表达感受的词汇表;非暴力沟通主张使用具体的语言 1）下列词语可用来表达我们的需要得到满足时的感受： 兴奋，喜悦，欣喜，甜蜜，精力充沛，兴高采烈，感激，感动，乐观，自信，振作，振奋，开心，高兴，快乐，愉快，幸福，陶醉，满足，欣慰，心旷神怡，喜出望外，平静，自在，舒适，放松，踏实，安全，温暖，放心，无忧无虑…… 2）下列词语可用来表达我们的需要没有得到满足时的感受： 害怕，担心，焦虑，忧虑，着急，紧张，心神不宁，心烦意乱，忧伤，沮丧，灰心，气馁，泄气，绝望，伤感，凄凉，悲伤，恼怒，愤怒，烦恼，苦恼，生气，厌烦，不满，不快，不耐烦，不高兴，震惊，失望，困惑，茫然，寂寞，孤独，郁闷，难过，悲观，沉重，麻木，精疲力尽，萎靡不振，疲惫不堪，昏昏欲睡，无精打采，尴尬，惭愧，妒忌，遗憾，不舒服…… 感受的根源 别人的行为可能会刺激我们，但并不是我们感受的根源。感受的根源在于自身，是我们的需要和期待以及对他人言行的看法，导致了我们的感受。可以用“我（感到）……因为我……”句式来认识感受与自身的关系。 听到不中听的话的四种选择：责备自己，指责他人，体会自己的感受和需要，体会他人的感受和需要。批评往往暗含着期待。对他人的批评实际上间接表达了我们尚未满足的需要。做生活的主人——我们对自己的意愿、感受和行动负完全的责任。 听到不中听的话：四种选择 第一种是认为自己犯了猎 第二种是指责对方 第三种是了解我们的感受和需要 第四种是用心体会他人的感受和需要 通过了解我们的需要、愿望、期待以及想法，我们不再指责他人，而承认我们的感受源于自身。 使用以下表达方式时，我们可能就已经忽视了感受与自身的关系 1）只提及相关的事情 2）2）只提及他人的行为 3）3）指责他人 我们可以通过“我（感到）……因为我……”这种表达方式来认识感受与自身的关系 非暴力沟通需要如果我们通过批评来提出主张，人们的反应常常是申辩或反击。反之，如果我们直接说出需要，其他人就较有可能做出积极的回应。 大多数人并不习惯从需要的角度来考虑问题。在不顺心时，我们倾向于考虑别人有什么错。 根据我长期以来的经验，一旦人们开始谈论需要，而不指责对方，他们就有可能找到办法来满足双方的需要。以下是一些我们每个人都有的基本需要： 1、自由选择：选择梦想、目标、方向，自由制定计划来实现这些梦想、目标和方向。 2、庆祝：庆祝生命的创造力以及梦想的实现，纪念人生的失落、亲人的去世或梦想的破灭等（表达悲伤） 3）言行不一：真诚、创造 、意义、自我肯定。 4）滋养身体：空气、食物、运动，免于病毒、细菌、昆虫及肉食动物的伤害，休息、住所、触摸、水。 5）玩耍：乐趣、欢笑。 6）情意相通：美、和谐、激励、秩序、平静。 7）相互依存：接纳、欣赏、亲密关系、社会、体贴、成长，安全感、倾听，诚实（诚实使我们能够认识和超越自己的局限性），爱、信心、尊重、支持、信任、理解。 从“情感的奴隶”到“生活的主人” 对于大多数的人来说，个人成长一般会经历三个阶段。 第一阶段：“情感的奴隶” 在这个阶段，我们相信自己需要为他人负责——让他们快乐是我们的义务。如果别人不高兴，我们就会感到不安，觉得自己有责任做点什么。此时，我们特别容易把亲人看作是负担 第二阶段：“面目可憎 为他人的情绪负责，牺牲自己迎合他人，代价实在很大。想到日子过得这么憋屈，我闪可能会很恼怒 第三阶段：“生活的主人” 我们乐于互助。我们帮助他人，是出于爱，而不是出于恐惧、内疚或惭愧。那是自由而快乐的行为。此时，我们意识到，虽然我们对自己的意愿、感受和行动负有完全的责任，但无法为他人负责。我们还发现，人与人相互依存，损人无法真正利己。非暴力沟通正是想帮助我们既表达自己，又关心他人。 请求帮助提出具体的请求 清楚地告诉对方，我们希望他们做什么 我们提出的请求越具体越好。如果我们的意思含糊不清，别人就难了解我们到底想要什么 明确谈话的目的 我们期待的是如实的反馈——我们想了解他人的真实想法。当然，有时我们希望他人采取某种行动。对自己的认识越深刻，表达越清楚，我们就越可能得到称心的回应。 请求反馈 我们的意思和别人的理解有时可能是两回事。如果无法确实对方是否已经明白，我们可能就需要得到反馈 了解他人的反应 a）对方此时此刻的感受 有时，我们想了解对方的感受，以及为什么他们会产生那样的感受。为此，我们也许会问：“听你说这些，你的心情怎么样？”然后，我们可以进一步问：“为什么呢？” b）对方正在想什么:有时，我们想了解对方的想法。在询问时，说清楚想了解的是哪些方面的想法，将有助于我们获得所需要的回应。例如，我们可以和对方说：“我想请你谈谈我的建议是否有可行性。如果不太可行，那根据你的判断，哪些因素会妨碍建议的实施呢？”如果我们只是问“对这个建议你有什么看法”，那么，对方谈的内容也许并不是我们关心的。 c）对方是否接受我们的请求 在另一些时候，我们可能想知道，对方是否愿意接受我们的请求。这时，我们也许会问：“我想知道，你是否同意将会议时间延迟一周？ 用全身心倾听 为了倾听他们，我们需要先放下已有的想法和判断，全神贯注地体会对方 ●建议：“我想你应该……” ●比较：“这算不了什么。你听听我的经历……” ●说教：“如果你这样做……你将会得到很大的好处。” ●安慰：“这不是你的错，你已经尽最大努力了。” ●回忆：“这让我想起……” ●同情：“哦，你这可怜的人……” ●否定：“高兴一点。不要这么难过。” ●询问：“这种情况是什么时候开始的？” ●辩解：“我原想早点打电话给你，但昨晚……” ●纠正：“事情的经过不是那样的。 非暴力沟通的忧伤及自我宽恕可以激发我们对生命的爱 练习 用“选择做”代替“不得不” 第一步 在日常生活中，你觉得哪些事情没意思，却又认为自己不得不做？请将它们列在一张纸上。 当我第一次审视自己的清单时，仅仅是它的长度就让我明白为什么我活得不开心。我终于意识到，有许多事情，我之所以日复一日地去做，是因为我相信那是不得不做的事情。 我清单上的第一项是“写临床报告”。我讨厌写那些报告，然而，每天我至少要折磨自己一个小时。第二项则是“开车送小孩上学。” 第二步 列好清单后，向自己坦白：你做这些事情是因为你选择了做它们，而不是因为你不得不做。在你所列的每个项目前，加上“我选择做”。 当时，我对这一步骤有些抗拒。我反复强调：“写临床报告不是我的选择！我不得不做！我是一个临床心理医生 。我不得不写这些报告。” 第三步 一旦承认某一行为是你的选择，就填写以下的声明来了解你为什么要那么做：“我选择做__是因为我想要__。” :深入理解我们行为的动机 你在思考“我选择做__是因为我想要__” 1）为了钱 2）2）为了得到赞同 3）3）为了逃避惩罚 4）4）不感到羞愧 5）5）为了避免内疚 6）6）为了履行职责 充分表达愤怒 非暴力沟通并不主张忽视或压抑愤怒，它认为，通过深入地了解愤怒，我们可以充分表达内心的渴望。 为什么我们会生气？ 充分表达愤怒的第一步是我们不再归咎于他人。如果我们认为“他让我很生气”，那么，我们难免就会指责他人。然而，实际情况是，我们心情并不取决于他人的行为。 我们认为别人就当认错或受罚——我相信这就是我们生气的原因。 除了专注于自身的感受和需要，我们还可以选择去体会对方的感受和需要。此时，我们也不会感到生气。我们无须压抑愤怒，只要我们专注于他人的感受和需要，愤怒也就不再存在。 “合理的愤怒”？ 我坚信，专注于我们的需要，比评判他人是什么人更有益于生活。 与其沉浸于“合理的愤怒”，不如倾听自己和他人的需要。这也许需要一个过程，但通过不断地实践，我们将会有意识地用“我生气是因为我需要……”来取代“我生气是因为他们……”。 暴力的种子 表达愤怒的四个步骤 停下来，除了呼吸，什么也别做。我们避免采取行动去指责或惩罚对方。我们只是静静地体会自己。一想是什么想起使我们生气了 为了充分地表达自己，我们现在需要张开嘴，说出我们的愤怒——怒火此时已被转化为需要以及与需要相联系的情感 先倾听他人 给自己时间我们需要有足够的耐心来学习和运用非暴力沟通 在不顺心时，许多人已经习惯于批评和指责他人。因此，在刚开始运用非暴力沟通时，我们可以把节奏放慢些，在说话前先想一想，有时，我们甚至停下来，什么也不说 运用强制力避免伤害 使用强制力的目的是为了保护自己和他人，是为了避免伤害，而不是惩罚他人。 如果我们威胁他人和实施惩罚，对方常常产生敌意和抵触心理，彼此的关系将会疏远。 惩罚还可能使人忽视事情本身的意义，而把注意力放在不服从的后果上。 体罚是最常见的惩罚，指责或否定、不给孩子好处也是一种惩罚。 当你不喜欢他的行为时，请问自己两个问题：我希望他怎么做？我希望他基于什么原因做我希望他做的事情？ 如果冲突双方都能充分表达观察、感受、需要和请求，并得到对方的理解，那么，双方的需要通过可以同时得到满足。至少，他们可以求同存异。 然而，在有些时候，双方没有机会进行这样的对话。例如，有一方也许不想交流，或是危险迫在眉睫没有时间交流。在这样的情况下，我们可能就需要使用强制力来避免伤害。 使用强制力的目的 非暴力沟通中，我们运用强制力是出于防卫（保护自己或对方）的目的而不是为了惩罚、羞辱或谴责对方 重获生活的热情 通过运用非暴力沟通，我们不再试图分析自己或他人有什么毛病，而是用心去了解我们的需要和他人的需要，这样，我们的内心将逐渐变得平和。 一旦我们发现自己心底深处的愿望，并采取积极的行动，我们将会重获生活的热情。 倾听内心的声音 认识情感的根源在于个人的需要和想法，并以建设性的语言提出明确的请求，非暴力沟通帮助我们认识社会文化对个体的消极影响。一旦认识到社会文化的局限性，我们就可能突破它的束缚，至少，我们已经迈出了关键的一步。 解决内心的冲突 心灵环保 用非暴力沟通代替诊断 表达感激 非暴力沟通鼓励我们充分表达感激。在表达感激时，我们说出：1）对我们有益的行为；2）我们的哪些需要得到了满足；3）我们的需要得到满足后，我们是什么样的心情。 当别人以这样的方式表达对我们的感激时，我们可以与对方一起庆祝生命的美——即不自大，也不假谦虚 赞扬的动机 用非暴力沟通的方式表达感激时，我们只是为了庆祝他人的行为提升了我们的生活品质，而不是想得到任何回报。 非暴力沟通表达感激的方式 非暴力沟通表达感激的方式包含三个部分： 1.对方做了什么事情使我们的生活得到了改善； 2.我们有哪些需要得到了满足； 3.我们的心情怎么样？ 感悟：非暴力沟通谈论了如何运用观察、感受、需要和请求来沟通，化解人际交往中的冲突，以此获得爱和幸福。 在人际交往中，很多人往往只注重自己的感受，人们习惯指责对方，推卸责任，以至于激化矛盾冲突，而这本书告诉我们，我们应该站在对方的角度上去思考感受问题，通过转变一些沟通和聆听的方式可以让我们更好的理解他人，获得理解和信任。 读了这本书，让我意识到原来沟通还可以用另外一种方式。为了与他人更好的沟通理解，我们需要学会非暴力沟通，提高沟通品质。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Comprehensive-Python-Cheatsheet]]></title>
    <url>%2F2019%2F10%2F27%2FComprehensive-Python-Cheatsheet%2F</url>
    <content type="text"><![CDATA[Contents​ 1. Collections: List , Dictionary , Set , Tuple , Range , Enumerate , Iterator , Generator .​ 2. Types: Type , String , Regular_Exp , Format , Numbers , Combinatorics , Datetime .​ 3. Syntax: Args , Inline , Closure , Decorator , Class , Duck_Types , Enum , Exceptions .​ 4. System: Print , Input , Command_Line_Arguments , Open , Path , Command_Execution .​ 5. Data: JSON , Pickle , CSV , SQLite , Bytes , Struct , Array , MemoryView , Deque .​ 6. Advanced: Threading , Operator , Introspection , Metaprograming , Eval , Coroutine .​ 7. Libraries: Progress_Bar , Plot , Table , Curses , Logging , Scraping , Web , Profile ,​ NumPy , Image , Animation , Audio , Synthesizer . Main12if __name__ == '__main__': # Runs main() if file wasn't imported. main() List1234567891011121314151617181920&lt;list&gt; = &lt;list&gt;[from_inclusive : to_exclusive : ±step_size]&lt;list&gt;.append(&lt;el&gt;) # Or: &lt;list&gt; += [&lt;el&gt;]&lt;list&gt;.extend(&lt;collection&gt;) # Or: &lt;list&gt; += &lt;collection&gt;&lt;list&gt;.sort()&lt;list&gt;.reverse()&lt;list&gt; = sorted(&lt;collection&gt;)&lt;iter&gt; = reversed(&lt;list&gt;)sum_of_elements = sum(&lt;collection&gt;)elementwise_sum = [sum(pair) for pair in zip(list_a, list_b)]sorted_by_second = sorted(&lt;collection&gt;, key=lambda el: el[1])sorted_by_both = sorted(&lt;collection&gt;, key=lambda el: (el[1], el[0]))flatter_list = list(itertools.chain.from_iterable(&lt;list&gt;))product_of_elems = functools.reduce(lambda out, x: out * x, &lt;collection&gt;)list_of_chars = list(&lt;str&gt;)&lt;int&gt; = &lt;list&gt;.count(&lt;el&gt;) # Returns number of occurrences. Also works on strings.index = &lt;list&gt;.index(&lt;el&gt;) # Returns index of first occurrence or raises ValueError.&lt;list&gt;.insert(index, &lt;el&gt;) # Inserts item at index and moves the rest to the right.&lt;el&gt; = &lt;list&gt;.pop([index]) # Removes and returns item at index or from the end.&lt;list&gt;.remove(&lt;el&gt;) # Removes first occurrence of item or raises ValueError.&lt;list&gt;.clear() # Removes all items. Also works on dictionary and set. Dictionary12345678910111213&lt;view&gt; = &lt;dict&gt;.keys() # Coll. of keys that reflects changes.&lt;view&gt; = &lt;dict&gt;.values() # Coll. of values that reflects changes.&lt;view&gt; = &lt;dict&gt;.items() # Coll. of key-value tuples.value = &lt;dict&gt;.get(key, default=None) # Returns default if key is missing.value = &lt;dict&gt;.setdefault(key, default=None) # Returns and writes default if key is missing.&lt;dict&gt; = collections.defaultdict(&lt;type&gt;) # Creates a dict with default value of type.&lt;dict&gt; = collections.defaultdict(lambda: 1) # Creates a dict with default value 1.&lt;dict&gt;.update(&lt;dict&gt;)&lt;dict&gt; = dict(&lt;collection&gt;) # Creates a dict from coll. of key-value pairs.&lt;dict&gt; = dict(zip(keys, values)) # Creates a dict from two collections.&lt;dict&gt; = dict.fromkeys(keys [, value]) # Creates a dict from collection of keys.value = &lt;dict&gt;.pop(key) # Removes item or raises KeyError.&#123;k: v for k, v in &lt;dict&gt;.items() if k in keys&#125; # Filters dictionary by keys. Counter1234567&gt;&gt;&gt; from collections import Counter&gt;&gt;&gt; colors = ['blue', 'red', 'blue', 'red', 'blue']&gt;&gt;&gt; counter = Counter(colors)&gt;&gt;&gt; counter['yellow'] += 1Counter(&#123;'blue': 3, 'red': 2, 'yellow': 1&#125;)&gt;&gt;&gt; counter.most_common()[0]('blue', 3) Set123456789101112&lt;set&gt; = set()&lt;set&gt;.add(&lt;el&gt;) # Or: &lt;set&gt; |= &#123;&lt;el&gt;&#125;&lt;set&gt;.update(&lt;collection&gt;) # Or: &lt;set&gt; |= &lt;set&gt;&lt;set&gt; = &lt;set&gt;.union(&lt;coll.&gt;) # Or: &lt;set&gt; | &lt;set&gt;&lt;set&gt; = &lt;set&gt;.intersection(&lt;coll.&gt;) # Or: &lt;set&gt; &amp; &lt;set&gt;&lt;set&gt; = &lt;set&gt;.difference(&lt;coll.&gt;) # Or: &lt;set&gt; - &lt;set&gt;&lt;set&gt; = &lt;set&gt;.symmetric_difference(&lt;coll.&gt;) # Or: &lt;set&gt; ^ &lt;set&gt;&lt;bool&gt; = &lt;set&gt;.issubset(&lt;coll.&gt;) # Or: &lt;set&gt; &lt;= &lt;set&gt;&lt;bool&gt; = &lt;set&gt;.issuperset(&lt;coll.&gt;) # Or: &lt;set&gt; &gt;= &lt;set&gt;&lt;el&gt; = &lt;set&gt;.pop() # Raises KeyError if empty.&lt;set&gt;.remove(&lt;el&gt;) # Raises KeyError if missing.&lt;set&gt;.discard(&lt;el&gt;) # Doesn't raise an error. Frozen Set Is immutable and hashable. That means it can be used as a key in a dictionary or as an element in a set. 1&lt;frozenset&gt; = frozenset(&lt;collection&gt;) TupleTuple is an immutable and hashable list. 123&lt;tuple&gt; = ()&lt;tuple&gt; = (&lt;el&gt;, )&lt;tuple&gt; = (&lt;el_1&gt;, &lt;el_2&gt; [, ...]) Named TupleTuple’s subclass with named elements. 123456789101112&gt;&gt;&gt; from collections import namedtuple&gt;&gt;&gt; Point = namedtuple('Point', 'x y')&gt;&gt;&gt; p = Point(1, y=2)Point(x=1, y=2)&gt;&gt;&gt; p[0]1&gt;&gt;&gt; p.x1&gt;&gt;&gt; getattr(p, 'y')2&gt;&gt;&gt; p._fields # Or: Point._fields('x', 'y') Range12345&lt;range&gt; = range(to_exclusive)&lt;range&gt; = range(from_inclusive, to_exclusive)&lt;range&gt; = range(from_inclusive, to_exclusive, ±step_size)from_inclusive = &lt;range&gt;.startto_exclusive = &lt;range&gt;.stop Enumerate12for i, el in enumerate(&lt;collection&gt; [, i_start]): ... Iterator123&lt;iter&gt; = iter(&lt;collection&gt;) # `iter(&lt;iter&gt;)` returns unmodified iterator.&lt;iter&gt; = iter(&lt;function&gt;, to_exclusive) # A Sequence of return values until 'to_exclusive'.&lt;el&gt; = next(&lt;iter&gt; [, default]) # Raises StopIteration or returns 'default' on end. Itertools123456789from itertools import count, repeat, cycle, chain, islice&lt;iter&gt; = count(start=0, step=1) # Returns incremented value endlessly.&lt;iter&gt; = repeat(&lt;el&gt; [, times]) # Returns element endlessly or 'times' times.&lt;iter&gt; = cycle(&lt;collection&gt;) # Repeats the sequence endlessly.&lt;iter&gt; = chain(&lt;coll_1&gt;, &lt;coll_2&gt; [, ...]) # Empties collections in order.&lt;iter&gt; = chain.from_iterable(&lt;collection&gt;) # Empties collections inside a collection in order.&lt;iter&gt; = islice(&lt;collection&gt;, to_exclusive)&lt;iter&gt; = islice(&lt;collection&gt;, from_inclusive, to_exclusive)&lt;iter&gt; = islice(&lt;collection&gt;, from_inclusive, to_exclusive, +step_size) Generator Any function that contains a yield statement returns a generator. Generators and iterators are interchangeable. 1234567def count(start, step): while True: yield startpython start += step&gt;&gt;&gt; counter = count(10, 2)&gt;&gt;&gt; next(counter), next(counter), next(counter)(10, 12, 14) Type Everything is an object. Every object has a type. Type and class are synonymous. 1234&lt;type&gt; = type(&lt;el&gt;) # Or: &lt;el&gt;.__class__&lt;bool&gt; = isinstance(&lt;el&gt;, &lt;type&gt;) # Or: issubclass(type(&lt;el&gt;), &lt;type&gt;)&gt;&gt;&gt; type('a'), 'a'.__class__, str(&lt;class 'str'&gt;, &lt;class 'str'&gt;, &lt;class 'str'&gt;) Some types do not have built-in names, so they must be imported:1from types import FunctionType, MethodType, LambdaType, GeneratorType ABCAn abstract base class introduces virtual subclasses, that don’t inherit from it but are still recognized by isinstance() and issubclass(). 12345678910111213141516171819202122&gt;&gt;&gt; from collections.abc import Sequence, Collection, Iterable&gt;&gt;&gt; isinstance([1, 2, 3], Iterable)True+------------------+----------+------------+----------+| | Sequence | Collection | Iterable |+------------------+----------+------------+----------+| list, range, str | yes | yes | yes || dict, set | | yes | yes || iter | | | yes |+------------------+----------+------------+----------+&gt;&gt;&gt; from numbers import Integral, Rational, Real, Complex, Number&gt;&gt;&gt; isinstance(123, Number)True+--------------------+----------+----------+--------+---------+--------+| | Integral | Rational | Real | Complex | Number |+--------------------+----------+----------+--------+---------+--------+| int | yes | yes | yes | yes | yes || fractions.Fraction | | yes | yes | yes | yes || float | | | yes | yes | yes || complex | | | | yes | yes || decimal.Decimal | | | | | yes |+--------------------+----------+----------+--------+---------+--------+ String1234567891011121314&lt;str&gt; = &lt;str&gt;.strip() # Strips all whitespace characters from both ends.&lt;str&gt; = &lt;str&gt;.strip('&lt;chars&gt;') # Strips all passed characters from both ends.&lt;list&gt; = &lt;str&gt;.split() # Splits on one or more whitespace characters.&lt;list&gt; = &lt;str&gt;.split(sep=None, maxsplit=-1) # Splits on 'sep' str at most 'maxsplit' times.&lt;list&gt; = &lt;str&gt;.splitlines(keepends=False) # Splits on line breaks. Keeps them if 'keepends'.&lt;str&gt; = &lt;str&gt;.join(&lt;coll_of_strings&gt;) # Joins elements using string as separator.&lt;bool&gt; = &lt;sub_str&gt; in &lt;str&gt; # Checks if string contains a substring.&lt;bool&gt; = &lt;str&gt;.startswith(&lt;sub_str&gt;) # Pass tuple of strings for multiple options.&lt;bool&gt; = &lt;str&gt;.endswith(&lt;sub_str&gt;) # Pass tuple of strings for multiple options.&lt;int&gt; = &lt;str&gt;.find(&lt;sub_str&gt;) # Returns start index of first match or -1.&lt;int&gt; = &lt;str&gt;.index(&lt;sub_str&gt;) # Same but raises ValueError if missing.&lt;str&gt; = &lt;str&gt;.replace(old, new [, count]) # Replaces 'old' with 'new' at most 'count' times.&lt;bool&gt; = &lt;str&gt;.isnumeric() # True if str contains only numeric characters.&lt;list&gt; = textwrap.wrap(&lt;str&gt;, width) # Nicely breaks string into lines. Also: ‘lstrip()’, ‘rstrip()’. Also: ‘lower()’, ‘upper()’, ‘capitalize()’ and ‘title()’. Char12345678&lt;str&gt; = chr(&lt;int&gt;) # Converts int to unicode char.&lt;int&gt; = ord(&lt;str&gt;) # Converts unicode char to int.&gt;&gt;&gt; ord('0'), ord('9')(48, 57)&gt;&gt;&gt; ord('A'), ord('Z')(65, 90)&gt;&gt;&gt; ord('a'), ord('z')(97, 122) Regex1234567import re&lt;str&gt; = re.sub(&lt;regex&gt;, new, text, count=0) # Substitutes all occurrences.&lt;list&gt; = re.findall(&lt;regex&gt;, text) # Returns all occurrences.&lt;list&gt; = re.split(&lt;regex&gt;, text, maxsplit=0) # Use brackets in regex to keep the matches.&lt;Match&gt; = re.search(&lt;regex&gt;, text) # Searches for first occurrence of pattern.&lt;Match&gt; = re.match(&lt;regex&gt;, text) # Searches only at the beginning of the text.&lt;iter&gt; = re.finditer(&lt;regex&gt;, text) # Returns all occurrences as match objects. Search() and match() return None if they can’t find a match. Argument ‘flags=re.IGNORECASE’ can be used with all functions. Argument ‘flags=re.MULTILINE’ makes ‘^’ and ‘$’ match the start/end of each line. Argument ‘flags=re.DOTALL’ makes dot also accept newline. Use r’\1’ or ‘\1’ for backreference. Add ‘?’ after an operator to make it non-greedy. Match Object12345&lt;str&gt; = &lt;Match&gt;.group() # Whole match. Also group(0).&lt;str&gt; = &lt;Match&gt;.group(1) # Part in first bracket.&lt;tuple&gt; = &lt;Match&gt;.groups() # All bracketed parts.&lt;int&gt; = &lt;Match&gt;.start() # Start index of a match.&lt;int&gt; = &lt;Match&gt;.end() # Exclusive end index of a match. Special Sequences By default digits, whitespaces and alphanumerics from all alphabets are matched, unless ‘flags=re.ASCII’ argument is used. Use capital letter for negation. 123'\d' == '[0-9]' # Digit'\s' == '[ \t\n\r\f\v]' # Whitespace'\w' == '[a-zA-Z0-9_]' # Alphanumeric Format12&lt;str&gt; = f'&#123;&lt;el_1&gt;&#125;, &#123;&lt;el_2&gt;&#125;'&lt;str&gt; = '&#123;&#125;, &#123;&#125;'.format(&lt;el_1&gt;, &lt;el_2&gt;) Attributes1234567&gt;&gt;&gt; from collections import namedtuple&gt;&gt;&gt; Person = namedtuple('Person', 'name height')&gt;&gt;&gt; person = Person('Jean-Luc', 187)&gt;&gt;&gt; f'&#123;person.height&#125;''187'&gt;&gt;&gt; '&#123;p.height&#125;'.format(p=person)'187' General Options12345&#123;&lt;el&gt;:&lt;10&#125; # '&lt;el&gt; '&#123;&lt;el&gt;:^10&#125; # ' &lt;el&gt; '&#123;&lt;el&gt;:&gt;10&#125; # ' &lt;el&gt;'&#123;&lt;el&gt;:.&lt;10&#125; # '&lt;el&gt;......'&#123;&lt;el&gt;:&lt;0&#125; # '&lt;el&gt;' Strings‘!r’ calls object’s repr() method, instead of str(), to get a string. 123&#123;'abcde'!r:&lt;10&#125; # "'abcde' "&#123;'abcde':.3&#125; # 'abc'&#123;'abcde':10.3&#125; # 'abc ' Numbers123456&#123; 123456:10,&#125; # ' 123,456'&#123; 123456:10_&#125; # ' 123_456'&#123; 123456:+10&#125; # ' +123456'&#123;-123456:=10&#125; # '- 123456'&#123; 123456: &#125; # ' 123456'&#123;-123456: &#125; # '-123456' Floats1234&#123;1.23456:10.3&#125; # ' 1.23'&#123;1.23456:10.3f&#125; # ' 1.235'&#123;1.23456:10.3e&#125; # ' 1.235e+00'&#123;1.23456:10.3%&#125; # ' 123.456%' Comparison of float presentation types:123456789101112131415161718192021222324+----------------+----------------+---------------+----------------+-----------------+| | &#123;&lt;float&gt;&#125; | &#123;&lt;float&gt;:f&#125; | &#123;&lt;float&gt;:e&#125; | &#123;&lt;float&gt;:%&#125; |+----------------+----------------+---------------+----------------+-----------------+| 0.000056789 | '5.6789e-05' | '0.000057' | '5.678900e-05' | '0.005679%' || 0.00056789 | '0.00056789' | '0.000568' | '5.678900e-04' | '0.056789%' || 0.0056789 | '0.0056789' | '0.005679' | '5.678900e-03' | '0.567890%' || 0.056789 | '0.056789' | '0.056789' | '5.678900e-02' | '5.678900%' || 0.56789 | '0.56789' | '0.567890' | '5.678900e-01' | '56.789000%' || 5.6789 | '5.6789' | '5.678900' | '5.678900e+00' | '567.890000%' || 56.789 | '56.789' | '56.789000' | '5.678900e+01' | '5678.900000%' || 567.89 | '567.89' | '567.890000' | '5.678900e+02' | '56789.000000%' |+----------------+----------------+---------------+----------------+-----------------++----------------+----------------+---------------+----------------+-----------------+| | &#123;&lt;float&gt;:.2&#125; | &#123;&lt;float&gt;:.2f&#125; | &#123;&lt;float&gt;:.2e&#125; | &#123;&lt;float&gt;:.2%&#125; |+----------------+----------------+---------------+----------------+-----------------+| 0.000056789 | '5.7e-05' | '0.00' | '5.68e-05' | '0.01%' || 0.00056789 | '0.00057' | '0.00' | '5.68e-04' | '0.06%' || 0.0056789 | '0.0057' | '0.01' | '5.68e-03' | '0.57%' || 0.056789 | '0.057' | '0.06' | '5.68e-02' | '5.68%' || 0.56789 | '0.57' | '0.57' | '5.68e-01' | '56.79%' || 5.6789 | '5.7' | '5.68' | '5.68e+00' | '567.89%' || 56.789 | '5.7e+01' | '56.79' | '5.68e+01' | '5678.90%' || 567.89 | '5.7e+02' | '567.89' | '5.68e+02' | '56789.00%' |+----------------+----------------+---------------+----------------+-----------------+ Ints123&#123;90:c&#125; # 'Z'&#123;90:X&#125; # '5A'&#123;90:b&#125; # '1011010' NumbersTypes12345&lt;int&gt; = int(&lt;float/str/bool&gt;) # Or: math.floor(&lt;float&gt;)&lt;float&gt; = float(&lt;int/str/bool&gt;)&lt;complex&gt; = complex(real=0, imag=0) # Or: &lt;real&gt; + &lt;real&gt;j&lt;Fraction&gt; = fractions.Fraction(numerator=0, denominator=1)&lt;Decimal&gt; = decimal.Decimal(&lt;str/int/float&gt;) ‘int()’ and ‘float()’ raise ValueError on malformed strings. Decimal numbers can be represented exactly, unlike floats where ‘1.1 + 2.2 != 3.3’. Their precision can be adjusted with ‘decimal.getcontext().prec = ‘. Basic Functions1234&lt;num&gt; = pow(&lt;num&gt;, &lt;num&gt;) # Or: &lt;num&gt; ** &lt;num&gt;&lt;num&gt; = abs(&lt;num&gt;)&lt;int&gt; = round(&lt;num&gt;)&lt;num&gt; = round(&lt;num&gt;, ±ndigits) # `round(126, -1) == 130` Math123from math import e, pi, inf, nanfrom math import cos, acos, sin, asin, tan, atan, degrees, radiansfrom math import log, log10, log2 Statistics1from statistics import mean, median, variance, pvariance, pstdev Random12345from random import random, randint, choice, shuffle&lt;float&gt; = random()&lt;int&gt; = randint(from_inclusive, to_inclusive)&lt;el&gt; = choice(&lt;list&gt;)shuffle(&lt;list&gt;) Bin, Hex1234&lt;int&gt; = 0b&lt;bin&gt; # Or: 0x&lt;hex&gt;&lt;int&gt; = int('&lt;bin&gt;', 2) # Or: int('&lt;hex&gt;', 16)&lt;int&gt; = int('0b&lt;bin&gt;', 0) # Or: int('0x&lt;hex&gt;', 0)'0b&lt;bin&gt;' = bin(&lt;int&gt;) # Or: '0x&lt;hex&gt;' = hex(&lt;int&gt;) Bitwise Operators123456&lt;int&gt; = &lt;int&gt; &amp; &lt;int&gt; # And&lt;int&gt; = &lt;int&gt; | &lt;int&gt; # Or&lt;int&gt; = &lt;int&gt; ^ &lt;int&gt; # Xor (0 if both bits equal)&lt;int&gt; = &lt;int&gt; &lt;&lt; n_bits # Shift left&lt;int&gt; = &lt;int&gt; &gt;&gt; n_bits # Shift right&lt;int&gt; = ~&lt;int&gt; # Compliment (flips bits) Combinatorics Every function returns an iterator. If you want to print the iterator, you need to pass it to the list() function! 1234567891011121314151617from itertools import product, combinations, combinations_with_replacement, permutations&gt;&gt;&gt; product([0, 1], repeat=3)[(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)]&gt;&gt;&gt; product('ab', '12')[('a', '1'), ('a', '2'), ('b', '1'), ('b', '2')]&gt;&gt;&gt; combinations('abc', 2)[('a', 'b'), ('a', 'c'), ('b', 'c')]&gt;&gt;&gt; combinations_with_replacement('abc', 2)[('a', 'a'), ('a', 'b'), ('a', 'c'), ('b', 'b'), ('b', 'c'), ('c', 'c')]&gt;&gt;&gt; permutations('abc', 2)[('a', 'b'), ('a', 'c'), ('b', 'a'), ('b', 'c'), ('c', 'a'), ('c', 'b')] Datetime Module ‘datetime’ provides ‘date’ , ‘time’ , ‘datetime’ and ‘timedelta’ classes. All are immutable and hashable. Time and datetime can be ‘aware’ , meaning they have defined timezone, or ‘naive’ , meaning they don’t. If object is naive it is presumed to be in the system’s timezone. 12from datetime import date, time, datetime, timedeltafrom dateutil.tz import UTC, tzlocal, gettz Constructors12345&lt;D&gt; = date(year, month, day)&lt;T&gt; = time(hour=0, minute=0, second=0, microsecond=0, tzinfo=None, fold=0)&lt;DT&gt; = datetime(year, month, day, hour=0, minute=0, second=0, ...)&lt;TD&gt; = timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0) Use ‘&lt;D/DT&gt;.weekday()’ to get the day of the week (Mon == 0). ‘fold=1’ means second pass in case of time jumping back for one hour. Now123&lt;D/DTn&gt; = D/DT.today() # Current local date or naive datetime.&lt;DTn&gt; = DT.utcnow() # Naive datetime from current UTC time.&lt;DTa&gt; = DT.now(&lt;tzinfo&gt;) # Aware datetime from current tz time. To extract time use ‘.time()’, ‘.time()’ or ‘.timetz()’. Timezone12345&lt;tzinfo&gt; = UTC # UTC timezone. London without DST.&lt;tzinfo&gt; = tzlocal() # Local timezone. Also gettz().&lt;tzinfo&gt; = gettz('&lt;Cont.&gt;/&lt;City&gt;') # 'Continent/City_Name' timezone or None.&lt;DTa&gt; = &lt;DT&gt;.astimezone(&lt;tzinfo&gt;) # Datetime, converted to passed timezone.&lt;Ta/DTa&gt; = &lt;T/DT&gt;.replace(tzinfo=&lt;tzinfo&gt;) # Unconverted object with new timezone. Encode12345&lt;D/T/DT&gt; = D/T/DT.fromisoformat('&lt;iso&gt;') # Object from ISO string. Raises ValueError.&lt;DT&gt; = DT.strptime(&lt;str&gt;, '&lt;format&gt;') # Datetime from str, according to format.&lt;D/DTn&gt; = D/DT.fromordinal(&lt;int&gt;) # D/DTn from days since Christ, at midnight.&lt;DTn&gt; = DT.fromtimestamp(&lt;real&gt;) # Local time DTn from seconds since Epoch.&lt;DTa&gt; = DT.fromtimestamp(&lt;real&gt;, &lt;tz.&gt;) # Aware datetime from seconds since Epoch. ISO strings come in following forms: ‘YYYY-MM-DD’, ‘HH:MM:SS.ffffff[±]’, or both separated by a space or a ‘T’. Offset is formatted as: ‘HH:MM’. On Unix systems Epoch is ‘1970-01-01 00:00 UTC’, ‘1970-01-01 01:00 CET’, … Decode12345&lt;str&gt; = &lt;D/T/DT&gt;.isoformat() # ISO string representation.&lt;str&gt; = &lt;D/T/DT&gt;.strftime('&lt;format&gt;') # Custom string representation.&lt;int&gt; = &lt;D/DT&gt;.toordinal() # Days since Christ, ignoring time and tz.&lt;float&gt; = &lt;DTn&gt;.timestamp() # Seconds since Epoch from DTn in local time.&lt;float&gt; = &lt;DTa&gt;.timestamp() # Seconds since Epoch from DTa. Format1234&gt;&gt;&gt; from datetime import datetime&gt;&gt;&gt; dt = datetime.strptime('2015-05-14 23:39:00.00 +0200', '%Y-%m-%d %H:%M:%S.%f %z')&gt;&gt;&gt; dt.strftime("%A, %dth of %B '%y, %I:%M%p %Z")"Thursday, 14th of May '15, 11:39PM UTC+02:00" When parsing, ‘%z’ also accepts ‘±HH:MM’. For abbreviated weekday and month use ‘%a’ and ‘%b’. Arithmetics1234&lt;TD&gt; = &lt;D/DT&gt; - &lt;D/DT&gt;&lt;D/DT&gt; = &lt;D/DT&gt; ± &lt;TD&gt;&lt;TD&gt; = &lt;TD&gt; ± &lt;TD&gt;&lt;TD&gt; = &lt;TD&gt; * &lt;real&gt; ArgumentsInside Function Call123&lt;function&gt;(&lt;positional_args&gt;) # f(0, 0)&lt;function&gt;(&lt;keyword_args&gt;) # f(x=0, y=0)&lt;function&gt;(&lt;positional_args&gt;, &lt;keyword_args&gt;) # f(0, y=0) Inside Function Definition123def f(&lt;nondefault_args&gt;): # def f(x, y):def f(&lt;default_args&gt;): # def f(x=0, y=0):def f(&lt;nondefault_args&gt;, &lt;default_args&gt;): # def f(x, y=0): Splat OperatorInside Function CallSplat expands a collection into positional arguments, while splatty-splat expands a dictionary into keyword arguments. 123args = (1, 2)kwargs = &#123;'x': 3, 'y': 4, 'z': 5&#125;func(*args, **kwargs) Is the same as:1func(1, 2, x=3, y=4, z=5) Inside Function DefinitionSplat combines zero or more positional arguments into a tuple, while splatty-splat combines zero or more keyword arguments into a dictionary. 1234def add(*a): return sum(a)&gt;&gt;&gt; add(1, 2, 3)6 Legal argument combinations:123456789101112131415def f(x, y, z): # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3) | f(1, 2, 3)def f(*, x, y, z): # f(x=1, y=2, z=3)def f(x, *, y, z): # f(x=1, y=2, z=3) | f(1, y=2, z=3)def f(x, y, *, z): # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3)def f(*args): # f(1, 2, 3)def f(x, *args): # f(1, 2, 3)def f(*args, z): # f(1, 2, z=3)def f(x, *args, z): # f(1, 2, z=3)def f(**kwargs): # f(x=1, y=2, z=3)def f(x, **kwargs): # f(x=1, y=2, z=3) | f(1, y=2, z=3)def f(*, x, **kwargs): # f(x=1, y=2, z=3)def f(*args, **kwargs): # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3) | f(1, 2, 3)def f(x, *args, **kwargs): # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3) | f(1, 2, 3)def f(*args, y, **kwargs): # f(x=1, y=2, z=3) | f(1, y=2, z=3)def f(x, *args, z, **kwargs): # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3) Other Uses12345&lt;list&gt; = [*&lt;collection&gt; [, ...]]&lt;set&gt; = &#123;*&lt;collection&gt; [, ...]&#125;&lt;tuple&gt; = (*&lt;collection&gt;, [...])&lt;dict&gt; = &#123;**&lt;dict&gt; [, ...]&#125;head, *body, tail = &lt;collection&gt; InlineLambda12&lt;function&gt; = lambda: &lt;return_value&gt;&lt;function&gt; = lambda &lt;argument_1&gt;, &lt;argument_2&gt;: &lt;return_value&gt; Comprehension12345&lt;list&gt; = [i+1 for i in range(10)] # [1, 2, ..., 10]&lt;set&gt; = &#123;i for i in range(10) if i &gt; 5&#125; # &#123;6, 7, 8, 9&#125;&lt;iter&gt; = (i+5 for i in range(10)) # (5, 6, ..., 14)&lt;dict&gt; = &#123;i: i*2 for i in range(10)&#125; # &#123;0: 0, 1: 2, ..., 9: 18&#125;out = [i+j for i in range(10) for j in range(10)] Is the same as:1234out = []for i in range(10): for j in range(10): out.append(i+j) Map, Filter, Reduce1234from functools import reduce&lt;iter&gt; = map(lambda x: x + 1, range(10)) # (1, 2, ..., 10)&lt;iter&gt; = filter(lambda x: x &gt; 5, range(10)) # (6, 7, 8, 9)&lt;obj&gt; = reduce(lambda out, x: out + x, range(10)) # 45 Any, All12&lt;bool&gt; = any(&lt;collection&gt;) # False if empty.&lt;bool&gt; = all(el[1] for el in &lt;collection&gt;) # True if empty. If - Else123&lt;expression_if_true&gt; if &lt;condition&gt; else &lt;expression_if_false&gt;&gt;&gt;&gt; [a if a else 'zero' for a in (0, 1, 0, 3)]['zero', 1, 'zero', 3] Namedtuple, Enum, Dataclass123456789from collections import namedtuplePoint = namedtuple('Point', 'x y')point = Point(0, 0)from enum import EnumDirection = Enum('Direction', 'n e s w')direction = Direction.nfrom dataclasses import make_dataclassCreature = make_dataclass('Creature', ['location', 'direction'])creature = Creature(Point(0, 0), Direction.n) ClosureWe have a closure in Python when: A nested function references a value of its enclosing function and then the enclosing function returns the nested function. 1234567def get_multiplier(a): def out(b): return a * b return out&gt;&gt;&gt; multiply_by_3 = get_multiplier(3)&gt;&gt;&gt; multiply_by_3(10)30 If multiple nested functions within enclosing function reference the same value, that value gets shared. To dynamically access function’s first free variable use ‘.closure[0].cell_contents’. Partial123456from functools import partial&lt;function&gt; = partial(&lt;function&gt; [, &lt;arg_1&gt;, &lt;arg_2&gt;, ...])&gt;&gt;&gt; import operator as op&gt;&gt;&gt; multiply_by_3 = partial(op.mul, 3)&gt;&gt;&gt; multiply_by_3(10)30 Partial is also useful in cases when a function needs to be passed as an argument, because it enables us to set its arguments beforehand. A few examples being ‘defaultdict()’, ‘iter(, to_exclusive)’ and dataclass’s ‘field(default_factory=)’. NonlocalIf variable is being assigned to anywhere in the scope, it is regarded as a local variable, unless it is declared as a ‘global’ or a ‘nonlocal’. 12345678910def get_counter(): i = 0 def out(): nonlocal i i += 1 return i return out&gt;&gt;&gt; counter = get_counter()&gt;&gt;&gt; counter(), counter(), counter()(1, 2, 3) DecoratorA decorator takes a function, adds some functionality and returns it. 123@decorator_namedef function_that_gets_passed_to_decorator(): ... Debugger ExampleDecorator that prints function’s name every time it gets called. 123456789101112from functools import wrapsdef debug(func): @wraps(func) def out(*args, **kwargs): print(func.__name__) return func(*args, **kwargs) return out@debugdef add(x, y): return x + y Wraps is a helper decorator that copies the metadata of a passed function (func) to the function it is wrapping (out). Without it ‘add.name‘ would return ‘out’. LRU CacheDecorator that caches function’s return values. All function’s arguments must be hashable. 12345from functools import lru_cache@lru_cache(maxsize=None)def fib(n): return n if n &lt; 2 else fib(n-2) + fib(n-1) Recursion depth is limited to 1000 by default. To increase it use ‘sys.setrecursionlimit()’. Parametrized DecoratorA decorator that accepts arguments and returns a normal decorator that accepts a function. 123456789101112131415from functools import wrapsdef debug(print_result=False): def decorator(func): @wraps(func) def out(*args, **kwargs): result = func(*args, **kwargs) print(func.__name__, result if print_result else '') return result return out return decorator@debug(print_result=True)def add(x, y): return x + y Class123456789101112class &lt;name&gt;: def __init__(self, a): self.a = a def __repr__(self): class_name = self.__class__.__name__ return f'&#123;class_name&#125;(&#123;self.a!r&#125;)' def __str__(self): return str(self.a) @classmethod def get_class_name(cls): return cls.__name__ Return value of repr() should be unambiguous and of str() readable. If only repr() is defined, it will also be used for str(). Str() use cases:12345print(&lt;el&gt;)print(f'&#123;&lt;el&gt;&#125;')raise Exception(&lt;el&gt;)loguru.logger.debug(&lt;el&gt;)csv.writer(&lt;file&gt;).writerow([&lt;el&gt;]) Repr() use cases:12345print([&lt;el&gt;])print(f'&#123;&lt;el&gt;!r&#125;')&gt;&gt;&gt; &lt;el&gt;loguru.logger.exception()Z = dataclasses.make_dataclass('Z', ['a']); print(Z(&lt;el&gt;)) Constructor Overloading123class &lt;name&gt;: def __init__(self, a=None): self.a = a Inheritance123456789class Person: def __init__(self, name, age): self.name = name self.age = ageclass Employee(Person): def __init__(self, name, age, staff_num): super().__init__(name, age) self.staff_num = staff_num Multiple Inheritance123class A: passclass B: passclass C(A, B): pass MRO determines the order in which parent classes are traversed when searching for a method: 12&gt;&gt;&gt; C.mro()[&lt;class 'C'&gt;, &lt;class 'A'&gt;, &lt;class 'B'&gt;, &lt;class 'object'&gt;] Property123456789101112class MyClass: @property def a(self): return self._a @a.setter def a(self, value): self._a = value&gt;&gt;&gt; el = MyClass()&gt;&gt;&gt; el.a = 123&gt;&gt;&gt; el.a123 DataclassDecorator that automatically generates init(), repr() and eq() special methods. 1234567from dataclasses import dataclass, field@dataclass(order=False, frozen=False)class &lt;class_name&gt;: &lt;attr_name_1&gt;: &lt;type&gt; &lt;attr_name_2&gt;: &lt;type&gt; = &lt;default_value&gt; &lt;attr_name_3&gt;: list/dict/set = field(default_factory=list/dict/set) Objects can be made sortable with ‘order=True’ and/or immutable and hashable with ‘frozen=True’. Function field() is needed because ‘: list = []’ would make a list that is shared among all instances. Default_factory can be any callable. Inline:1234from dataclasses import make_dataclass&lt;class&gt; = make_dataclass('&lt;class_name&gt;', &lt;coll_of_attribute_names&gt;)&lt;class&gt; = make_dataclass('&lt;class_name&gt;', &lt;coll_of_tuples&gt;)&lt;tuple&gt; = ('&lt;attr_name&gt;', &lt;type&gt; [, &lt;default_value&gt;]) SlotsMechanism that restricts objects to attributes listed in ‘slots’ and significantly reduces their memory footprint. 1234class MyClassWithSlots: __slots__ = ['a'] def __init__(self): self.a = 1 Copy123from copy import copy, deepcopy&lt;object&gt; = copy(&lt;object&gt;)&lt;object&gt; = deepcopy(&lt;object&gt;) Duck TypesA duck type is an implicit type that prescribes a set of special methods. Any object that has those methods defined is considered a member of that duck type. Comparable If eq() method is not overridden, it returns ‘id(self) == id(other)’, which is the same as ‘self is other’. That means all objects compare not equal by default. Only the left side object has eq() method called, unless it returns NotImplemented, in which case the right object is consulted. 1234567class MyComparable: def __init__(self, a): self.a = a def __eq__(self, other): if isinstance(other, type(self)): return self.a == other.a return NotImplemented Hashable Hashable object needs both hash() and eq() methods and its hash value should never change. Hashable objects that compare equal must have the same hash value, meaning default hash() that returns ‘id(self)’ will not do. That is why Python automatically makes classes unhashable if you only implement eq(). 123456789101112class MyHashable: def __init__(self, a): self._a = copy.deepcopy(a) @property def a(self): return self._a def __eq__(self, other): if isinstance(other, type(self)): return self.a == other.a return NotImplemented def __hash__(self): return hash(self.a) Sortable With total_ordering decorator you only need to provide eq() and one of lt(), gt(), le() or ge() special methods. 1234567891011121314from functools import total_ordering@total_orderingclass MySortable: def __init__(self, a): self.a = a def __eq__(self, other): if isinstance(other, type(self)): return self.a == other.a return NotImplemented def __lt__(self, other): if isinstance(other, type(self)): return self.a &lt; other.a return NotImplemented Iterator Any object that defines methods next() and iter() is an iterator. Next() should return next item or raise StopIteration. Iter() should return ‘self’. 1234567891011class Counter: def __init__(self): self.i = 0 def __next__(self): self.i += 1 return self.i def __iter__(self): return self&gt;&gt;&gt; counter = Counter()&gt;&gt;&gt; next(counter), next(counter), next(counter)(1, 2, 3) Python has many different iterator objects: Iterators returned by the iter() function, such as list_iterator and set_iterator. Objects returned by the itertools module, such as count, repeat and cycle. Generators returned by the generator functions and generator expressions. All file objects, etc. Callable All functions and classes have a call() method, hence are callable. When this cheatsheet uses ‘‘ for an argument, it actually means ‘‘. 123456789class Counter: def __init__(self): self.i = 0 def __call__(self): self.i += 1 return self.i&gt;&gt;&gt; counter = Counter()&gt;&gt;&gt; counter(), counter(), counter()(1, 2, 3) Context Manager Enter() should lock the resources and return an object. Exit() should release the resources. 12345678910111213class MyOpen(): def __init__(self, filename): self.filename = filename def __enter__(self): self.file = open(self.filename) return self.file def __exit__(self, *args): self.file.close()&gt;&gt;&gt; with open('test.txt', 'w') as file:... file.write('Hello World!')&gt;&gt;&gt; with MyOpen('test.txt') as file:... print(file.read())Hello World! Iterable Duck TypesIterable Only required method is iter(). It should return an iterator of object’s items. Contains() automatically works on any object that has iter() defined. 1234567891011class MyIterable: def __init__(self, a): self.a = a def __iter__(self): for el in self.a: yield el&gt;&gt;&gt; z = MyIterable([1, 2, 3])&gt;&gt;&gt; iter(z)&lt;generator object MyIterable.__iter__&gt;&gt;&gt;&gt; 1 in zTrue Collection Only required methods are iter() and len(). This cheatsheet actually means ‘‘ when it uses ‘‘. I chose not to use the name ‘iterable’ because it sounds scarier and more vague than ‘collection’. 123456789class MyCollection: def __init__(self, a): self.a = a def __iter__(self): return iter(self.a) def __contains__(self, el): return el in self.a def __len__(self): return len(self.a) Sequence Only required methods are len() and getitem(). Getitem() should return an item at index or raise IndexError. Iter() and contains() automatically work on any object that has getitem() defined. Reversed() automatically works on any object that has getitem() and len() defined. 12345678910111213class MySequence: def __init__(self, a): self.a = a def __iter__(self): return iter(self.a) def __contains__(self, el): return el in self.a def __len__(self): return len(self.a) def __getitem__(self, i): return self.a[i] def __reversed__(self): return reversed(self.a) Collections.abc.Sequence It’s a richer interface than the basic sequence. Extending it generates iter(), contains(), reversed(), index(), and count(). Unlike ‘abc.Iterable’ and ‘abc.Collection’, it is not a duck type. That is why ‘issubclass(MySequence, collections.abc.Sequence)’ would return False even if MySequence had all the methods defined. 1234567class MyAbcSequence(collections.abc.Sequence): def __init__(self, a): self.a = a def __len__(self): return len(self.a) def __getitem__(self, i): return self.a[i] Table of required and available special methods:1234567891011+------------+----------+------------+----------+--------------+| | Iterable | Collection | Sequence | abc.Sequence |+------------+----------+------------+----------+--------------+| iter() | REQ | REQ | yes | yes || contains() | yes | yes | yes | yes || len() | | REQ | REQ | REQ || getitem() | | | REQ | REQ || reversed() | | | yes | yes || index() | | | | yes || count() | | | | yes |+------------+----------+------------+----------+--------------+ Other ABCs that generate missing methods are: MutableSequence, Set, MutableSet, Mapping and MutableMapping. Names of their required methods are stored in ‘.abstractmethods‘. Enum12345678910from enum import Enum, autoclass &lt;enum_name&gt;(Enum): &lt;member_name_1&gt; = &lt;value_1&gt; &lt;member_name_2&gt; = &lt;value_2_a&gt;, &lt;value_2_b&gt; &lt;member_name_3&gt; = auto() @classmethod def get_member_names(cls): return [a.name for a in cls.__members__.values()] If there are no numeric values before auto(), it returns 1. Otherwise it returns an increment of last numeric value. 123456789&lt;member&gt; = &lt;enum&gt;.&lt;member_name&gt; # Returns a member.&lt;member&gt; = &lt;enum&gt;['&lt;member_name&gt;'] # Returns a member or raises KeyError.&lt;member&gt; = &lt;enum&gt;(&lt;value&gt;) # Returns a member or raises ValueError.name = &lt;member&gt;.namevalue = &lt;member&gt;.valuelist_of_members = list(&lt;enum&gt;)member_names = [a.name for a in &lt;enum&gt;]member_values = [a.value for a in &lt;enum&gt;]random_member = random.choice(list(&lt;enum&gt;)) Inline123Cutlery = Enum('Cutlery', ['fork', 'knife', 'spoon'])Cutlery = Enum('Cutlery', 'fork knife spoon')Cutlery = Enum('Cutlery', &#123;'fork': 1, 'knife': 2, 'spoon': 3&#125;) Functions can not be values, so they must be wrapped:123from functools import partialLogicOp = Enum('LogicOp', &#123;'AND': partial(lambda l, r: l and r), 'OR' : partial(lambda l, r: l or r)&#125;) Another solution in this particular case, is to use ‘and_’ and ‘or_’ functions from module operator. ExceptionsBasic Example1234try: &lt;code&gt;except &lt;exception&gt;: &lt;code&gt; Complex Example12345678910try: &lt;code_1&gt;except &lt;exception_a&gt;: &lt;code_2_a&gt;except &lt;exception_b&gt;: &lt;code_2_b&gt;else: &lt;code_2_c&gt;finally: &lt;code_3&gt; Catching Exceptions1234except &lt;exception&gt;:except &lt;exception&gt; as &lt;name&gt;:except (&lt;exception&gt;, ...):except (&lt;exception&gt;, ...) as &lt;name&gt;: Also catches subclasses of the exception. Raising Exceptions1234raise &lt;exception&gt;raise &lt;exception&gt;()raise &lt;exception&gt;(&lt;el&gt;)raise &lt;exception&gt;(&lt;el&gt;, ...) Useful built-in exceptions:123raise ValueError('Argument is of right type but inappropriate value!')raise TypeError('Argument is of wrong type!')raise RuntimeError('None of above!') Re-raising caught exception:123except &lt;exception&gt;: &lt;code&gt; raise Common Built-in Exceptions1234567891011121314151617181920BaseException +-- SystemExit # Raised by the sys.exit() function. +-- KeyboardInterrupt # Raised when the user hits the interrupt key. +-- Exception # User-defined exceptions should be derived from this class. +-- StopIteration # Raised by next() when run on an empty iterator. +-- ArithmeticError # Base class for arithmetic errors. | +-- ZeroDivisionError # Raised when dividing by zero. +-- AttributeError # Raised when an attribute is missing. +-- EOFError # Raised by input() when it hits end-of-file condition. +-- LookupError # Raised when a look-up on a sequence or dict fails. | +-- IndexError # Raised when a sequence index is out of range. | +-- KeyError # Raised when a dictionary key is not found. +-- NameError # Raised when a variable name is not found. +-- OSError # Failures such as “file not found” or “disk full”. | +-- FileNotFoundError # When a file or directory is requested but doesn't exist. +-- RuntimeError # Raised by errors that don't fall in other categories. | +-- RecursionError # Raised when the the maximum recursion depth is exceeded. +-- TypeError # Raised when an argument is of wrong type. +-- ValueError # When an argument is of right type but inappropriate value. +-- UnicodeError # Raised when encoding/decoding strings from/to bytes fails. Collections and their exceptions:12345678+-----------+------------+----------+----------+| | list | dict | set |+-----------+------------+----------+----------+| getitem() | IndexError | KeyError | || pop() | IndexError | KeyError | KeyError || remove() | ValueError | | KeyError || index() | ValueError | | |+-----------+------------+----------+----------+ User-defined Exceptions12345class MyError(Exception): passclass MyInputError(MyError): pass Print1print(&lt;el_1&gt;, ..., sep=' ', end='\n', file=sys.stdout, flush=False) Use ‘file=sys.stderr’ for errors. Use ‘flush=True’ to forcibly flush the stream. Pretty Print12from pprint import pprintpprint(&lt;collection&gt;, width=80, depth=None) Levels deeper than ‘depth’ get replaced by ‘…’. InputReads a line from user input or pipe if present. 1&lt;str&gt; = input(prompt=None) Trailing newline gets stripped. Prompt string is printed to the standard output before reading input. Raises EOFError when user hits EOF or input stream gets exhausted. Command Line Arguments123import sysscript_name = sys.argv[0]arguments = sys.argv[1:] Argparse123456789from argparse import ArgumentParser, FileTypep = ArgumentParser(description=&lt;str&gt;)p.add_argument('-&lt;short_name&gt;', '--&lt;name&gt;', action='store_true') # Flagp.add_argument('-&lt;short_name&gt;', '--&lt;name&gt;', type=&lt;type&gt;) # Optionp.add_argument('&lt;name&gt;', type=&lt;type&gt;, nargs=1) # First argumentp.add_argument('&lt;name&gt;', type=&lt;type&gt;, nargs='+') # Remaining argumentsp.add_argument('&lt;name&gt;', type=&lt;type&gt;, nargs='*') # Optional argumentsargs = p.parse_args() # Exits on error.value = args.&lt;name&gt; Use ‘help=‘ to set argument description. Use ‘default=‘ to set the default value. Use ‘type=FileType()’ for files. OpenOpens the file and returns a corresponding file object. 1&lt;file&gt; = open('&lt;path&gt;', mode='r', encoding=None, newline=None) ‘encoding=None’ means default encoding is used, which is platform dependent. Best practice is to use ‘encoding=”utf-8”‘ whenever possible. ‘newline=None’ means all different end of line combinations are converted to ‘\n’ on read, while on write all ‘\n’ characters are converted to system’s default line separator. ‘newline=””‘ means no conversions take place, but input is still broken into chunks by readline() and readlines() on either ‘\n’, ‘\r’ or ‘\r\n’. Modes ‘r’ - Read (default). ‘w’ - Write (truncate). ‘x’ - Write or fail if the file already exists. ‘a’ - Append. ‘w+’ - Read and write (truncate). ‘r+’ - Read and write from the start. ‘a+’ - Read and write from the end. ‘t’ - Text mode (default). ‘b’ - Binary mode. Exceptions ‘FileNotFoundError’ can be risen when reading with ‘r’ or ‘r+’. ‘FileExistsError’ can be risen when writing with ‘x’. ‘IsADirectoryError’ and ‘PermissionError’ can be risen by any. ‘OSError’ is the parent class of all listed exceptions. File1234567891011&lt;file&gt;.seek(0) # Moves to the start of the file.&lt;file&gt;.seek(offset) # Moves 'offset' chars/bytes from the start.&lt;file&gt;.seek(0, 2) # Moves to the end of the file.&lt;bin_file&gt;.seek(±offset, &lt;anchor&gt;) # Anchor: 0 start, 1 current pos., 2 end.&lt;str/bytes&gt; = &lt;file&gt;.read(size=-1) # Reads 'size' chars/bytes or until EOF.&lt;str/bytes&gt; = &lt;file&gt;.readline() # Returns a line or empty string on EOF.&lt;list&gt; = &lt;file&gt;.readlines() # Returns a list of remaining lines.&lt;str/bytes&gt; = next(&lt;file&gt;) # Returns a line using buffer. Do not mix.&lt;file&gt;.write(&lt;str/bytes&gt;) # Writes a string or bytes object.&lt;file&gt;.writelines(&lt;coll.&gt;) # Writes a coll. of strings or bytes objects.&lt;file&gt;.flush() # Flushes write buffer. Methods do not add or strip trailing newlines, even writelines(). Read Text from File123def read_file(filename): with open(filename, encoding='utf-8') as file: return file.readlines() Write Text to File123def write_to_file(filename, text): with open(filename, 'w', encoding='utf-8') as file: file.write(text) Path1234567from os import path, listdirfrom glob import glob&lt;bool&gt; = path.exists('&lt;path&gt;')&lt;bool&gt; = path.isfile('&lt;path&gt;')&lt;bool&gt; = path.isdir('&lt;path&gt;')&lt;list&gt; = listdir('&lt;path&gt;') # List of filenames located at path.&lt;list&gt; = glob('&lt;pattern&gt;') # Filenames matching the wildcard pattern. Pathlib1234567891011121314151617from pathlib import Pathcwd = Path()&lt;Path&gt; = Path('&lt;path&gt;' [, '&lt;path&gt;', &lt;Path&gt;, ...])&lt;Path&gt; = &lt;Path&gt; / '&lt;dir&gt;' / '&lt;file&gt;'&lt;bool&gt; = &lt;Path&gt;.exists()&lt;bool&gt; = &lt;Path&gt;.is_file()&lt;bool&gt; = &lt;Path&gt;.is_dir()&lt;iter&gt; = &lt;Path&gt;.iterdir() # Returns dir contents as Path objects.&lt;iter&gt; = &lt;Path&gt;.glob('&lt;pattern&gt;') # Returns Paths matching the wildcard pattern.&lt;str&gt; = str(&lt;Path&gt;) # Path as a string.&lt;str&gt; = &lt;Path&gt;.name # Final component.&lt;str&gt; = &lt;Path&gt;.stem # Final component without extension.&lt;str&gt; = &lt;Path&gt;.suffix # Final component's extension.&lt;tup.&gt; = &lt;Path&gt;.parts # All components as strings.&lt;Path&gt; = &lt;Path&gt;.resolve() # Returns absolute path without symlinks.&lt;Path&gt; = &lt;Path&gt;.parent # Returns path without final component.&lt;file&gt; = open(&lt;Path&gt;) # Opens the file and returns a file object. OS CommandsFiles and Directories Paths can be either strings, Paths, or DirEntry objects. Functions report OS related errors by raising either OSError or one of its subclasses. 123456789101112import os, shutilos.chdir(&lt;path&gt;) # Changes current working directory.os.mkdir(&lt;path&gt;, mode=0o777) # Creates a directory.os.rename(from, to) # Renames the file or directory.os.replace(from, to) # Same, but overwrites 'to' if it exists.os.remove(&lt;path&gt;) # Deletes the file.os.rmdir(&lt;path&gt;) # Deletes empty directory.shutil.rmtree(&lt;path&gt;) # Deletes the entire directory tree.shutil.copy(from, to) # Copies the file.shutil.copytree(from, to) # Copies the entire directory tree.&lt;str&gt; = os.getcwd() # Returns the current working directory.&lt;iter&gt; = os.scandir(path='.') # Returns os.DirEntry objects located at path. DirEntry:123456&lt;bool&gt; = &lt;DirEntry&gt;.is_file()&lt;bool&gt; = &lt;DirEntry&gt;.is_dir()&lt;str&gt; = &lt;DirEntry&gt;.path # Path as a string.&lt;str&gt; = &lt;DirEntry&gt;.name # Final component.&lt;Path&gt; = Path(&lt;DirEntry&gt;) # Path object.&lt;file&gt; = open(&lt;DirEntry&gt;) # File object. Shell Commands12import os&lt;str&gt; = os.popen('&lt;shell_command&gt;').read() Using subprocess:123456&gt;&gt;&gt; import subprocess, shlex&gt;&gt;&gt; a = subprocess.run(shlex.split('ls -a'), stdout=subprocess.PIPE)&gt;&gt;&gt; a.stdoutb'.\n..\nfile1.txt\nfile2.txt\n'&gt;&gt;&gt; a.returncode0 JSONText file format for storing collections of strings and numbers. 123import json&lt;str&gt; = json.dumps(&lt;object&gt;, ensure_ascii=True, indent=None)&lt;object&gt; = json.loads(&lt;str&gt;) Read Object from JSON File123def read_json_file(filename): with open(filename, encoding='utf-8') as file: return json.load(file) Write Object to JSON File123def write_to_json_file(filename, an_object): with open(filename, 'w', encoding='utf-8') as file: json.dump(an_object, file, ensure_ascii=False, indent=2) PickleBinary file format for storing objects. 123import pickle&lt;bytes&gt; = pickle.dumps(&lt;object&gt;)&lt;object&gt; = pickle.loads(&lt;bytes&gt;) Read Object from File123def read_pickle_file(filename): with open(filename, 'rb') as file: return pickle.load(file) Write Object to File123def write_to_pickle_file(filename, an_object): with open(filename, 'wb') as file: pickle.dump(an_object, file) CSVText file format for storing spreadsheets. 1import csv Read123&lt;reader&gt; = csv.reader(&lt;file&gt;, dialect='excel', delimiter=',')&lt;list&gt; = next(&lt;reader&gt;) # Returns next row as a list of strings.&lt;list&gt; = list(&lt;reader&gt;) # Returns list of remaining rows. File must be opened with ‘newline=””‘ argument, or newlines embedded inside quoted fields will not be interpreted correctly! Write123&lt;writer&gt; = csv.writer(&lt;file&gt;, dialect='excel', delimiter=',')&lt;writer&gt;.writerow(&lt;collection&gt;) # Encodes objects using `str(&lt;el&gt;)`.&lt;writer&gt;.writerows(&lt;coll_of_coll&gt;) # Appends multiple rows. File must be opened with ‘newline=””‘ argument, or an extra ‘\r’ will be added on platforms that use ‘\r\n’ linendings! Parameters ‘dialect’ - Master parameter that sets the default values. ‘delimiter’ - A one-character string used to separate fields. ‘quotechar’ - Character for quoting fields that contain special characters. ‘doublequote’ - Whether quotechars inside fields get doubled or escaped. ‘skipinitialspace’ - Whether whitespace after delimiter gets stripped. ‘lineterminator’ - How does writer terminate lines. ‘quoting’ - Controls the amount of quoting: 0 - as necessary, 1 - all. ‘escapechar’ - Character for escaping ‘quotechar’ if ‘doublequote’ is false. Dialects1234567891011+------------------+-----------+-----------+--------------+| | excel | excel_tab | unix_dialect |+------------------+-----------+-----------+--------------+| delimiter | ',' | '\t' | ',' || quotechar | '"' | '"' | '"' || doublequote | True | True | True || skipinitialspace | False | False | False || lineterminator | '\r\n' | '\r\n' | '\n' || quoting | 0 | 0 | 1 || escapechar | None | None | None |+------------------+-----------+-----------+--------------+ Read Rows from CSV File123def read_csv_file(filename): with open(filename, encoding='utf-8', newline='') as file: return list(csv.reader(file)) Write Rows to CSV File1234def write_to_csv_file(filename, rows): with open(filename, 'w', encoding='utf-8', newline='') as file: writer = csv.writer(file) writer.writerows(rows) SQLiteServer-less database engine that stores each database into separate file. ConnectOpens a connection to the database file. Creates a new file if path doesn’t exist. 1234import sqlite3db = sqlite3.connect('&lt;path&gt;') # Also ':memory:'....db.close() ReadReturned values can be of type str, int, float, bytes or None. 123&lt;cursor&gt; = db.execute('&lt;query&gt;') # Can raise sqlite3.OperationalError.&lt;tuple&gt; = &lt;cursor&gt;.fetchone() # Returns next row. Also next(&lt;cursor&gt;).&lt;list&gt; = &lt;cursor&gt;.fetchall() # Returns remaining rows. Write12db.execute('&lt;query&gt;')db.commit() Or:12with db: db.execute('&lt;query&gt;') Placeholders Passed values can be of type str, int, float, bytes, None, bool, datetime.date or datetime.datetme. Bools will be stored and returned as ints and dates as ISO formatted strings. 123db.execute('&lt;query&gt;', &lt;list/tuple&gt;) # Replaces '?'s in query with values.db.execute('&lt;query&gt;', &lt;dict/namedtuple&gt;) # Replaces ':&lt;key&gt;'s with values.db.executemany('&lt;query&gt;', &lt;coll_of_above&gt;) # Runs execute() many times. ExampleIn this example values are not actually saved because ‘db.commit()’ is omitted! 12345&gt;&gt;&gt; db = sqlite3.connect('test.db')&gt;&gt;&gt; db.execute('create table t (a, b, c)')&gt;&gt;&gt; db.execute('insert into t values (1, 2, 3)')&gt;&gt;&gt; db.execute('select * from t').fetchall()[(1, 2, 3)] MySQLHas a very similar interface, with differences listed below. 1234567# $ pip3 install mysql-connectorfrom mysql import connectordb = connector.connect(host=&lt;str&gt;, user=&lt;str&gt;, password=&lt;str&gt;, database=&lt;str&gt;)&lt;cursor&gt; = db.cursor()&lt;cursor&gt;.execute('&lt;query&gt;') # Only cursor has execute method.&lt;cursor&gt;.execute('&lt;query&gt;', &lt;list/tuple&gt;) # Replaces '%s's in query with values.&lt;cursor&gt;.execute('&lt;query&gt;', &lt;dict/namedtuple&gt;) # Replaces '%(&lt;key&gt;)s's with values. BytesBytes object is an immutable sequence of single bytes. Mutable version is called bytearray. 1234&lt;bytes&gt; = b'&lt;str&gt;' # Only accepts ASCII characters and \x00 - \xff.&lt;int&gt; = &lt;bytes&gt;[&lt;index&gt;] # Returns int in range from 0 to 255.&lt;bytes&gt; = &lt;bytes&gt;[&lt;slice&gt;] # Returns bytes even if it has only one element.&lt;bytes&gt; = &lt;bytes&gt;.join(&lt;coll_of_bytes&gt;) # Joins elements using bytes object as separator. Encode1234&lt;bytes&gt; = bytes(&lt;coll_of_ints&gt;) # Ints must be in range from 0 to 255.&lt;bytes&gt; = bytes(&lt;str&gt;, 'utf-8') # Or: &lt;str&gt;.encode('utf-8')&lt;bytes&gt; = &lt;int&gt;.to_bytes(n_bytes, byteorder='big|little', signed=False)&lt;bytes&gt; = bytes.fromhex('&lt;hex&gt;') Decode1234&lt;list&gt; = list(&lt;bytes&gt;) # Returns ints in range from 0 to 255.&lt;str&gt; = str(&lt;bytes&gt;, 'utf-8') # Or: &lt;bytes&gt;.decode('utf-8')&lt;int&gt; = int.from_bytes(&lt;bytes&gt;, byteorder='big|little', signed=False)'&lt;hex&gt;' = &lt;bytes&gt;.hex() Read Bytes from File123def read_bytes(filename): with open(filename, 'rb') as file: return file.read() Write Bytes to File123def write_bytes(filename, bytes_obj): with open(filename, 'wb') as file: file.write(bytes_obj) Struct Module that performs conversions between a sequence of numbers and a bytes object. Machine’s native type sizes and byte order are used by default. 1234from struct import pack, unpack, iter_unpack&lt;bytes&gt; = pack('&lt;format&gt;', &lt;num_1&gt; [, &lt;num_2&gt;, ...])&lt;tuple&gt; = unpack('&lt;format&gt;', &lt;bytes&gt;)&lt;tuples&gt; = iter_unpack('&lt;format&gt;', &lt;bytes&gt;) Example1234&gt;&gt;&gt; pack('&gt;hhl', 1, 2, 3)b'\x00\x01\x00\x02\x00\x00\x00\x03'&gt;&gt;&gt; unpack('&gt;hhl', b'\x00\x01\x00\x02\x00\x00\x00\x03')(1, 2, 3) FormatFor standard sizes start format string with: ‘=’ - native byte order ‘&lt;’ - little-endian ‘&gt;’ - big-endian Integer types. Use capital letter for unsigned type. Standard sizes are in brackets: ‘x’ - pad byte ‘b’ - char (1) ‘h’ - short (2) ‘i’ - int (4) ‘l’ - long (4) ‘q’ - long long (8) Floating point types: ‘f’ - float (4) ‘d’ - double (8) ArrayList that can only hold numbers of a predefined type. Available types and their sizes in bytes are listed above. 1234from array import array&lt;array&gt; = array('&lt;typecode&gt;', &lt;collection&gt;) # Array from coll. of numbers.&lt;array&gt; = array('&lt;typecode&gt;', &lt;bytes&gt;) # Array from bytes object.&lt;bytes&gt; = &lt;array&gt;.tobytes() Memory View A sequence object that points to the memory of another object. Each element can reference a single or multiple consecutive bytes, depending on format. Order and number of elements can be changed with slicing. 123456789101112&lt;mview&gt; = memoryview(&lt;bytes/bytearray/array&gt;)&lt;num&gt; = &lt;mview&gt;[&lt;index&gt;] # Returns an int or a float.&lt;mview&gt; = &lt;mview&gt;[&lt;slice&gt;] # Mview with rearranged elements.&lt;mview&gt; = &lt;mview&gt;.cast('&lt;typecode&gt;') # Casts memoryview to the new format.&lt;mview&gt;.release() # Releases the object's memory buffer.&lt;bin_file&gt;.write(&lt;mview&gt;) # Appends mview to the binary file.&lt;bytes&gt; = bytes(&lt;mview&gt;) # Creates a new bytes object.&lt;bytes&gt; = &lt;bytes&gt;.join(&lt;coll_of_mviews&gt;) # Joins mviews using bytes object as sep.&lt;list&gt; = list(&lt;mview&gt;) # Returns list of ints or floats.&lt;str&gt; = str(&lt;mview&gt;, 'utf-8')&lt;int&gt; = int.from_bytes(&lt;mview&gt;, byteorder='big|little', signed=False)'&lt;hex&gt;' = &lt;mview&gt;.hex() DequeA thread-safe list with efficient appends and pops from either side. Pronounced “deck”. 123456from collections import deque&lt;deque&gt; = deque(&lt;collection&gt;, maxlen=None)&lt;deque&gt;.appendleft(&lt;el&gt;) # Opposite element is dropped if full.&lt;el&gt; = &lt;deque&gt;.popleft() # Raises IndexError if empty.&lt;deque&gt;.extendleft(&lt;collection&gt;) # Collection gets reversed.&lt;deque&gt;.rotate(n=1) # Rotates elements to the right. Threading CPython interpreter can only run a single thread at a time. That is why using multiple threads won’t result in a faster execution, unless there is an I/O operation in the thread. 1from threading import Thread, RLock Thread12345thread = Thread(target=&lt;function&gt;, args=(&lt;first_arg&gt;, ))thread.start()...&lt;bool&gt; = thread.is_alive() # Checks if thread has finished executing.thread.join() # Waits for thread to finish. Use ‘kwargs=‘ to pass keyword arguments to the function. Use ‘daemon=True’, or the program will not be able to exit while the thread is alive. Lock1234lock = RLock()lock.acquire() # Waits for lock to be available....lock.release() Or:123lock = RLock()with lock: ... Thread Pool Executor1234567from concurrent.futures import ThreadPoolExecutorwith ThreadPoolExecutor(max_workers=None) as executor: &lt;iter&gt; = executor.map(lambda x: x + 1, range(3)) # (1, 2, 3) &lt;iter&gt; = executor.map(lambda x, y: x + y, 'abc', '123') # ('a1', 'b2', 'c3') &lt;Future&gt; = executor.submit(&lt;function&gt; [, &lt;arg_1&gt;, ...])&lt;bool&gt; = &lt;Future&gt;.done() # Checks if thread has finished executing.&lt;obj&gt; = &lt;Future&gt;.result() # Waits for thread to finish and returns result. QueueA thread-safe FIFO queue. For LIFO queue use LifoQueue. 123456from queue import Queue&lt;Queue&gt; = Queue(maxsize=0)&lt;Queue&gt;.put(&lt;el&gt;) # Blocks until queue stops being full.&lt;Queue&gt;.put_nowait(&lt;el&gt;) # Raises queue.Full exception if full.&lt;el&gt; = &lt;Queue&gt;.get() # Blocks until queue stops being empty.&lt;el&gt; = &lt;Queue&gt;.get_nowait() # Raises _queue.Empty exception if empty. OperatorModule of functions that provide the functionality of operators. 12345678910from operator import add, sub, mul, truediv, floordiv, mod, pow, neg, absfrom operator import eq, ne, lt, le, gt, gefrom operator import and_, or_, not_from operator import itemgetter, attrgetter, methodcallerimport operator as opsorted_by_second = sorted(&lt;collection&gt;, key=op.itemgetter(1))sorted_by_both = sorted(&lt;collection&gt;, key=op.itemgetter(1, 0))product_of_elems = functools.reduce(op.mul, &lt;collection&gt;)LogicOp = enum.Enum('LogicOp', &#123;'AND': op.and_, 'OR' : op.or_&#125;)last_el = op.methodcaller('pop')(&lt;list&gt;) IntrospectionInspecting code at runtime. Variables123&lt;list&gt; = dir() # Names of variables in current scope.&lt;dict&gt; = locals() # Dict of local variables. Also vars().&lt;dict&gt; = globals() # Dict of global variables. Attributes1234&lt;dict&gt; = vars(&lt;object&gt;)&lt;bool&gt; = hasattr(&lt;object&gt;, '&lt;attr_name&gt;')value = getattr(&lt;object&gt;, '&lt;attr_name&gt;')setattr(&lt;object&gt;, '&lt;attr_name&gt;', value) Parameters1234from inspect import signature&lt;sig&gt; = signature(&lt;function&gt;)no_of_params = len(&lt;sig&gt;.parameters)param_names = list(&lt;sig&gt;.parameters.keys()) MetaprogramingCode that generates code. TypeType is the root class. If only passed an object it returns its type (class). Otherwise it creates a new class. 123&lt;class&gt; = type(&lt;class_name&gt;, &lt;parents_tuple&gt;, &lt;attributes_dict&gt;)&gt;&gt;&gt; Z = type('Z', (), &#123;'a': 'abcde', 'b': 12345&#125;)&gt;&gt;&gt; z = Z() Meta ClassClass that creates classes. 123def my_meta_class(name, parents, attrs): attrs['a'] = 'abcde' return type(name, parents, attrs) Or:1234class MyMetaClass(type): def __new__(cls, name, parents, attrs): attrs['a'] = 'abcde' return type.__new__(cls, name, parents, attrs) New() is a class method that gets called before init(). If it returns an instance of its class, then that instance gets passed to init() as a ‘self’ argument. It receives the same arguments as init(), except for the first one that specifies the desired class of returned instance (MyMetaClass in our case). New() can also be called directly, usually from a new() method of a child class (def __new__(cls): return super().__new__(cls)), in which case init() is not called. Metaclass AttributeRight before a class is created it checks if it has a ‘metaclass’ attribute defined. If not, it recursively checks if any of his parents has it defined and eventually comes to type(). 1234class MyClass(metaclass=MyMetaClass): b = 12345&gt;&gt;&gt; MyClass.a, MyClass.b('abcde', 12345) Type Diagram1234567891011type(MyClass) == MyMetaClass # MyClass is an instance of MyMetaClass.type(MyMetaClass) == type # MyMetaClass is an instance of type.+---------+-------------+| Classes | Metaclasses |+---------+-------------|| MyClass &gt; MyMetaClass || | v || object ---&gt; type &lt;+ || | ^ +---+ || str -------+ |+---------+-------------+ Inheritance Diagram1234567891011MyClass.__base__ == object # MyClass is a subclass of object.MyMetaClass.__base__ == type # MyMetaClass is a subclass of type.+---------+-------------+| Classes | Metaclasses |+---------+-------------|| MyClass | MyMetaClass || v | v || object &lt;--- type || ^ | || str | |+---------+-------------+ Eval1234567&gt;&gt;&gt; from ast import literal_eval&gt;&gt;&gt; literal_eval('1 + 2')3&gt;&gt;&gt; literal_eval('[1, 2, 3]')[1, 2, 3]&gt;&gt;&gt; literal_eval('abs(1)')ValueError: malformed node or string Coroutine Any function that contains a ‘(yield)’ expression returns a coroutine. Coroutines are similar to iterators, but data needs to be pulled out of an iterator by calling ‘next()’, while we push data into the coroutine by calling ‘.send()’. Coroutines provide more powerful data routing possibilities than iterators. Helper Decorator All coroutines must first be “primed” by calling ‘next()’. Remembering to call next() is easy to forget. Solved by wrapping coroutine functions with the following decorator: 123456def coroutine(func): def out(*args, **kwargs): cr = func(*args, **kwargs) next(cr) return cr return out Pipeline Example123456789101112131415161718def reader(target): for i in range(10): target.send(i) target.close()@coroutinedef adder(target): while True: value = (yield) target.send(value + 100)@coroutinedef printer(): while True: value = (yield) print(value, end=' ')&gt;&gt;&gt; reader(adder(printer()))100 101 102 103 104 105 106 107 108 109 LibrariesProgress Bar12345# $ pip3 install tqdmfrom tqdm import tqdmfrom time import sleepfor el in tqdm([1, 2, 3]): sleep(0.2) Plot12345678# $ pip3 install matplotlibfrom matplotlib import pyplotpyplot.plot(&lt;y_data&gt; [, label=&lt;str&gt;])pyplot.plot(&lt;x_data&gt;, &lt;y_data&gt;)pyplot.legend() # Adds a legend.pyplot.savefig(&lt;filename&gt;) # Saves the figure.pyplot.show() # Displays the figure.pyplot.clf() # Clears the figure. TablePrints a CSV file as an ASCII table:1234567# $ pip3 install tabulateimport csv, tabulatewith open('test.csv', encoding='utf-8', newline='') as file: rows = csv.reader(file) header = [a.title() for a in next(rows)] table = tabulate.tabulate(rows, header) print(table) CursesClears the terminal, prints a message and waits for an ESC key press:12345678910111213141516171819202122from curses import wrapper, curs_set, asciifrom curses import KEY_UP, KEY_RIGHT, KEY_DOWN, KEY_LEFTdef main(): wrapper(draw)def draw(screen): curs_set(0) # Makes cursor invisible. screen.nodelay(True) # Makes getch() non-blocking. screen.clear() screen.addstr(0, 0, 'Press ESC to quit.') while screen.getch() != ascii.ESC: passdef get_border(screen): from collections import namedtuple P = namedtuple('P', 'x y') height, width = screen.getmaxyx() return P(width - 1, height - 1)if __name__ == '__main__': main() Logging12345# $ pip3 install logurufrom loguru import loggerlogger.add('debug_&#123;time&#125;.log', colorize=True) # Connects a log file.logger.add('error_&#123;time&#125;.log', level='ERROR') # Another file for errors or higher.logger.&lt;level&gt;('A logging message.') Levels: ‘debug’, ‘info’, ‘success’, ‘warning’, ‘error’, ‘critical’. ExceptionsException description, stack trace and values of variables are appended automatically. 1234try: ...except &lt;exception&gt;: logger.exception('An error happened.') RotationArgument that sets a condition when a new log file is created. 1rotation=&lt;int&gt;|&lt;datetime.timedelta&gt;|&lt;datetime.time&gt;|&lt;str&gt; ‘‘ - Max file size in bytes. ‘‘ - Max age of a file. ‘‘ - Time of day. ‘‘ - Any of above as a string: ‘100 MB’, ‘1 month’, ‘monday at 12:00’, … RetentionSets a condition which old log files get deleted. 1retention=&lt;int&gt;|&lt;datetime.timedelta&gt;|&lt;str&gt; ‘‘ - Max number of files. ‘‘ - Max age of a file. ‘‘ - Max age as a string: ‘1 week, 3 days’, ‘2 months’, … ScrapingScrapes Python’s URL, version number and logo from Wikipedia page:123456789101112131415# $ pip3 install requests beautifulsoup4import requestsfrom bs4 import BeautifulSoupurl = 'https://en.wikipedia.org/wiki/Python_(programming_language)'html = requests.get(url).textdoc = BeautifulSoup(html, 'html.parser')table = doc.find('table', class_='infobox vevent')rows = table.find_all('tr')link = rows[11].find('a')['href']ver = rows[6].find('div').text.split()[0]url_i = rows[0].find('img')['src']image = requests.get(f'https:&#123;url_i&#125;').contentwith open('test.png', 'wb') as file: file.write(image)print(link, ver) Web123# $ pip3 install bottlefrom bottle import run, route, static_file, template, post, request, responseimport json Run12run(host='localhost', port=8080)run(host='0.0.0.0', port=80, server='cherrypy') Static Request123@route('/img/&lt;image&gt;')def send_image(image): return static_file(image, 'img_dir/', mimetype='image/png') Dynamic Request123@route('/&lt;sport&gt;')def send_page(sport): return template('&lt;h1&gt;&#123;&#123;title&#125;&#125;&lt;/h1&gt;', title=sport) REST Request1234567@post('/odds/&lt;sport&gt;')def odds_handler(sport): team = request.forms.get('team') home_odds, away_odds = 2.44, 3.29 response.headers['Content-Type'] = 'application/json' response.headers['Cache-Control'] = 'no-cache' return json.dumps([team, home_odds, away_odds]) Test:1234567# $ pip3 install requests&gt;&gt;&gt; import requests&gt;&gt;&gt; url = 'http://localhost:8080/odds/football'&gt;&gt;&gt; data = &#123;'team': 'arsenal f.c.'&#125;&gt;&gt;&gt; response = requests.post(url, data=data)&gt;&gt;&gt; response.json()['arsenal f.c.', 2.44, 3.29] ProfilingStopwatch1234from time import timestart_time = time() # Seconds since the Epoch....duration = time() - start_time High performance:1234from time import perf_counterstart_time = perf_counter() # Seconds since restart....duration = perf_counter() - start_time Timing a Snippet1234&gt;&gt;&gt; from timeit import timeit&gt;&gt;&gt; timeit('"-".join(str(a) for a in range(100))',... number=10000, globals=globals(), setup='pass')0.34986 Profiling by Line1234567891011121314151617181920# $ pip3 install line_profiler memory_profiler@profiledef main(): a = [*range(10000)] b = &#123;*range(10000)&#125;main()$ kernprof -lv test.pyLine # Hits Time Per Hit % Time Line Contents======================================================= 1 @profile 2 def main(): 3 1 1128.0 1128.0 27.4 a = [*range(10000)] 4 1 2994.0 2994.0 72.6 b = &#123;*range(10000)&#125;$ python3 -m memory_profiler test.pyLine # Mem usage Increment Line Contents======================================================= 1 35.387 MiB 35.387 MiB @profile 2 def main(): 3 35.734 MiB 0.348 MiB a = [*range(10000)] 4 36.160 MiB 0.426 MiB b = &#123;*range(10000)&#125; Call GraphGenerates a PNG image of a call graph with highlighted bottlenecks:12345678# $ pip3 install pycallgraphfrom pycallgraph import output, PyCallGraphfrom datetime import datetimetime_str = datetime.now().strftime('%Y%m%d%H%M%S')filename = f'profile-&#123;time_str&#125;.png'drawer = output.GraphvizOutput(output_file=filename)with PyCallGraph(drawer): &lt;code_to_be_profiled&gt; NumPyArray manipulation mini language. Can run up to one hundred times faster than equivalent Python code. 1234567891011# $ pip3 install numpyimport numpy as np&lt;array&gt; = np.array(&lt;list&gt;)&lt;array&gt; = np.arange(from_inclusive, to_exclusive, ±step_size)&lt;array&gt; = np.ones(&lt;shape&gt;)&lt;array&gt; = np.random.randint(from_inclusive, to_exclusive, &lt;shape&gt;)&lt;array&gt;.shape = &lt;shape&gt;&lt;view&gt; = &lt;array&gt;.reshape(&lt;shape&gt;)&lt;view&gt; = np.broadcast_to(&lt;array&gt;, &lt;shape&gt;)&lt;array&gt; = &lt;array&gt;.sum(axis)indexes = &lt;array&gt;.argmin(axis) Shape is a tuple of dimension sizes. Axis is an index of dimension that gets collapsed. Leftmost dimension has index 0. Indexing12345678&lt;el&gt; = &lt;2d_array&gt;[0, 0] # First element.&lt;1d_view&gt; = &lt;2d_array&gt;[0] # First row.&lt;1d_view&gt; = &lt;2d_array&gt;[:, 0] # First column. Also [..., 0].&lt;3d_view&gt; = &lt;2d_array&gt;[None, :, :] # Expanded by dimension of size 1.&lt;1d_array&gt; = &lt;2d_array&gt;[&lt;1d_row_indexes&gt;, &lt;1d_column_indexes&gt;]&lt;2d_array&gt; = &lt;2d_array&gt;[&lt;2d_row_indexes&gt;, &lt;2d_column_indexes&gt;]&lt;2d_bools&gt; = &lt;2d_array&gt; &gt; 0&lt;1d_array&gt; = &lt;2d_array&gt;[&lt;2d_bools&gt;] If row and column indexes differ in shape, they are combined with broadcasting. BroadcastingBroadcasting is a set of rules by which NumPy functions operate on arrays of different sizes and/or dimensions. 12left = [[0.1], [0.6], [0.8]] # Shape: (3, 1)right = [ 0.1 , 0.6 , 0.8 ] # Shape: (3) 1. If array shapes differ in length, left-pad the shorter shape with ones:12left = [[0.1], [0.6], [0.8]] # Shape: (3, 1)right = [[0.1 , 0.6 , 0.8]] # Shape: (1, 3) &lt;- ! 2. If any dimensions differ in size, expand the ones that have size 1 by duplicating their elements:12left = [[0.1, 0.1, 0.1], [0.6, 0.6, 0.6], [0.8, 0.8, 0.8]] # Shape: (3, 3) &lt;- !right = [[0.1, 0.6, 0.8], [0.1, 0.6, 0.8], [0.1, 0.6, 0.8]] # Shape: (3, 3) &lt;- ! 3. If neither non-matching dimension has size 1, rise an error.ExampleFor each point returns index of its nearest point ([0.1, 0.6, 0.8] =&gt; [1, 2, 1]):12345678910111213141516171819202122&gt;&gt;&gt; points = np.array([0.1, 0.6, 0.8])[ 0.1, 0.6, 0.8]&gt;&gt;&gt; wrapped_points = points.reshape(3, 1)[[ 0.1], [ 0.6], [ 0.8]]&gt;&gt;&gt; distances = wrapped_points - points[[ 0. , -0.5, -0.7], [ 0.5, 0. , -0.2], [ 0.7, 0.2, 0. ]]&gt;&gt;&gt; distances = np.abs(distances)[[ 0. , 0.5, 0.7], [ 0.5, 0. , 0.2], [ 0.7, 0.2, 0. ]]&gt;&gt;&gt; i = np.arange(3)[0, 1, 2]&gt;&gt;&gt; distances[i, i] = np.inf[[ inf, 0.5, 0.7], [ 0.5, inf, 0.2], [ 0.7, 0.2, inf]]&gt;&gt;&gt; distances.argmin(1)[1, 2, 1] Image123456789101112131415# $ pip3 install pillowfrom PIL import Image&lt;Image&gt; = Image.new('&lt;mode&gt;', (width, height))&lt;Image&gt; = Image.open('&lt;path&gt;')&lt;Image&gt; = &lt;Image&gt;.convert('&lt;mode&gt;')&lt;Image&gt;.save('&lt;path&gt;')&lt;Image&gt;.show()&lt;tuple/int&gt; = &lt;Image&gt;.getpixel((x, y)) # Returns a pixel.&lt;Image&gt;.putpixel((x, y), &lt;tuple/int&gt;) # Writes a pixel to image.&lt;ImagingCore&gt; = &lt;Image&gt;.getdata() # Returns a sequence of pixels.&lt;Image&gt;.putdata(&lt;list/ImagingCore&gt;) # Writes a sequence of pixels.&lt;Image&gt;.paste(&lt;Image&gt;, (x, y)) # Writes an image to image.&lt;2d_array&gt; = np.array(&lt;Image&gt;) # NumPy array from greyscale image.&lt;3d_array&gt; = np.array(&lt;Image&gt;) # NumPy array from color image.&lt;Image&gt; = Image.fromarray(&lt;array&gt;) # Image from NumPy array. Modes ‘1’ - 1-bit pixels, black and white, stored with one pixel per byte. ‘L’ - 8-bit pixels, greyscale. ‘RGB’ - 3x8-bit pixels, true color. ‘RGBA’ - 4x8-bit pixels, true color with transparency mask. ‘HSV’ - 3x8-bit pixels, Hue, Saturation, Value color space. ExamplesCreates a PNG image of a rainbow gradient:123456WIDTH, HEIGHT = 100, 100size = WIDTH * HEIGHThues = [255 * i/size for i in range(size)]img = Image.new('HSV', (WIDTH, HEIGHT))img.putdata([(int(h), 255, 255) for h in hues])img.convert('RGB').save('test.png') Adds noise to a PNG image:12345from random import randintadd_noise = lambda value: max(0, min(255, value + randint(-20, 20)))img = Image.open('test.png').convert('HSV')img.putdata([(add_noise(h), s, v) for h, s, v in img.getdata()])img.convert('RGB').save('test.png') ImageDraw12345678from PIL import ImageDraw&lt;ImageDraw&gt; = ImageDraw.Draw(&lt;Image&gt;)&lt;ImageDraw&gt;.point((x, y), fill=None)&lt;ImageDraw&gt;.line((x1, y1, x2, y2 [, ...]), fill=None, width=0, joint=None) &lt;ImageDraw&gt;.arc((x1, y1, x2, y2), from_deg, to_deg, fill=None, width=0)&lt;ImageDraw&gt;.rectangle((x1, y1, x2, y2), fill=None, outline=None, width=0)&lt;ImageDraw&gt;.polygon((x1, y1, x2, y2 [, ...]), fill=None, outline=None)&lt;ImageDraw&gt;.ellipse((x1, y1, x2, y2), fill=None, outline=None, width=0) Use ‘fill=‘ to set the primary color. Use ‘outline=‘ to set the secondary color. Color can be specified as a tuple, int, ‘#rrggbb’ string or a color name. AnimationCreates a GIF of a bouncing ball:12345678910111213# $ pip3 install pillow imageiofrom PIL import Image, ImageDrawimport imageioWIDTH, R = 126, 10frames = []for velocity in range(15): y = sum(range(velocity+1)) frame = Image.new('L', (WIDTH, WIDTH)) draw = ImageDraw.Draw(frame) draw.ellipse((WIDTH/2-R, y, WIDTH/2+R, y+2*R), fill='white') frames.append(frame)frames += reversed(frames[1:-1])imageio.mimsave('test.gif', frames, duration=0.03) Audio123456789101112import wave&lt;Wave_read&gt; = wave.open('&lt;path&gt;', 'rb')framerate = &lt;Wave_read&gt;.getframerate() # Number of frames per second.nchannels = &lt;Wave_read&gt;.getnchannels() # Number of samples per frame.sampwidth = &lt;Wave_read&gt;.getsampwidth() # Sample size in bytes.nframes = &lt;Wave_read&gt;.getnframes() # Number of frames.&lt;bytes&gt; = &lt;Wave_read&gt;.readframes(nframes) # Returns next 'nframes' frames.&lt;Wave_write&gt; = wave.open('&lt;path&gt;', 'wb')&lt;Wave_write&gt;.setframerate(&lt;int&gt;) # 44100 for CD, 48000 for video.&lt;Wave_write&gt;.setnchannels(&lt;int&gt;) # 1 for mono, 2 for stereo.&lt;Wave_write&gt;.setsampwidth(&lt;int&gt;) # 2 for CD quality sound.&lt;Wave_write&gt;.writeframes(&lt;bytes&gt;) # Appends frames to file. Bytes object contains a sequence of frames, each consisting of one or more samples. In stereo signal first sample of a frame belongs to the left channel. Each sample consists of one or more bytes that, when converted to an integer, indicate the displacement of a speaker membrane at a given moment. If sample width is one, then the integer should be encoded unsigned. For all other sizes the integer should be encoded signed with little-endian byte order. Sample Values12345678+-----------+-------------+------+-------------+| sampwidth | min | zero | max |+-----------+-------------+------+-------------+| 1 | 0 | 128 | 255 || 2 | -32768 | 0 | 32767 || 3 | -8388608 | 0 | 8388607 || 4 | -2147483648 | 0 | 2147483647 |+-----------+-------------+------+-------------+ Read Float Samples from WAV File123456789def read_wav_file(filename): def get_int(a_bytes): an_int = int.from_bytes(a_bytes, 'little', signed=width!=1) return an_int - 128 * (width == 1) with wave.open(filename, 'rb') as file: width = file.getsampwidth() frames = file.readframes(file.getnframes()) byte_samples = (frames[i: i + width] for i in range(0, len(frames), width)) return [get_int(b) / pow(2, width * 8 - 1) for b in byte_samples] Write Float Samples to WAV File1234567891011def write_to_wav_file(filename, float_samples, nchannels=1, sampwidth=2, framerate=44100): def get_bytes(a_float): a_float = max(-1, min(1 - 2e-16, a_float)) a_float += sampwidth == 1 a_float *= pow(2, sampwidth * 8 - 1) return int(a_float).to_bytes(sampwidth, 'little', signed=sampwidth!=1) with wave.open(filename, 'wb') as file: file.setnchannels(nchannels) file.setsampwidth(sampwidth) file.setframerate(framerate) file.writeframes(b''.join(get_bytes(f) for f in float_samples)) ExamplesSaves a sine wave to a mono WAV file:123from math import pi, sinsamples_f = (sin(i * 2 * pi * 440 / 44100) for i in range(100000))write_to_wav_file('test.wav', samples_f) Adds noise to a mono WAV file:1234from random import randomadd_noise = lambda value: value + (random() - 0.5) * 0.03samples_f = (add_noise(f) for f in read_wav_file('test.wav'))write_to_wav_file('test.wav', samples_f) SynthesizerPlays Popcorn by Gershon Kingsley:123456789101112131415# $ pip3 install simpleaudioimport simpleaudio, math, structfrom itertools import chain, repeatF = 44100P1 = '71♪,69,,71♪,66,,62♪,66,,59♪,,,'P2 = '71♪,73,,74♪,73,,74,,71,,73♪,71,,73,,69,,71♪,69,,71,,67,,71♪,,,'get_pause = lambda seconds: repeat(0, int(seconds * F))sin_f = lambda i, hz: math.sin(i * 2 * math.pi * hz / F)get_wave = lambda hz, seconds: (sin_f(i, hz) for i in range(int(seconds * F)))get_hz = lambda key: 8.176 * 2 ** (int(key) / 12)parse_note = lambda note: (get_hz(note[:2]), 0.25 if '♪' in note else 0.125)get_samples = lambda note: get_wave(*parse_note(note)) if note else get_pause(0.125)samples_f = chain.from_iterable(get_samples(n) for n in f'&#123;P1&#125;&#123;P1&#125;&#123;P2&#125;'.split(','))samples_b = b''.join(struct.pack('&lt;h', int(f * 30000)) for f in samples_f)simpleaudio.play_buffer(samples_b, 1, 2, F) Basic Script Template123456789101112131415161718192021222324252627#!/usr/bin/env python3## Usage: .py#from collections import namedtuplefrom dataclasses import make_dataclassfrom enum import Enumfrom sys import argvimport redef main(): pass##### UTIL#def read_file(filename): with open(filename, encoding='utf-8') as file: return file.readlines()if __name__ == '__main__': main()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive SQL 编译过程]]></title>
    <url>%2F2019%2F10%2F15%2FHive-SQL-%E7%BC%96%E8%AF%91%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[--- # **Hive SQL 编译过程** Hive是基于Hadoop的一个数据仓库系统，在各大公司都有广泛的应用。美团数据仓库也是基于Hive搭建，每天执行近万次的Hive ETL计算流程，负责每天数百GB的数据存储和分析。Hive的稳定性和性能对我们的数据分析非常关键。 在几次升级Hive的过程中，我们遇到了一些大大小小的问题。通过向社区的咨询和自己的努力，在解决这些问题的同时我们对Hive将SQL编译为MapReduce的过程有了比较深入的理解。对这一过程的理解不仅帮助我们解决了一些Hive的bug，也有利于我们优化Hive SQL，提升我们对Hive的掌控力，同时有能力去定制一些需要的功能。 MapReduce实现基本SQL操作的原理详细讲解SQL编译为MapReduce之前，我们先来看看MapReduce框架实现SQL基本操作的原理 Join的实现原理1select u.name, o.orderid from order o join user u on o.uid = u.uid; 在map的输出value中为不同表的数据打上tag标记，在reduce阶段根据tag判断数据来源。MapReduce的过程如下（这里只是说明最基本的Join的实现，还有其他的实现方式） MapReduce CommonJoin的实现 Group By的实现原理1select rank, isonline, count(*) from city group by rank, isonline; 将GroupBy的字段组合为map的输出key值，利用MapReduce的排序，在reduce阶段保存LastKey区分不同的key。MapReduce的过程如下（当然这里只是说明Reduce端的非Hash聚合过程） MapReduce Group By的实现 Distinct的实现原理1select dealid, count(distinct uid) num from order group by dealid; 当只有一个distinct字段时，如果不考虑Map阶段的Hash GroupBy，只需要将GroupBy字段和Distinct字段组合为map输出key，利用mapreduce的排序，同时将GroupBy字段作为reduce的key，在reduce阶段保存LastKey即可完成去重 MapReduce Distinct的实现 如果有多个distinct字段呢，如下面的SQL 1select dealid, count(distinct uid), count(distinct date) from order group by dealid; 实现方式有两种： （1）如果仍然按照上面一个distinct字段的方法，即下图这种实现方式，无法跟据uid和date分别排序，也就无法通过LastKey去重，仍然需要在reduce阶段在内存中通过Hash去重 MapReduce Multi Distinct的实现 （2）第二种实现方式，可以对所有的distinct字段编号，每行数据生成n行数据，那么相同字段就会分别排序，这时只需要在reduce阶段记录LastKey即可去重。 这种实现方式很好的利用了MapReduce的排序，节省了reduce阶段去重的内存消耗，但是缺点是增加了shuffle的数据量。 需要注意的是，在生成reduce value时，除第一个distinct字段所在行需要保留value值，其余distinct数据行value字段均可为空。 MapReduce Multi Distinct的实现 SQL转化为MapReduce的过程了解了MapReduce实现SQL基本操作之后，我们来看看Hive是如何将SQL转化为MapReduce任务的，整个编译过程分为六个阶段： Antlr定义SQL的语法规则，完成SQL词法，语法解析，将SQL转化为抽象语法树AST Tree 遍历AST Tree，抽象出查询的基本组成单元QueryBlock 遍历QueryBlock，翻译为执行操作树OperatorTree 逻辑层优化器进行OperatorTree变换，合并不必要的ReduceSinkOperator，减少shuffle数据量 遍历OperatorTree，翻译为MapReduce任务 物理层优化器进行MapReduce任务的变换，生成最终的执行计划 下面分别对这六个阶段进行介绍 Phase1 SQL词法，语法解析AntlrHive使用Antlr实现SQL的词法和语法解析。Antlr是一种语言识别的工具，可以用来构造领域语言。 这里不详细介绍Antlr，只需要了解使用Antlr构造特定的语言只需要编写一个语法文件，定义词法和语法替换规则即可，Antlr完成了词法分析、语法分析、语义分析、中间代码生成的过程。 Hive中语法规则的定义文件在0.10版本以前是Hive.g一个文件，随着语法规则越来越复杂，由语法规则生成的Java解析类可能超过Java类文件的最大上限，0.11版本将Hive.g拆成了5个文件，词法规则HiveLexer.g和语法规则的4个文件SelectClauseParser.g，FromClauseParser.g，IdentifiersParser.g，HiveParser.g。 抽象语法树AST Tree经过词法和语法解析后，如果需要对表达式做进一步的处理，使用 Antlr 的抽象语法树语法Abstract Syntax Tree，在语法分析的同时将输入语句转换成抽象语法树，后续在遍历语法树时完成进一步的处理。 下面的一段语法是Hive SQL中SelectStatement的语法规则，从中可以看出，SelectStatement包含select, from, where, groupby, having, orderby等子句。 （在下面的语法规则中，箭头表示对于原语句的改写，改写后会加入一些特殊词标示特定语法，比如TOK_QUERY标示一个查询块） 123456789101112131415selectStatement : selectClause fromClause whereClause? groupByClause? havingClause? orderByClause? clusterByClause? distributeByClause? sortByClause? limitClause? -&gt; ^(TOK_QUERY fromClause ^(TOK_INSERT ^(TOK_DESTINATION ^(TOK_DIR TOK_TMP_FILE)) selectClause whereClause? groupByClause? havingClause? orderByClause? clusterByClause? distributeByClause? sortByClause? limitClause?)) ; 样例SQL为了详细说明SQL翻译为MapReduce的过程，这里以一条简单的SQL为例，SQL中包含一个子查询，最终将数据写入到一张表中 123456789101112131415161718FROM( SELECT p.datekey datekey, p.userid userid, c.clienttype FROM detail.usersequence_client c JOIN fact.orderpayment p ON p.orderid = c.orderid JOIN default.user du ON du.userid = p.userid WHERE p.datekey = 20131118 ) baseINSERT OVERWRITE TABLE `test`.`customer_kpi`SELECT base.datekey, base.clienttype, count(distinct base.userid) buyer_countGROUP BY base.datekey, base.clienttype SQL生成AST TreeAntlr对Hive SQL解析的代码如下，HiveLexerX，HiveParser分别是Antlr对语法文件Hive.g编译后自动生成的词法解析和语法解析类，在这两个类中进行复杂的解析。 1234567891011121314HiveLexerX lexer = new HiveLexerX(new ANTLRNoCaseStringStream(command)); //词法解析，忽略关键词的大小写TokenRewriteStream tokens = new TokenRewriteStream(lexer);if (ctx != null) &#123; ctx.setTokenRewriteStream(tokens);&#125;HiveParser parser = new HiveParser(tokens); //语法解析parser.setTreeAdaptor(adaptor);HiveParser.statement_return r = null;try &#123; r = parser.statement(); //转化为AST Tree&#125; catch (RecognitionException e) &#123; e.printStackTrace(); throw new ParseException(parser.errors);&#125; 最终生成的AST Tree如下图右侧（使用Antlr Works生成，Antlr Works是Antlr提供的编写语法文件的编辑器），图中只是展开了骨架的几个节点，没有完全展开。 子查询1/2，分别对应右侧第1/2两个部分。 SQL生成AST Tree 这里注意一下内层子查询也会生成一个TOK_DESTINATION节点。请看上面SelectStatement的语法规则，这个节点是在语法改写中特意增加了的一个节点。原因是Hive中所有查询的数据均会保存在HDFS临时的文件中，无论是中间的子查询还是查询最终的结果，Insert语句最终会将数据写入表所在的HDFS目录下。 详细来看，将内存子查询的from子句展开后，得到如下AST Tree，每个表生成一个TOK_TABREF节点，Join条件生成一个“=”节点。其他SQL部分类似，不一一详述。 AST Tree Phase2 SQL基本组成单元QueryBlockAST Tree仍然非常复杂，不够结构化，不方便直接翻译为MapReduce程序，AST Tree转化为QueryBlock就是将SQL进一部抽象和结构化。 QueryBlockQueryBlock是一条SQL最基本的组成单元，包括三个部分：输入源，计算过程，输出。简单来讲一个QueryBlock就是一个子查询。 下图为Hive中QueryBlock相关对象的类图，解释图中几个重要的属性 QB#aliasToSubq（表示QB类的aliasToSubq属性）保存子查询的QB对象，aliasToSubq key值是子查询的别名 QB#qbp即QBParseInfo保存一个基本SQL单元中的给个操作部分的AST Tree结构，QBParseInfo#nameToDest这个HashMap保存查询单元的输出，key的形式是inclause-i（由于Hive支持Multi Insert语句，所以可能有多个输出），value是对应的ASTNode节点，即TOK_DESTINATION节点。类QBParseInfo其余HashMap属性分别保存输出和各个操作的ASTNode节点的对应关系。 QBParseInfo#JoinExpr保存TOK_JOIN节点。QB#QBJoinTree是对Join语法树的结构化。 QB#qbm保存每个输入表的元信息，比如表在HDFS上的路径，保存表数据的文件格式等。 QBExpr这个对象是为了表示Union操作。 QueryBlock AST Tree生成QueryBlockAST Tree生成QueryBlock的过程是一个递归的过程，先序遍历AST Tree，遇到不同的Token节点，保存到相应的属性中，主要包含以下几个过程 TOK_QUERY =&gt; 创建QB对象，循环递归子节点 TOK_FROM =&gt; 将表名语法部分保存到QB对象的aliasToTabs等属性中 TOK_INSERT =&gt; 循环递归子节点 TOK_DESTINATION =&gt; 将输出目标的语法部分保存在QBParseInfo对象的nameToDest属性中 TOK_SELECT =&gt; 分别将查询表达式的语法部分保存在destToSelExpr、destToAggregationExprs、destToDistinctFuncExprs三个属性中 TOK_WHERE =&gt; 将Where部分的语法保存在QBParseInfo对象的destToWhereExpr属性中 最终样例SQL生成两个QB对象，QB对象的关系如下，QB1是外层查询，QB2是子查询 12345QB1 \ QB2 Phase3 逻辑操作符OperatorOperatorHive最终生成的MapReduce任务，Map阶段和Reduce阶段均由OperatorTree组成。逻辑操作符，就是在Map阶段或者Reduce阶段完成单一特定的操作。 基本的操作符包括TableScanOperator，SelectOperator，FilterOperator，JoinOperator，GroupByOperator，ReduceSinkOperator 从名字就能猜出各个操作符完成的功能，TableScanOperator从MapReduce框架的Map接口原始输入表的数据，控制扫描表的数据行数，标记是从原表中取数据。JoinOperator完成Join操作。FilterOperator完成过滤操作 ReduceSinkOperator将Map端的字段组合序列化为Reduce Key/value, Partition Key，只可能出现在Map阶段，同时也标志着Hive生成的MapReduce程序中Map阶段的结束。 Operator在Map Reduce阶段之间的数据传递都是一个流式的过程。每一个Operator对一行数据完成操作后之后将数据传递给childOperator计算。 Operator类的主要属性和方法如下 RowSchema表示Operator的输出字段 InputObjInspector outputObjInspector解析输入和输出字段 processOp接收父Operator传递的数据，forward将处理好的数据传递给子Operator处理 Hive每一行数据经过一个Operator处理之后，会对字段重新编号，colExprMap记录每个表达式经过当前Operator处理前后的名称对应关系，在下一个阶段逻辑优化阶段用来回溯字段名 由于Hive的MapReduce程序是一个动态的程序，即不确定一个MapReduce Job会进行什么运算，可能是Join，也可能是GroupBy，所以Operator将所有运行时需要的参数保存在OperatorDesc中，OperatorDesc在提交任务前序列化到HDFS上，在MapReduce任务执行前从HDFS读取并反序列化。Map阶段OperatorTree在HDFS上的位置在Job.getConf(“hive.exec.plan”) + “/map.xml” QueryBlock QueryBlock生成Operator TreeQueryBlock生成Operator Tree就是遍历上一个过程中生成的QB和QBParseInfo对象的保存语法的属性，包含如下几个步骤： QB#aliasToSubq =&gt; 有子查询，递归调用 QB#aliasToTabs =&gt; TableScanOperator QBParseInfo#joinExpr =&gt; QBJoinTree =&gt; ReduceSinkOperator + JoinOperator QBParseInfo#destToWhereExpr =&gt; FilterOperator QBParseInfo#destToGroupby =&gt; ReduceSinkOperator + GroupByOperator QBParseInfo#destToOrderby =&gt; ReduceSinkOperator + ExtractOperator 由于Join/GroupBy/OrderBy均需要在Reduce阶段完成，所以在生成相应操作的Operator之前都会先生成一个ReduceSinkOperator，将字段组合并序列化为Reduce Key/value, Partition Key 接下来详细分析样例SQL生成OperatorTree的过程 先序遍历上一个阶段生成的QB对象 首先根据子QueryBlock QB2#aliasToTabs {du=dim.user, c=detail.usersequence_client, p=fact.orderpayment}生成TableScanOperator 12TableScanOperator(“dim.user”) TS[0]TableScanOperator(“detail.usersequence_client”) TS[1] TableScanOperator(“fact.orderpayment”) TS[2] 先序遍历QBParseInfo#joinExpr生成QBJoinTree，类QBJoinTree也是一个树状结构，QBJoinTree保存左右表的ASTNode和这个查询的别名，最终生成的查询树如下 12345 base / \ p du / \c p 前序遍历QBJoinTree，先生成detail.usersequence_client和fact.orderpayment的Join操作树 Join to Operator 图中 TS=TableScanOperator RS=ReduceSinkOperator JOIN=JoinOperator 生成中间表与dim.user的Join操作树 Join to Operator 根据QB2 QBParseInfo#destToWhereExpr 生成FilterOperator。此时QB2遍历完成。 下图中SelectOperator在某些场景下会根据一些条件判断是否需要解析字段。 Where to Operator 图中 FIL= FilterOperator SEL= SelectOperator 根据QB1的QBParseInfo#destToGroupby生成ReduceSinkOperator + GroupByOperator GroupBy to Operator 图中 GBY= GroupByOperator GBY[12]是HASH聚合，即在内存中通过Hash进行聚合运算 最终都解析完后，会生成一个FileSinkOperator，将数据写入HDFS FileSinkOperator 图中FS=FileSinkOperator Phase4 逻辑层优化器大部分逻辑层优化器通过变换OperatorTree，合并操作符，达到减少MapReduce Job，减少shuffle数据量的目的。 名称 作用 ② SimpleFetchOptimizer 优化没有GroupBy表达式的聚合查询 ② MapJoinProcessor MapJoin，需要SQL中提供hint，0.11版本已不用 ② BucketMapJoinOptimizer BucketMapJoin ② GroupByOptimizer Map端聚合 ① ReduceSinkDeDuplication 合并线性的OperatorTree中partition/sort key相同的reduce ① PredicatePushDown 谓词前置 ① CorrelationOptimizer 利用查询中的相关性，合并有相关性的Job，HIVE-2206 ColumnPruner 字段剪枝 表格中①的优化器均是一个Job干尽可能多的事情/合并。②的都是减少shuffle数据量，甚至不做Reduce。 CorrelationOptimizer优化器非常复杂，都能利用查询中的相关性，合并有相关性的Job，参考 Hive Correlation Optimizer 对于样例SQL，有两个优化器对其进行优化。下面分别介绍这两个优化器的作用，并补充一个优化器ReduceSinkDeDuplication的作用 PredicatePushDown优化器断言判断提前优化器将OperatorTree中的FilterOperator提前到TableScanOperator之后 PredicatePushDown NonBlockingOpDeDupProc优化器NonBlockingOpDeDupProc优化器合并SEL-SEL 或者 FIL-FIL 为一个Operator NonBlockingOpDeDupProc ReduceSinkDeDuplication优化器ReduceSinkDeDuplication可以合并线性相连的两个RS。实际上CorrelationOptimizer是ReduceSinkDeDuplication的超集，能合并线性和非线性的操作RS，但是Hive先实现的ReduceSinkDeDuplication 譬如下面这条SQL语句 1from (select key, value from src group by key, value) s select s.key group by s.key; 经过前面几个阶段之后，会生成如下的OperatorTree，两个Tree是相连的，这里没有画到一起 ReduceSinkDeDuplication 这时候遍历OperatorTree后能发现前前后两个RS输出的Key值和PartitionKey如下 Key PartitionKey childRS key key parentRS key,value key,value ReduceSinkDeDuplication优化器检测到：1. pRS Key完全包含cRS Key，且排序顺序一致；2. pRS PartitionKey完全包含cRS PartitionKey。符合优化条件，会对执行计划进行优化。 ReduceSinkDeDuplication将childRS和parentheRS与childRS之间的Operator删掉，保留的RS的Key为key,value字段，PartitionKey为key字段。合并后的OperatorTree如下： ReduceSinkDeDuplication Phase5 OperatorTree生成MapReduce Job的过程OperatorTree转化为MapReduce Job的过程分为下面几个阶段 对输出表生成MoveTask 从OperatorTree的其中一个根节点向下深度优先遍历 ReduceSinkOperator标示Map/Reduce的界限，多个Job间的界限 遍历其他根节点，遇过碰到JoinOperator合并MapReduceTask 生成StatTask更新元数据 剪断Map与Reduce间的Operator的关系 对输出表生成MoveTask由上一步OperatorTree只生成了一个FileSinkOperator，直接生成一个MoveTask，完成将最终生成的HDFS临时文件移动到目标表目录下 12MoveTask[Stage-0]Move Operator 开始遍历将OperatorTree中的所有根节点保存在一个toWalk的数组中，循环取出数组中的元素（省略QB1，未画出） 开始遍历 取出最后一个元素TS[p]放入栈 opStack{TS[p]}中 Rule #1 TS% 生成MapReduceTask对象，确定MapWork发现栈中的元素符合下面规则R1（这里用python代码简单表示） 1"".join([t + "%" for t in opStack]) == "TS%" 生成一个MapReduceTask[Stage-1]对象，MapReduceTask[Stage-1]对象的MapWork属性保存Operator根节点的引用。由于OperatorTree之间之间的Parent Child关系，这个时候MapReduceTask[Stage-1]包含了以TS[p]为根的所有Operator Stage-1 生成Map阶段 Rule #2 TS%.*RS% 确定ReduceWork继续遍历TS[p]的子Operator，将子Operator存入栈opStack中 当第一个RS进栈后，即栈opStack = {TS[p], FIL[18], RS[4]}时，就会满足下面的规则R2 1"".join([t + "%" for t in opStack]) == "TS%.*RS%" 这时候在MapReduceTask[Stage-1]对象的ReduceWork属性保存JOIN[5]的引用 Stage-1 生成Reduce阶段 Rule #3 RS%.*RS% 生成新MapReduceTask对象，切分MapReduceTask继续遍历JOIN[5]的子Operator，将子Operator存入栈opStack中 当第二个RS放入栈时，即当栈opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6]}时，就会满足下面的规则R3 1"".join([t + "%" for t in opStack]) == “RS%.*RS%” //循环遍历opStack的每一个后缀数组 这时候创建一个新的MapReduceTask[Stage-2]对象，将OperatorTree从JOIN[5]和RS[6]之间剪开，并为JOIN[5]生成一个子Operator FS[19]，RS[6]生成一个TS[20]，MapReduceTask[Stage-2]对象的MapWork属性保存TS[20]的引用。 新生成的FS[19]将中间数据落地，存储在HDFS临时文件中。 Stage-2 继续遍历RS[6]的子Operator，将子Operator存入栈opStack中 当opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6], JOIN[8], SEL[10], GBY[12], RS[13]}时，又会满足R3规则 同理生成MapReduceTask[Stage-3]对象，并切开 Stage-2 和 Stage-3 的OperatorTree Stage-3 R4 FS% 连接MapReduceTask与MoveTask最终将所有子Operator存入栈中之后，opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6], JOIN[8], SEL[10], GBY[12], RS[13], GBY[14], SEL[15], FS[17]} 满足规则R4 1"".join([t + "%" for t in opStack]) == “FS%” 这时候将MoveTask与MapReduceTask[Stage-3]连接起来，并生成一个StatsTask，修改表的元信息 MoveTask 合并Stage此时并没有结束，还有两个根节点没有遍历。 将opStack栈清空，将toWalk的第二个元素加入栈。会发现opStack = {TS[du]}继续满足R1 TS%，生成MapReduceTask[Stage-5] Stage-5 继续从TS[du]向下遍历，当opStack={TS[du], RS[7]}时，满足规则R2 TS%.*RS% 此时将JOIN[8]保存为MapReduceTask[Stage-5]的ReduceWork时，发现在一个Map对象保存的Operator与MapReduceWork对象关系的Map&lt;Operator, MapReduceWork&gt;对象中发现，JOIN[8]已经存在。此时将MapReduceTask[Stage-2]和MapReduceTask[Stage-5]合并为一个MapReduceTask 合并 Stage-2 和 Stage-5 同理从最后一个根节点TS[c]开始遍历，也会对MapReduceTask进行合并 合并 Stage-1 和 Stage-6 切分Map Reduce阶段最后一个阶段，将MapWork和ReduceWork中的OperatorTree以RS为界限剪开 切分Map Reduce阶段 OperatorTree生成MapReduceTask全貌最终共生成3个MapReduceTask，如下图 OperatorTree生成MapReduceTask全貌 Phase6 物理层优化器这里不详细介绍每个优化器的原理，单独介绍一下MapJoin的优化器 名称 作用 Vectorizer HIVE-4160，将在0.13中发布 SortMergeJoinResolver 与bucket配合，类似于归并排序 SamplingOptimizer 并行order by优化器，在0.12中发布 CommonJoinResolver + MapJoinResolver MapJoin优化器 MapJoin原理 mapjoin原理 MapJoin简单说就是在Map阶段将小表读入内存，顺序扫描大表完成Join。 上图是Hive MapJoin的原理图，出自Facebook工程师Liyin Tang的一篇介绍Join优化的slice，从图中可以看出MapJoin分为两个阶段： 通过MapReduce Local Task，将小表读入内存，生成HashTableFiles上传至Distributed Cache中，这里会对HashTableFiles进行压缩。 MapReduce Job在Map阶段，每个Mapper从Distributed Cache读取HashTableFiles到内存中，顺序扫描大表，在Map阶段直接进行Join，将数据传递给下一个MapReduce任务。 conditionaltask 如果Join的两张表一张表是临时表，就会生成一个ConditionalTask，在运行期间判断是否使用MapJoin CommonJoinResolver优化器CommonJoinResolver优化器就是将CommonJoin转化为MapJoin，转化过程如下 深度优先遍历Task Tree 找到JoinOperator，判断左右表数据量大小 对与小表 + 大表 =&gt; MapJoinTask，对于小/大表 + 中间表 =&gt; ConditionalTask 遍历上一个阶段生成的MapReduce任务，发现MapReduceTask[Stage-2] JOIN[8]中有一张表为临时表，先对Stage-2进行深度拷贝（由于需要保留原始执行计划为Backup Plan，所以这里将执行计划拷贝了一份），生成一个MapJoinOperator替代JoinOperator，然后生成一个MapReduceLocalWork读取小表生成HashTableFiles上传至DistributedCache中。 mapjoin变换 MapReduceTask经过变换后的执行计划如下图所示 mapjoin变换 MapJoinResolver优化器MapJoinResolver优化器遍历Task Tree，将所有有local work的MapReduceTask拆成两个Task MapJoinResolver 最终MapJoinResolver处理完之后，执行计划如下图所示 MapJoinResolver Hive SQL编译过程的设计从上述整个SQL编译的过程，可以看出编译过程的设计有几个优点值得学习和借鉴 使用Antlr开源软件定义语法规则，大大简化了词法和语法的编译解析过程，仅仅需要维护一份语法文件即可。 整体思路很清晰，分阶段的设计使整个编译过程代码容易维护，使得后续各种优化器方便的以可插拔的方式开关，譬如Hive 0.13最新的特性Vectorization和对Tez引擎的支持都是可插拔的。 每个Operator只完成单一的功能，简化了整个MapReduce程序。 社区发展方向Hive依然在迅速的发展中，为了提升Hive的性能，hortonworks公司主导的Stinger计划提出了一系列对Hive的改进，比较重要的改进有： Vectorization - 使Hive从单行单行处理数据改为批量处理方式，大大提升了指令流水线和缓存的利用率 Hive on Tez - 将Hive底层的MapReduce计算框架替换为Tez计算框架。Tez不仅可以支持多Reduce阶段的任务MRR，还可以一次性提交执行计划，因而能更好的分配资源。 Cost Based Optimizer - 使Hive能够自动选择最优的Join顺序，提高查询速度 Implement insert, update, and delete in Hive with full ACID support - 支持表按主键的增量更新 我们也将跟进社区的发展，结合自身的业务需要，提升Hive型ETL流程的性能 参考HiveSQL编译过程https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html Antlr: http://www.antlr.org/ Wiki Antlr介绍: http://en.wikipedia.org/wiki/ANTLR Hive Wiki: https://cwiki.apache.org/confluence/display/Hive/Home HiveSQL编译过程: http://www.slideshare.net/recruitcojp/internal-hive Join Optimization in Hive: Join Strategies in Hive from the 2011 Hadoop Summit (Liyin Tang, Namit Jain) Hive Design Docs: https://cwiki.apache.org/confluence/display/Hive/DesignDocs 版权声明： 除非注明，本博文章均为原创，转载请以链接形式标明本文地址。]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>sql</tag>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DB2 performance Optimization]]></title>
    <url>%2F2019%2F10%2F14%2FDB2-performance-Optimization%2F</url>
    <content type="text"><![CDATA[# 提高 DB2 查询性能的常用方法 提高DB2查询性能的常用方法将着重介绍如何使用 Visual Explain 和 db2expln 查看动态查询的存取计划。读者可以查阅 DB2 Info Center 获得有关查看静态查询存取计划的内容。 DB2 Visual ExplainDB2 提供了非常直观有效的方法来查看查询的存取计划。DB2 Visual Explain 能够获得可视化的查询计划，而 db2expln 命令则可以获得文本形式的查询计划。有了查询计划，我们就可以有针对的对查询进行优化。根据查询计划找出代价最高的扫描 ( 表扫描，索引扫描等 ) 和操作 (Join，Filter，Fetch 等 )，继而通过改写查询或者创建索引消除代价较高的扫描或操作来优化查询。 DB2 提供了多种方法来得到可视化查询计划。 通过 DB2 Control Center 获得可视化查询计划。如图 1： 图 1. 可视化查询计划 点击”Explain SQL”后输入要进行分析的查询语句以及查询标号和标签，点击 Ok 按钮便可得到可视化的查询计划。此时，查询计划会被存储在系统的 Explain 表中。用户可以通过图 1 中的”Show Explained Statements History”命令获得存储在 Explain 表中的所有查询计划。 通过 Command Editor( 在 DB2 8.2 版本之前叫做 Command Center) 获得可视化的查询计划。如图 2： 图 2. 获得可视化的查询计划 在主窗口输入查询并连接数据库后，点击图中所示的按钮即可得到可视化的查询计划，如图 3： 图 3. 查询计划结果 在图 3 所示的查询计划中，还可以点击图示中的每个节点来察看详细的统计信息。譬如双击节点”FETCH(13) 21,959.75” 后将会弹出如图 4 所示的对话框： 图 4. 详细的统计信息 图 4 中的统计信息主要包括此 FETCH 操作的总代价，CPU，I/O 以及获得结果集中的第一行的代价。在这里，timerons 是结合了 CPU 和 I/O 代价的成本单位。此外，图 4 中还收集了其他相关信息。譬如此操作读取了哪个表的哪些列，每个谓词的选择度 (selectivity)，使用了多少 buffer 等等。 db2exfmt db2exfmt 命令能够将 Explain 表中存储的存取计划信息以文本的形式进行格式化输出。db2exfmt 命令将各项信息更为直观的显示，使用起来更加方便。命令如清单 1 所示： 清单 1. db2exfmt 命令 1234567db2exfmt -d &lt;``db_name``&gt; -e &lt;``schema``&gt; -g T -o &lt;``output``&gt; -u &lt;``user``&gt; &lt;``password``&gt; -w &lt;``timestamp``&gt;Example: db2exfmt -d test_db -e user -g T -o D:\temp\sql_1_result_db2exfmt.txt ``-u user password -w lQuery: ``sql_1.txt（附件中） ``Results: ``sql_1_result_db2exfmt.txt（附件中） db2expln db2expln 是命令行下的解释工具，和前面介绍的 Visual Explain 功能相似。通过该命令可以获得文本形式的查询计划。命令如清单 2 所示 : 清单 2. db2expln 命令 1db2expln -d &lt;``db_name``&gt; -user &lt;``user``&gt; &lt;``password``&gt; -stmtfile &lt;``sql.file``&gt;`` ``-z @ -output &lt;``output``&gt; -g``Example: db2expln -d test_db -user user password -stmtfile D:\temp\sql_1.txt`` ``-z @ -output D:\temp\sql_1_result_db2expln.txt –g``Query:`` ``sql_1.txt（附件中）`` ``Results:`` ``sql_1_result_db2expln.txt（附件中） db2expln 将存取计划以文本形式输出，它只提供存取计划中主要的信息，并不包含每一个操作占用多少 CPU、I/O、占用 Buffer 的大小以及使用的数据库对象等信息，方便阅读。但是 db2expln 也会将各项有关存取计划的信息存入 Explain 表中，用户可以使用 db2exfmt 察看详细的格式化文本信息。 db2advis db2advis 是 DB2 提供的另外一种非常有用的命令。通过该命令 DB2 可以根据优化器的配置以及机器性能给出提高查询性能的建议。这种建议主要集中于如何创建索引，这些索引可以降低多少查询代价，需要创建哪些表或者 Materialized Query Table(MQT) 等。命令如清单 3 所示： 清单 3. db2advis 命令 1db2advis -d &lt;``db_name``&gt; -a &lt;``user``&gt;/&lt;``password``&gt; -i &lt;``sql.file``&gt; -o &lt;``output``&gt;``Example: db2advis -d test_db -a user/password`` ``-i D:\temp\sql_2.txt &gt; D:\temp\sql_2_result_db2advis.txt``Query:`` ``sql_2.txt（附件中）`` ``Results:`` ``sql_2_result_db2advis.txt（附件中） 通过 -i 指定的 SQL 文件可以包含多个查询，但是查询必须以分号分隔。这与 db2expln 命令不同，db2expln 可以通过 -z 参数指定多个查询之间的分隔符。用户可以把某一个 workload 中所使用的所有查询写入 SQL 文件中，并在每个查询之前使用”–#SET FREQUENCY ”为其指定在这个 workload 中的执行频率。db2advis 会根据每个查询在这个 workload 的频率指数进行权衡来给出索引的创建建议，从而达到整个 workload 的性能最优。 db2batch 前面介绍的工具和命令只提供了查询的估算代价，但有些时候估算代价和实际的执行时间并不是完全呈线形关系，有必要实际执行这些查询。db2batch 就是这样一个 Benchmark 工具，它能够提供从准备到查询完成中各个阶段所花费地具体时间，CPU 时间，以及返回的记录。命令如清单 4 所示： 清单 4. db2batch 命令 1db2batch -d &lt;``db_name``&gt; -a &lt;``user``&gt;/&lt;``password``&gt;`` ``-i &lt;``time_condition``&gt; -f &lt;``sql.file``&gt; -r &lt;``output``&gt;``Example: db2batch -d test_db -a user/password`` ``-i complete -f D:\temp\sql_3.txt -r d:\temp\sql_3_result_db2batch.txt``Query:`` ``sql_3.txt（附件中）`` ``Results:`` ``sql_3_result_db2batch.txt（附件中） 对于执行 db2batch 时一些详细的设置可以通过 -o 参数指定，也可以在 SQL 文件中指定，譬如本例中在 SQL 文件中使用了下面的配置参数 : –#SET ROWS_FETCH -1 ROWS_OUT 5 PERF_DETAIL 1 DELIMITER @ TIMESTAMP 其中 ROWS_FETCH 和 ROWS_OUT 定义了从查询的结果集中读取记录数和打印到输出文件中的记录数，PERF_DETAIL 设置了收集性能信息的级别，DELIMITER 则指定了多个查询间的间隔符。 提高查询性能的常用方法 下面我们将从三个方面介绍一些提高查询性能的方法。 创建索引 根据查询所使用的列建立多列索引 建立索引是用来提高查询性能最常用的方法。对于一个特定的查询，可以为某一个表所有出现在查询中的列建立一个联合索引，包括出现在 select 子句和条件语句中的列。但简单的建立一个覆盖所有列的索引并不一定能有效提高查询，因为在多列索引中列的顺序是非常重要的。这个特性是由于索引的 B+ 树结构决定的。一般情况下，要根据谓词的选择度来排列索引中各列的位置，选择度大的谓词所使用的列放在索引的前面，把那些只存在与 select 子句中的列放在索引的最后。譬如清单 5 中的查询： 清单 5. 索引中的谓词位置 1select add_date``from temp.customer``where city = 'WASHINGTON'``and cntry_code = 'USA'; 对于这样的查询可以在 temp.customer 上建立 (city，cntry_code，add_date) 索引。由于该索引包含了 temp.customer 所有用到的列，此查询将不会访问 temp.customer 的数据页面，而直接使用了索引页面。对于包含多列的联合索引，索引树中的根节点和中间节点存储了多列的值的联合。这就决定了存在两种索引扫描。回到清单 5 中的查询，由于此查询在新建索引的第一列上存在谓词条件，DB2 能够根据这个谓词条件从索引树的根节点开始遍历，经过中间节点最后定位到某一个叶子节点，然后从此叶子节点开始往后进行在叶子节点上的索引扫描，直到找到所有满足条件的记录。这种索引扫描称之为 Matching Index Scan。但是如果将 add_date 放在索引的第一个位置，而查询并不存在 add_date 上的谓词条件，那么这个索引扫描将会从第一个索引叶子节点开始，它无法从根节点开始并经过中间节点直接定位到某一个叶子节点，这种扫描的范围扩大到了整个索引，我们称之为 Non-matching Index Scan。图 5 显示了 DB2 根据不同索引生成的存取计划。 图 5. 根据不同索引生成的存取计划 根据条件语句中的谓词的选择度创建索引 因为建立索引需要占用数据库的存储空间，所以需要在空间和时间性能之间进行权衡。很多时候，只考虑那些在条件子句中有条件判断的列上建立索引会也会同样有效，同时节约了空间。譬如清单 5 中的查询，可以只建立 (city，cntry_code) 索引。我们还可以进一步地检查条件语句中的这两个谓词的选择度，执行清单 6 中的语句检查谓词选择度： 清单 6. 检查谓词选择度 1Queries:``1. select count(*) from temp.customer``where city = 'WASHINGTON'``and cntry_code = 'USA';``2. select count(*) from temp.customer``where city = 'WASHINGTON';``3. select count(*) from temp.customer``where cntry_code = 'USA';``Results:``1. 1404``2. 1407``3. 128700 选择度越大，过滤掉的记录越多，返回的结果集也就越小。从清单 6 的结果可以看到，第二个查询的选择度几乎有和整个条件语句相同。因此可以直接建立单列索引 (city)，其性能与索引 (city，cntry_code，add_date) 具有相差不多的性能。表 1 中对两个索引的性能和大小进行了对比。 表 1. 两个索引的性能和大小对比 索引 查询计划总代价 索引大小 cust_i1(city，cntry_code，add_date) 28.94 timerons 19.52M cust_i3(city) 63.29 timerons 5.48M 从表 1 中可以看到单列索引 (city) 具有更加有效的性能空间比，也就是说占有尽可能小的空间得到尽可能高的查询速度。 避免在建有索引的列上使用函数 这是一个很简单的原则，如果在建有索引的列上使用函数，由于函数的单调性不确定，函数的返回值和输入值可能不会一一对应，就可能存在索引中位置差异很大的多个列值可以满足带有函数的谓词条件，因此 DB2 优化器将无法进行 Matching Index Scan，更坏的情况下可能会导致直接进行表扫描。图 6 中对比了使用 function 前后的存取计划的变化。 图 6. 使用 function 前后的存取计划的变化 在那些需要被排序的列上创建索引 这里的排序不仅仅指 order by 子句，还包括 distinct 和 group by 子句，他们都会产生排序的操作。由于索引本身是有序的，在其创建过程中已经进行了排序处理，因此在应用这些语句的列上创建索引会降低排序操作的代价。这种情况一般针对于没有条件语句的查询。如果存在条件语句，DB2 优化器会首先选择出满足条件的纪录，然后才对中间结果集进行排序。对于没有条件语句的查询，排序操作在总的查询代价中会占有较大比重，因此能够较大限度的利用索引的排序结构进行查询优化。此时可以创建单列索引，如果需要创建联合索引则需要把被排序的列放在联合索引的第一列。图 7 对比了清单 7 中的查询在创建索引前后的存取计划。 清单 7. 查询在创建索引前后的存取计划 1select distinct add_date from temp.customer; 图 7. 在创建索引前后的存取计划 从图 7 中我们可以看到在没有索引的情况下 SORT 操作是 24751.69 timerons，但是有索引的情况下，不再需要对结果集进行排序，可以直接进行 UNIQUE 操作，表中显示了这一操作只花费了 2499.98 timerons. 图 8 对比了清单 8 中的查询在创建联合索引前后的存取计划，从中可以更好的理解索引对排序操作的优化。 清单 8. 查询示例 1select cust_name from temp.customer order by add_date; 图 8. 创建联合索引前后的存取计划 索引的 B+ 树结构决定了索引 temp.cust_i5 的所有叶子节点本身就是按照 add_date 排序的，所以对于清单 8 中的查询，只需要顺序扫描索引 temp.cust_i5 的所有叶子节点。但是对于 temp.cust_i6 索引，其所有叶子节点是按照 cust_name 排序，因此在经过对索引的叶子节点扫描获得所有数据之后，还需要对 add_date 进行排序操作。 合理使用 include 关键词创建索引 对于类似下面的查询 : 清单 9. 查询示例 1select cust_name from temp.customer``where cust_num between '0007000000' and '0007200000' 在第一点中我们提到可以在 cust_num 和 cust_name 上建立联合索引来提高查询性能。但是由于 cust_num 是主键，可以使用 include 关键字创建唯一性索引： create unique index temp.cust_i7 on temp.customer(cust_num) include (cust_name) 使用 include 后，cust_name 列的数据将只存在于索引树的叶子节点，并不存在于索引的关键字中。这种情况下，使用带有 include 列的唯一索引会带来优于联合索引的性能，因为唯一索引能够避免一些不必要的操作，如排序。对于清单 9 中的查询创建索引 temp.cust_i7 后存取计划的代价为 12338.7 timerons，创建联合索引 temp.cust_i8(cust_num，cust_name) 后的代价为 12363.17 timerons。一般情况下，当查询的 where 子句中存在主键的谓词我们就可以创建带有 include 列的唯一索引，形成纯索引访问来提高查询性能。注意 include 只能用在创建唯一性索引中。 指定索引的排序属性 对于下面用来显示最近一个员工入职的时间的查询： select max(add_date) from temp.employee 很显然这个查询会进行全表扫描。查询计划如图 9.a: 图 9. 查询计划 显然我们可以在 add_date 上创建索引。根据下面的命令创建索引后的查询计划如图 9.b。 create index temp.employee_i1 on temp.employee(add_date) 这里存在一个误区，大家可能认为既然查询里要取得的是 add_date 的最大值，而我们又在 add_date 上建立了一个索引，优化器应该知道从索引树中直接去寻找最大值。但是实际情况并非如此，因为创建索引的时候并没有指定排序属性，默认为 ASC 升序排列，DB2 将会扫描整个索引树的叶子节点取得所有值后，然后取其最大。我们可以通过设置索引的排序属性来提高查询性能，根据下面的命令创建索引后的查询计划如图 9.c。 create index temp.employee_i1 on temp.employee(add_date desc) 对于降序排列的索引，DB2 不需要扫描整个索引数的叶子节点，因为第一个节点便是最大的。我们同样可以使用 ALLOW REVERSE SCANS 来指定索引为双向扫描，具有和 DESC 近似的查询性能。ALLOW REVERSE SCANS 可以被认为是 ASC 和 DESC 的组合，只是在以后数据更新的时候维护成本会相对高一些。 如果无法改变索引的排序属性，但是我们具有额外的信息，该公司每个月都会有新员工入职，那么这个查询就可以改写成： select max(add_date) from temp.employee where add_date &gt; current timestamp - 1 month 这样通过限定一个查询范围也会有效地提高查询性能。 索引和表的维护 重新组织索引 随着数据的不断删除，插入和更新，索引页会变得越来越零散，索引页的物理存储顺序不再匹配其逻辑顺序，索引结构的层次会变得过大，这些都会导致索引页的预读取变得效率低下。因此，根据数据更新的频繁程度需要适当的重新组织索引。可以使用 REORG INDEXES 命令来重新组织索引结构，也可以删除并重新创建索引达到相同的目的。同样的，对表进行重新组织也会带来性能的改善。 重新组织某一个表的所有索引的命令如下：REORG INDEXES ALL FOR TABLE table_name。 重新组织一个表的数据的命令如下，在下面的命令还可以为其指定一个特定的索引，REORG 命令将会根据这个索引的排序方式重新组织该表的数据。 REORG TABLE table_name INDEX index_name。 重新收集表和索引的统计信息 和在 2.1 中提到的原因类似，当一个表经过大量的索引修改、数据量变化或者重新组织后，可能需要重新收集表以及相关索引的统计信息。这些统计信息主要是关于表和索引存储的物理特性，包括记录数目，数据页的数目以及记录的平均长度等。优化器将根据这些信息决定使用什么样的存取计划来访问数据。因此，不能真实反映实际情况的统计信息可能会导致优化器选择错误的存取计划。收集表及其所有索引的统计信息的命令如下：RUNSTATS ON TABLE table_name FOR INDEXES ALL。 上述两个命令具有复杂的参数选择，用户可以参阅 DB2 Info Center 来根据实际情况使用这两个命令。 修改查询 合理使用 NOT IN 和 NOT EXISTS 一般情况下 NOT EXISTS 具有快于 NOT IN 的性能，但是这并不绝对。根据具体的数据情况、存在的索引以及查询的结构等因素，两者会有较大的性能差异，开发人员需要根据实际情况选择适当的方式。 譬如下面的查询： 清单 10. 查询示例 1表结构：temp.customer(cust_num) 主键：cust_num``表结构：temp.contact(cnt_id，cust_num) 主键：cnt_id``表结构：temp.contact_detail(cnt_id，address，phone) 主键：cnt_id``查询 :``select cust_num``from temp.customer cust``where not exists (select 1 from temp.contact cont``here cust.cust_num = cont.cust_num) 此查询用来列出所有不存在联系人的客户。对于这样的需求，开发人员会最自然的写出清单 10 中的查询，的确，对于大部分情况它具有最优的性能。该查询的查询代价为 178,430 timerons。让我们再来看看使用 NOT IN 后查询的总代价，请看清单 11。 清单 11. 查询示例 1查询：``select cust_num``from temp.customer cust``where cust.cust_num not in (select cont.cust_num from temp.contact cont)``代价：12,648,897,536 timerons 可以看到 NOT EXISTS 的性能要比 NOT IN 高出许多。NOT IN 是自内向外的操作，即先得到子查询的结果，然后执行最外层的查询，而 NOT EXISTS 恰好相反，是自外向内的操作。在上述例子中，temp.contact 表中有 65 万条记录，使得 10.2 查询中的 NOT IN 列表非常大，导致了使用 NOT IN 的查询具有非常高的查询代价。下面我们对 10.1 和 10.2 的查询进行修改，将 temp.contact 表中的记录限制到 100 条，请看下面的查询： 清单 12. 查询示例 1查询：``select cust_num``from temp.customer cust``where not exists (select 1 from temp.contact cont``here cust.cust_num = cont.cust_num``and cont.cnt_id &lt; 100)``代价：42,015 timerons 清单 13. 查询示例 1查询：``select cust_num``from temp.customer cust``where cust.cust_num not in (select cont.cust_num from temp.contact cont``where cont.cnt_id &lt; 100)``代价：917,804 timerons 从 12 和 13 中可以看出 NOT EXISTS 的查询代价随子查询返回的结果集的变化没有大幅度的下降，随着子查询的结果集从 65 万下降到 100 条，NOT EXISTS 的查询代价从 178,430 下降到 42,015，只下降 4 倍。但是 NOT IN 的查询代价却有着极大的变化，其查询代价从 12,648,897,536 下降到 917,804，下降了 13782 倍。可见子查询的结果集对 NOT IN 的性能影响很大，但是这个简单的查询不能说明 NOT EXISTS 永远好于 NOT IN，因为同样存在一些因素对 NOT EXISTS 的性能有很大的影响。我们再看下面的例子： 清单 14. 查询示例 1查询：``select cust_num``from temp.customer cust``where not exists (select 1 from temp.contact cont``where cust.cust_num = cont.cust_num``and cont.cnt_id in (select cnt_id from temp.contact_detail``where cnt_id&lt;100))``代价：5,263,096 timerons 清单 15. 查询示例 1查询：``select cust_num``from temp.customer cust``where cust_num not in (select cust_num from temp.contact cont``where cont.cnt_id in (select cnt_id from temp.contact_detail``where cnt_id&lt;100))``代价：4,289,095 timerons 在上面的例子中，我们只是对查询增加了一个小改动，使用一个嵌套查询限制了在 temp.contact 中扫描的范围。但是在这两个新的查询中，NOT IN 的性能却又好于 NOT EXISTS。NOT EXISTS 的代价增加了 125 倍，而 NOT IN 的代价却只增加了 4 倍。这是由于 NOT EXISTS 是自外向内，嵌套查询的复杂度对其存在较大的影响。因此在实际应用中，要考虑子查询的结果集以及子查询的复杂度来决定使用 NOT EXISTS 或者 NOT IN。对于 IN，EXISTS 和 JOIN 等操作，大多数情况下 DB2 优化器都能形成比较一致的最终查询计划。 合理使用子查询减少数据扫描和利用索引 某些情况下可以将查询中的某一部分逻辑提取出来作为子查询出现，能够减少扫描的数据量，以及利用索引进行数据检索。请看清单 16 中的查询： 清单 16. 1索引：temp.cust_i1 on temp.customer(add_date)``temp.order_i1 on temp.order(sold_to_cust_num)``temp.order_i2 on temp.order(add_date)``查询：``select cust.cust_num``from temp.customer cust``left join temp.order ord``on cust.cust_num = ord.sold_to_cust_num``where cust.add_date &gt; current timestamp - 2 months``or ord.add_date &gt; current timestamp - 2 months 上面的查询用来选择所有两个月内新增加的用户以及在两个月内定购了产品的用户。从图 10.a 的查询计划中可看出没有任何索引被使用。 图 10. 查询计划 使用子查询对该查询重新改写后，请看清单 17: 清单 17. 1查询：``with tmp as(``select sold_to_cust_num from temp.order ``where add_date &gt; current timestamp - 2 months)``select cust.cust_num from temp.customer cust``where cust.add_date &gt; current timestamp - 2 months``or cust.cust_num in (select sold_to_cust_num from tmp ) 在清单 17 的查询中，我们使用子查询预先限定了要扫描 temp.order 表中的记录数目，而不是像清单 16 中的查询那样对 temp.order 表进行全表扫描。同时，在预先限定数据范围的时候，能够利用 temp.order_i2 索引。请看其查询计划，如图 10.b。可以看到查询代价有大幅度下降。其实，即使没有 temp.order_i2 索引，修改后的查询也仍然由于前者，因为它预先限定了数据的扫描范围，也减少了后续连接处理的数据量，请看图 10.c。 重新排列各个表的连接顺序，尽量减小中间结果集的数据量 一般情况下，DB2 会根据各表的 JOIN 顺序自顶向下顺序处理，因此合理排列各表的连接顺序会提高查询性能。譬如清单 18 中的查询： 清单 18. 1查询：``select cust.cust_name, ord.order_num, cnt.cnt_first_name``from temp.customer cust``left join temp.order ord``on cust.cust_num = ord.sold_to_cust_num``join temp.contact cnt``on cust.cust_num = cnt.cust_num``where cnt.mod_date &gt; current timestamp - 1 months 清单 18 中的查询用来选择出所有最近一个月内修改过联系人信息的客户的订单信息。此查询会按照链接的顺序先将 temp.customer 表和 temp.order 表进行 LEFT JOIN，然后使用结果集去 JOIN temp.contact 表。由于该查询使用了 LEFT JOIN，因此在生成中间结果集的时候不会有任何记录会被过滤掉，中间结果集的记录数目大于等于 temp.customer 表。了解到了 DB2 是如何解释和执行这样的查询后，很自然的我们就会想到将 JOIN 提前。请看清单 19。 清单 19. 1查询：``select cust.cust_name, ord.order_num, cnt.cnt_first_name``from temp.customer cust``join temp.contact cnt``on cust.cust_num = cnt.cust_num``left join temp.order ord``on cust.cust_num = ord.sold_to_cust_num``where cnt.mod_date &gt; current timestamp - 1 months 图 11.a 和图 11.b 分别为清单 18 和 19 的查询的存取计划。在 19 的查询中，在形成中间结果集的时候也应用到了 WHERE 语句中的条件，而不是在所有 JOIN 都结束以后才被应用去除记录的。 图 11. 查询计划 另外，在修改查询尽量减少中间结果集的记录条数的时候还要考虑中间结果集的数据总量，譬如中间结果集需要保存的每条记录的长度。如果我们把 JOIN temp.contact 提前以后，由于中间结果集需要保存过多的 contact 表的列反而使得结果集的数据总量变大，可能不会带来性能上的改善。 使用 UDF 代替查询中复杂的部分 由于 UDF 是预先编译的，性能普遍优于一般的查询，UDF 使用的存取计划一经编译就会相对稳定。笔者在工作中曾多次发现，使用 UDF 代替查询或者视图中的复杂部分会提高几倍甚至几十倍的性能，主要原因是迫使 DB2 使用指定的存取计划来充分利用 index 或者调整其访问过程（如 Join 顺序， Filter 位置等）。使用 UDF 进行优化的基本思路是，将复杂查询分解为多个部分执行，针对每个部分优化处理，将各部分组合时能够避免存取计划的一些不必要变化，优化整体性能。譬如清单 20 中的查询： 清单 20. 1查询：select * from temp.customer where cust_num in (``select distinct sold_to_cust_num from temp.order``where add_date &gt; current timestamp - 2 months``union``select distinct cust_num from temp.contact``where add_date &gt; current timestamp - 2 months``) 这个查询会导致优化器生成比较复杂的查询计划，尤其是 temp.customer 是一个比较复杂的视图的时候。这种情况下我们可以通过创建 UDF，将其分步执行：先执行子查询获得 cust_num 值的列表，然后执行最外层的查询。下面的例子是通过 UDF 对清单 20 的查询的改写： 清单 21. 1CREATE FUNCTION temp.getCustNum(p_date timestamp)``RETURNS``TABLE (cust_num CHARACTER(10))``RETURN``select distinct sold_to_cust_num from temp.order``where add_date &gt; p_date``union``select distinct cust_num from temp.contact``where add_date &gt; p_date;``select * from customer where cust_num in (``select cust_num from table(temp.getCustNum(current timestamp - 2 months)) tbl``) 改写前后的查询代价分别是 445,159.31 和 254,436.98。当面对比较复杂的查询时考虑使用 UDF 将其拆分为多步执行常常会带来意想不到的效果。在实际的项目中，如果数据处理和查询调用是包含在其他应用程序中如 Unix 脚本，Java 程序等，同样可以考虑采用分步数据处理的方式来调用数据库，以优化应用性能。 总结 本文主要介绍了如何使用 DB2 提供的各种查看存取计划的工具，并根据作者在 DB2 方面的开发经验总结了一些提高查询性能的方法和技巧。如果能够有效地利用 DB2 提供的各种工具，理解 DB2 中索引的结构，以及查询将如何被解释，数据库开发人员可以更好的提高查询性能来满足需求。 版权声明： 除非注明，本博文章均为原创，转载请以链接形式标明本文地址。]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>Optimization</tag>
        <tag>db2</tag>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mxLibraryLog]]></title>
    <url>%2F2019%2F10%2F07%2FmxLibraryLog%2F</url>
    <content type="text"></content>
      <tags>
        <tag>self-study</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有梦就有远方]]></title>
    <url>%2F2019%2F10%2F07%2Fsnaillife%2F</url>
    <content type="text"><![CDATA[有梦才有远方 &gt; 雪夜茫茫，你知道一棵小草的梦吗？寒冷孤寂中，她怀抱一个信念取暖，等到村归大地时，她就会以两片绿叶问候春天，而那两片绿叶，就是曾经在雪地下轻轻地梦呓。 &gt; 候鸟南飞，征途迢迢，他的梦呢?在远方，在视野里，那是南方湛蓝的大海。她很累很累，但依然往前奋飞。因为梦又赐予她另一对翅膀。 &gt; 窗前托腮凝思的少女，你是想做一朵云的诗，还是做一只蝶的画？ &gt; 风中奔跑的翩翩的少年，你是想做一只鹰，与天比高，还是做一条壮阔的长河，为大地抒怀? &gt; 我喜欢做梦。梦让我看到窗外的阳光，梦让我看到天边的彩霞，梦给我不变的召唤于步伐，梦引领我去追逐一个又一个目标。&gt; 1952年，一个叫查克贝瑞的美国青年，做了这么一个梦：超越贝多芬!并把这个消息告诉柴可夫斯基。多年以后，他成功了，成为摇滚音乐的奠基人之一。梦赋予他豪迈的宣言，梦也引领他走向光明的大道。梦启发了他的初心，他则用成功证明了梦的真实与壮美-——因为有了梦，才有了梦想；有了梦想，才有了理想；有了理想，才有了理想而奋斗的人生历程。 &gt; 没有泪水的人，他的眼睛是干涸的； &gt; 没有梦的人，他的夜晚是黑暗的。 &gt; 太阳总是在有梦的地方升起，月亮总是在有梦的地方朦胧。梦是永恒的微笑，使你的心灵永远充满激情，使你的双眼永远澄澈明亮。 &gt; 世界的万花筒散着诱人的清香，未来的天空下也传来迷人的歌唱。我们整装待发 ,用美梦打扮，从实干出发，等到我们抵达秋天的果园，轻轻地擦去夏天留在我们脸上的汗水与灰尘时，我们就可以听得见曾经对春天说过的那句话 ：美梦成真！]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>梦想</tag>
        <tag>破晓</tag>
        <tag>古月山风</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F10%2F07%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
</search>
